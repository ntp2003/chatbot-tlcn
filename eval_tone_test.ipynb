{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.metrics import ConversationalGEval\n",
    "\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "import deepeval.models.llms.openai_model as deepeval_models\n",
    "from deepeval import evaluate\n",
    "gpt_41_mini = deepeval_models.GPTModel(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    timeout=60,\n",
    "    #_openai_api_key=\"sk-BJpqmcWfn3O9bvr2eryf6Uyf1m7VpSQpL7cNxGGlZccRrfA1\",\n",
    "    #base_url=\"https://open.keyai.shop/v1\"\n",
    ")\n",
    "json_file = 'conversation_tone.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tc = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"tui mu·ªën h·ªèi c√°ch tra c·ª©u h√≥a ƒë∆°n ƒë√£ mua h√†ng\",\n",
    "            actual_output=\"D·∫° anh c√≥ th·ªÉ th·ª±c hi·ªán tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i [ƒë√¢y](https://hddt.fptshop.com.vn/).\",\n",
    "            # Kh√¥ng c·∫ßn context n·∫øu input ƒë√£ ƒë·ªß r√µ, nh∆∞ng criteria c·∫ßn x·ª≠ l√Ω ƒë∆∞·ª£c\n",
    "            context=[\"User gender: male\"] # C√≥ th·ªÉ th√™m n·∫øu mu·ªën r√µ r√†ng h∆°n\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"l√†m sao ƒë·ªÉ tra c·ª©u t√¨nh tr·∫°ng s·∫£n ph·∫©m g·ª≠i b·∫£o h√†nh t·∫°i FPT Shop?\",\n",
    "            actual_output=\"D·∫° anh c√≥ th·ªÉ tra c·ª©u t√¨nh tr·∫°ng m√°y g·ª≠i b·∫£o h√†nh b·∫•t c·ª© l√∫c n√†o [T·∫°i ƒë√¢y](https://fptshop.com.vn/kiem-tra-bao-hanh?tab=thong-tin-bao-hanh)..\",\n",
    "            context=[\"User gender: male\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"ƒê√°nh gi√° kh·∫£ nƒÉng c·ªßa chatbot trong vi·ªác s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† nh·∫•t qu√°n trong su·ªët cu·ªôc h·ªôi tho·∫°i. C·ª• th·ªÉ:\n",
    "    1. Chatbot (assistant) ph·∫£i LU√îN LU√îN t·ª± x∆∞ng l√† 'em'.\n",
    "    2. C√°ch chatbot g·ªçi ng∆∞·ªùi d√πng (user) ph·∫£i d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ho·∫∑c c√°ch ng∆∞·ªùi d√πng t·ª± x∆∞ng:\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'male' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'anh', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh'.\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'female' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch·ªã', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch·ªã'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch√∫', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch√∫' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'c√¥', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'c√¥' v√† t·ª± x∆∞ng 'ch√°u'. (L∆∞u √Ω: C·∫ßn ƒëi·ªÅu ch·ªânh n·∫øu model kh√¥ng ƒë∆∞·ª£c fine-tune ƒë·ªÉ x∆∞ng 'ch√°u'. N·∫øu model lu√¥n x∆∞ng 'em', th√¨ ti√™u ch√≠ n√†y c·∫ßn ph·∫£n √°nh ƒëi·ªÅu ƒë√≥, v√≠ d·ª•: \"N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch√∫', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch√∫' v√† v·∫´n t·ª± x∆∞ng 'em'\").\n",
    "        - N·∫øu 'User gender' l√† 'unknown' ho·∫∑c kh√¥ng ƒë∆∞·ª£c cung c·∫•p, v√† ng∆∞·ªùi d√πng kh√¥ng t·ª± x∆∞ng theo m·ªôt ƒë·∫°i t·ª´ c·ª• th·ªÉ n√†o ·ªü tr√™n, chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh/ch·ªã'.\n",
    "    3. Chatbot ph·∫£i duy tr√¨ c√°ch x∆∞ng h√¥ ƒë√£ thi·∫øt l·∫≠p v·ªõi ng∆∞·ªùi d√πng m·ªôt c√°ch nh·∫•t qu√°n trong c√°c l∆∞·ª£t tr·∫£ l·ªùi ti·∫øp theo, tr·ª´ khi c√≥ th√¥ng tin m·ªõi r√µ r√†ng v·ªÅ gi·ªõi t√≠nh ho·∫∑c c√°ch x∆∞ng h√¥ ∆∞u ti√™n c·ªßa ng∆∞·ªùi d√πng.\n",
    "    4. Kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng c√°c c√°ch x∆∞ng h√¥ kh√¥ng ph√π h·ª£p ho·∫∑c thi·∫øu t√¥n tr·ªçng.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # ƒê·ªÉ ph√¢n t√≠ch input c·ªßa user (v√≠ d·ª•: \"anh mu·ªën h·ªèi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # ƒê·ªÉ ph√¢n t√≠ch output c·ªßa model\n",
    "        # LLMTestCaseParams.CONTEXT,        # N·∫øu th√¥ng tin `User gender` ƒë∆∞·ª£c truy·ªÅn qua context cho m·ªói l∆∞·ª£t\n",
    "    ]\n",
    "    \n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deepeval.test_case import LLMTestCase, ConversationalTestCase\n",
    "from typing import List\n",
    "'''load testcase (with actual_output generated or not) from json file'''\n",
    "def load_testcase_from_json(json_file) -> List[ConversationalTestCase]:\n",
    "    try:\n",
    "            #parsed_data = json.loads(generated_json_string)\n",
    "            # load data from json file\n",
    "            with open( json_file,\"r\") as f:\n",
    "                parsed_data = json.load(f)\n",
    "            deepeval_test_cases = []\n",
    "            for conv_data in parsed_data:\n",
    "                llm_turns = []\n",
    "                for turn_data in conv_data.get(\"turns\", []):\n",
    "                    user_input = turn_data.get(\"user_input\")\n",
    "                    gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                    actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  \n",
    "\n",
    "                    current_context = []\n",
    "                    if gender_context_val and gender_context_val != \"null\":  #Ki·ªÉm tra null d∆∞·ªõi d·∫°ng chu·ªói\n",
    "                        current_context.append(f\"User gender: {gender_context_val}\")\n",
    "                \n",
    "                    if user_input:  #Ch·ªâ th√™m turn n·∫øu c√≥ user_input\n",
    "                        llm_turns.append(\n",
    "                            LLMTestCase(\n",
    "                                input=user_input,\n",
    "                                actual_output=actual_output_placeholder, # S·∫Ω ƒë∆∞·ª£c ƒëi·ªÅn sau\n",
    "                                context=current_context if current_context else None  # DeepEval c√≥ th·ªÉ mu·ªën None n·∫øu context r·ªóng\n",
    "                            )\n",
    "                        )\n",
    "                if llm_turns:  #Ch·ªâ th√™m ConversationalTestCase n·∫øu c√≥ turns h·ª£p l·ªá\n",
    "                    deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ d√πng messages\n",
    "                                                                                        #(ho·∫∑c `turns=llm_turns` cho phi√™n b·∫£n c≈© h∆°n)\n",
    "\n",
    "            print(f\"ƒê√£ load th√†nh c√¥ng {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "            return deepeval_test_cases\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"L·ªói gi·∫£i m√£ JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "import service.openai as openai_service\n",
    "from openai.types.chat_model import ChatModel\n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str,gen_answer_model:ChatModel=None) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "    # Add gender context to the conversation\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + gender_context},\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n",
    "\n",
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str\n",
    "\n",
    "# ko luu conversation vao history\n",
    "def get_actual_answer_for_all_testcase_without_conversation_history(json_file:str,gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    #deepeval_test_cases = load_testcase_from_json(json_file) # load test case with actual_output werent generated\n",
    "    '''\n",
    "    get_actual_answer for all testcase\n",
    "    iter_checkpoint is the index of the checkpoint fine-tuned model\n",
    "    gen_answer_model is the fine-tuned model to use for generating responses\n",
    "    '''\n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    for conversational_test_case in conversations:\n",
    "        processed_turns = []\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "\n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conversational_test_case.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        '''write to json file'''\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n",
    "\n",
    "#luu conversation vao history\n",
    "def get_actual_answer_with_conversation_history(json_file: str, gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    \n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "\n",
    "    for conv in conversations:\n",
    "        processed_turns = []\n",
    "        turns = conv.turns\n",
    "        user = create_user(\n",
    "            CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "        )\n",
    "        thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "        # Initialize conversation history with system message\n",
    "        history = [\n",
    "            {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + turns[0][\"user_gender_context\"]}\n",
    "        ]\n",
    "        \n",
    "        for turn in turns:\n",
    "            # Add user input to history\n",
    "            history.append({\"role\": \"user\", \"content\": turn[\"user_input\"]})\n",
    "            \n",
    "            # Set the model for this conversation\n",
    "            #openai_service._fine_tuning_model = gen_answer_model\n",
    "            \n",
    "            # Generate bot response using accumulated history\n",
    "            bot_response = gen_answer(\n",
    "                #thread_id=uuid4(),  # Generate new thread ID for each turn\n",
    "                thread_id=thread.id,\n",
    "                history=history,\n",
    "                #user_id=uuid4(),  # Generate new user ID for each turn\n",
    "                user_id=user.id,\n",
    "            )\n",
    "            turn.actual_output = bot_response\n",
    "            # Add bot response to history for next turn\n",
    "            history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "            \n",
    "            # Store processed turn\n",
    "            \n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "        \n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conv.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"{json_file}_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' function to get actual_output for all testcase and write to json file'''\n",
    "'''\n",
    "def get_actual_output_for_all_testcase(deepeval_test_cases,gen_answer_model,iter_checkpoint):\n",
    "    for conversational_test_case in deepeval_test_cases:\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "        with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "            json.dump(conversational_test_case, f)\n",
    "'''            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"ƒê√°nh gi√° kh·∫£ nƒÉng c·ªßa chatbot trong vi·ªác s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† nh·∫•t qu√°n trong su·ªët cu·ªôc h·ªôi tho·∫°i. C·ª• th·ªÉ:\n",
    "    1. Chatbot (assistant) trong 'actual_output' **n√™n** t·ª± x∆∞ng l√† 'em'. Vi·ªác n√†y ƒë∆∞·ª£c ∆∞u ti√™n, ƒë·∫∑c bi·ªát ·ªü c√°c l∆∞·ª£t n√≥i ƒë·∫ßu ho·∫∑c khi c·∫ßn l√†m r√µ h√†nh ƒë·ªông c·ªßa chatbot (v√≠ d·ª•: 'D·∫° em ch√†o anh', 'Em c√≥ th·ªÉ gi√∫p g√¨ ·∫°'). Vi·ªác kh√¥ng x∆∞ng 'em' trong m·ªôt s·ªë c√¢u tr·∫£ l·ªùi ng·∫Øn v√† tr·ª±c ti·∫øp ·ªü c√°c l∆∞·ª£t sau c√≥ th·ªÉ ƒë∆∞·ª£c ch·∫•p nh·∫≠n n·∫øu vƒÉn phong t·ª± nhi√™n v√† vai tr√≤ c·ªßa chatbot ƒë√£ r√µ r√†ng t·ª´ tr∆∞·ªõc. Chatbot **TUY·ªÜT ƒê·ªêI KH√îNG** ƒë∆∞·ª£c d√πng 't√¥i', 'm√¨nh' ƒë·ªÉ t·ª± x∆∞ng.\n",
    "    2. C√°ch chatbot g·ªçi ng∆∞·ªùi d√πng (user) ph·∫£i d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ho·∫∑c c√°ch ng∆∞·ªùi d√πng t·ª± x∆∞ng:\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'male' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'anh' nh∆∞ 'anh mu·ªën h·ªèi...', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh'.\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'female' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch·ªã' nh∆∞ 'ch·ªã mu·ªën h·ªèi...', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch·ªã'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch√∫', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch√∫' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'b√°c', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'b√°c' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'c√¥', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'c√¥' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'unknown' ho·∫∑c kh√¥ng ƒë∆∞·ª£c cung c·∫•p, v√† ng∆∞·ªùi d√πng kh√¥ng t·ª± x∆∞ng theo m·ªôt ƒë·∫°i t·ª´ c·ª• th·ªÉ n√†o ·ªü tr√™n, chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh/ch·ªã'.\n",
    "\n",
    "    3. T√≠nh nh·∫•t qu√°n: Chatbot ph·∫£i duy tr√¨ c√°ch x∆∞ng h√¥ ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p v·ªõi ng∆∞·ªùi d√πng m·ªôt c√°ch nh·∫•t qu√°n trong c√°c l∆∞·ª£t tr·∫£ l·ªùi ti·∫øp theo trong c√πng m·ªôt cu·ªôc h·ªôi tho·∫°i, tr·ª´ khi c√≥ th√¥ng tin m·ªõi r√µ r√†ng thay ƒë·ªïi c√°ch x∆∞ng h√¥.\n",
    "    4. Kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng c√°c c√°ch x∆∞ng h√¥ kh√¥ng ph√π h·ª£p ho·∫∑c thi·∫øu t√¥n tr·ªçng.\n",
    "\n",
    "    H∆Ø·ªöNG D·∫™N CH·∫§M ƒêI·ªÇM:\n",
    "    - ƒêi·ªÉm 1.0: Tu√¢n th·ªß ho√†n h·∫£o t·∫•t c·∫£ c√°c quy t·∫Øc tr√™n trong m·ªçi l∆∞·ª£t c·ªßa h·ªôi tho·∫°i.\n",
    "    - **Ph·∫°t n·∫∑ng (ƒëi·ªÉm g·∫ßn 0): N·∫øu chatbot t·ª± x∆∞ng sai ho√†n to√†n (v√≠ d·ª•: d√πng 't√¥i', 'm√¨nh' thay v√¨ 'em'; ho·∫∑c d√πng sai gi·ªØa 'em' v√† 'ch√°u' khi ng·ªØ c·∫£nh y√™u c·∫ßu r√µ r√†ng).**\n",
    "    - Ph·∫°t n·∫∑ng (ƒëi·ªÉm g·∫ßn 0): N·∫øu chatbot g·ªçi sai ng∆∞·ªùi d√πng m·ªôt c√°ch r√µ r√†ng (v√≠ d·ª•: context l√† 'User gender: male' nh∆∞ng chatbot g·ªçi l√† 'ch·ªã').\n",
    "    - **Ph·∫°t nh·∫π ho·∫∑c kh√¥ng ph·∫°t: ƒê·ªëi v·ªõi tr∆∞·ªùng h·ª£p chatbot kh√¥ng t·ª± x∆∞ng 'em' trong m·ªôt s·ªë √≠t c√¢u tr·∫£ l·ªùi ng·∫Øn, tr·ª±c ti·∫øp ·ªü c√°c l∆∞·ª£t sau, khi vi·ªác n√†y kh√¥ng ·∫£nh h∆∞·ªüng ƒë√°ng k·ªÉ ƒë·∫øn s·ª± r√µ r√†ng, t√≠nh l·ªãch s·ª± c·ªßa cu·ªôc h·ªôi tho·∫°i v√† vai tr√≤ chatbot ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p.**\n",
    "    - Xem x√©t to√†n b·ªô cu·ªôc h·ªôi tho·∫°i ƒë·ªÉ ƒë√°nh gi√° t√≠nh nh·∫•t qu√°n.\n",
    "    \"\"\",\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.CONTEXT,\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"ƒê√°nh gi√° kh·∫£ nƒÉng c·ªßa chatbot trong vi·ªác s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† nh·∫•t qu√°n trong su·ªët cu·ªôc h·ªôi tho·∫°i. \n",
    "\n",
    "    TH√îNG TIN C·∫¶N PH√ÇN T√çCH:\n",
    "    - 'input': Tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng - c·∫ßn ph√¢n t√≠ch c√°ch ng∆∞·ªùi d√πng t·ª± x∆∞ng v√† ng·ªØ c·∫£nh\n",
    "    - 'actual_output': Ph·∫£n h·ªìi c·ªßa chatbot - c·∫ßn ƒë√°nh gi√° c√°ch chatbot t·ª± x∆∞ng v√† g·ªçi ng∆∞·ªùi d√πng\n",
    "    - 'context': Th√¥ng tin b·ªï sung v·ªÅ ng∆∞·ªùi d√πng (v√≠ d·ª•: User gender) v√† ng·ªØ c·∫£nh cu·ªôc h·ªôi tho·∫°i\n",
    "\n",
    "    QUY T·∫ÆC ƒê√ÅNH GI√Å:\n",
    "\n",
    "    1. **C√°ch chatbot t·ª± x∆∞ng trong 'actual_output':**\n",
    "       - Chatbot **n√™n** t·ª± x∆∞ng l√† 'em' (ƒë∆∞·ª£c ∆∞u ti√™n, ƒë·∫∑c bi·ªát ·ªü c√°c l∆∞·ª£t n√≥i ƒë·∫ßu ho·∫∑c khi c·∫ßn l√†m r√µ h√†nh ƒë·ªông)\n",
    "       - Chatbot **TUY·ªÜT ƒê·ªêI KH√îNG** ƒë∆∞·ª£c d√πng 't√¥i', 'm√¨nh' ƒë·ªÉ t·ª± x∆∞ng\n",
    "       - Ngo·∫°i l·ªá: Khi ng∆∞·ªùi d√πng trong 'input' t·ª± x∆∞ng l√† 'ch√∫', 'b√°c', 'c√¥' th√¨ chatbot ph·∫£i t·ª± x∆∞ng 'ch√°u'\n",
    "\n",
    "    2. **C√°ch chatbot g·ªçi ng∆∞·ªùi d√πng (d·ª±a tr√™n 'input' v√† 'context'):**\n",
    "       - N·∫øu trong 'context' c√≥ 'User gender: male' HO·∫∂C ng∆∞·ªùi d√πng trong 'input' t·ª± x∆∞ng 'anh' ‚Üí chatbot g·ªçi 'anh'\n",
    "       - N·∫øu trong 'context' c√≥ 'User gender: female' HO·∫∂C ng∆∞·ªùi d√πng trong 'input' t·ª± x∆∞ng 'ch·ªã' ‚Üí chatbot g·ªçi 'ch·ªã'\n",
    "       - N·∫øu ng∆∞·ªùi d√πng trong 'input' t·ª± x∆∞ng 'ch√∫' ‚Üí chatbot g·ªçi 'ch√∫' v√† t·ª± x∆∞ng 'ch√°u'\n",
    "       - N·∫øu ng∆∞·ªùi d√πng trong 'input' t·ª± x∆∞ng 'b√°c' ‚Üí chatbot g·ªçi 'b√°c' v√† t·ª± x∆∞ng 'ch√°u'\n",
    "       - N·∫øu ng∆∞·ªùi d√πng trong 'input' t·ª± x∆∞ng 'c√¥' ‚Üí chatbot g·ªçi 'c√¥' v√† t·ª± x∆∞ng 'ch√°u'\n",
    "       - N·∫øu trong 'context' c√≥ 'User gender: unknown' ho·∫∑c kh√¥ng c√≥ th√¥ng tin gender, v√† ng∆∞·ªùi d√πng trong 'input' kh√¥ng t·ª± x∆∞ng r√µ r√†ng ‚Üí chatbot g·ªçi 'anh/ch·ªã'\n",
    "\n",
    "    3. **T√≠nh nh·∫•t qu√°n:** \n",
    "       - Ph√¢n t√≠ch to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i trong 'context' ƒë·ªÉ ƒë·∫£m b·∫£o chatbot duy tr√¨ c√°ch x∆∞ng h√¥ ƒë√£ thi·∫øt l·∫≠p\n",
    "       - Ch·ªâ ch·∫•p nh·∫≠n thay ƒë·ªïi c√°ch x∆∞ng h√¥ khi c√≥ th√¥ng tin m·ªõi r√µ r√†ng trong 'input'\n",
    "\n",
    "    4. **T√≠nh l·ªãch s·ª± v√† ph√π h·ª£p:**\n",
    "       - Kh√¥ng s·ª≠ d·ª•ng c√°ch x∆∞ng h√¥ thi·∫øu t√¥n tr·ªçng ho·∫∑c kh√¥ng ph√π h·ª£p v·ªõi vƒÉn h√≥a Vi·ªát Nam\n",
    "\n",
    "    H∆Ø·ªöNG D·∫™N CH·∫§M ƒêI·ªÇM:\n",
    "    - **ƒêi·ªÉm 1.0:** Tu√¢n th·ªß ho√†n h·∫£o t·∫•t c·∫£ c√°c quy t·∫Øc tr√™n, ph√π h·ª£p v·ªõi th√¥ng tin trong 'input', 'context' v√† th·ªÉ hi·ªán t√≠nh nh·∫•t qu√°n trong 'actual_output'\n",
    "    \n",
    "    - **Ph·∫°t n·∫∑ng (ƒëi·ªÉm 0.0-0.3):**\n",
    "      ‚Ä¢ Chatbot t·ª± x∆∞ng sai ho√†n to√†n ('t√¥i', 'm√¨nh' thay v√¨ 'em')\n",
    "      ‚Ä¢ S·ª≠ d·ª•ng sai gi·ªØa 'em' v√† 'ch√°u' khi 'input' ho·∫∑c 'context' y√™u c·∫ßu r√µ r√†ng\n",
    "      ‚Ä¢ G·ªçi sai ng∆∞·ªùi d√πng r√µ r√†ng (v√≠ d·ª•: 'context' l√† 'User gender: male' nh∆∞ng g·ªçi 'ch·ªã')\n",
    "      ‚Ä¢ Kh√¥ng nh·∫•t qu√°n trong c√πng cu·ªôc h·ªôi tho·∫°i m√† kh√¥ng c√≥ l√Ω do ch√≠nh ƒë√°ng t·ª´ 'input' m·ªõi\n",
    "    \n",
    "    - **Ph·∫°t v·ª´a (ƒëi·ªÉm 0.4-0.7):**\n",
    "      ‚Ä¢ Thi·∫øu m·ªôt s·ªë c√°ch x∆∞ng h√¥ c·∫ßn thi·∫øt ·ªü nh·ªØng v·ªã tr√≠ quan tr·ªçng\n",
    "      ‚Ä¢ Kh√¥ng t·∫≠n d·ª•ng ƒë·∫ßy ƒë·ªß th√¥ng tin t·ª´ 'context' ƒë·ªÉ x√°c ƒë·ªãnh c√°ch x∆∞ng h√¥ ph√π h·ª£p\n",
    "    \n",
    "    - **Ph·∫°t nh·∫π ho·∫∑c kh√¥ng ph·∫°t (ƒëi·ªÉm 0.8-1.0):**\n",
    "      ‚Ä¢ Chatbot kh√¥ng t·ª± x∆∞ng 'em' trong m·ªôt s·ªë √≠t c√¢u tr·∫£ l·ªùi ng·∫Øn, tr·ª±c ti·∫øp ·ªü c√°c l∆∞·ª£t sau, khi vai tr√≤ ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p v√† kh√¥ng ·∫£nh h∆∞·ªüng ƒë·∫øn t√≠nh l·ªãch s·ª±\n",
    "\n",
    "    C√ÅCH PH√ÇN T√çCH:\n",
    "    1. ƒê·ªçc k·ªπ 'context' ƒë·ªÉ hi·ªÉu th√¥ng tin v·ªÅ ng∆∞·ªùi d√πng v√† l·ªãch s·ª≠ h·ªôi tho·∫°i\n",
    "    2. Ph√¢n t√≠ch 'input' ƒë·ªÉ x√°c ƒë·ªãnh c√°ch ng∆∞·ªùi d√πng t·ª± x∆∞ng v√† mong ƒë·ª£i ƒë∆∞·ª£c g·ªçi\n",
    "    3. ƒê√°nh gi√° 'actual_output' d·ª±a tr√™n c√°c quy t·∫Øc tr√™n\n",
    "    4. Xem x√©t t√≠nh nh·∫•t qu√°n v·ªõi c√°c l∆∞·ª£t h·ªôi tho·∫°i tr∆∞·ªõc ƒë√≥ (n·∫øu c√≥ trong context)\n",
    "    \"\"\",\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.CONTEXT,\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713d2e504a174eccbffddadc453c6b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8029362452578461 The chatbot consistently uses 'Ch·ªã' to address the user, matching the user's self-reference in the input. Although the user's gender is unknown in context, the chatbot maintains politeness and cultural appropriateness without inconsistent shifts in pronouns.\n"
     ]
    }
   ],
   "source": [
    "test_case = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"Ch·ªã mu·ªën h·ªèi c√°ch tra c·ª©u ƒëi·ªÉm mua h√†ng ƒë√£ t√≠ch ƒë∆∞·ª£c t·∫°i FPT Shop .\",\n",
    "            actual_output= \" Ch·ªã c√≥ th·ªÉ th·ª±c hi·ªán tra c·ª©u ƒëi·ªÉm t√≠ch [t·∫°i ƒë√¢y](https://fptshop.com.vn/tai-khoan/lich-su-tich-diem) b·∫±ng c√°ch ƒëƒÉng nh·∫≠p s·ªë ƒëi·ªán tho·∫°i mua h√†ng c·ªßa ch·ªã.\",\n",
    "            # Kh√¥ng c·∫ßn context n·∫øu input ƒë√£ ƒë·ªß r√µ, nh∆∞ng criteria c·∫ßn x·ª≠ l√Ω ƒë∆∞·ª£c\n",
    "            # context=[\"User gender: female\"] # C√≥ th·ªÉ th√™m n·∫øu mu·ªën r√µ r√†ng h∆°n\n",
    "            context=[\"User gender: unknown\"]\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"V·∫≠y c√≤n tra c·ª©u v·ªÅ th√¥ng tin tr√∫ng th∆∞·ªüng c·ªßa FPT Shop khi tham gia c√°c ch∆∞∆°ng tr√¨nh mini game?\",\n",
    "            actual_output=\"Ch·ªã c√≥ th·ªÉ th·ª±c hi·ªán tra c·ª©u [t·∫°i ƒë√¢y](https://fptshop.com.vn/khuyen-mai/thong-tin-trao-thuong)\",\n",
    "            context=[\"User gender: unknown\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "pronoun_consistency_metric.measure(test_case)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anh mu·ªën h·ªèi c√°ch tra c·ª©u v·ªÅ h√≥a ƒë∆°n ƒë√£ mua h√†ng t·∫°i FPT Shop?\n",
      "User gender: male\n",
      "N·∫øu h√≥a ƒë∆°n ƒë√≥ mua h∆°n 1 nƒÉm r·ªìi th√¨ c√≥ t√¨m l·∫°i ƒë∆∞·ª£c kh√¥ng shop?\n",
      "User gender: male\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    print(turn.input)\n",
    "    # turn list to str\n",
    "    turn_str = \"\"\n",
    "    for t in turn.context:\n",
    "        turn_str += t\n",
    "    print(turn_str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-165e-7c72-bfd0-d513b251ee06\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 12\n",
      "faq id : 16\n",
      "faq id : 62\n",
      "faq id : 18\n",
      "2025-06-01 12:07:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: f6eb87ad-616a-4b58-a7e3-126f60c8f886 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='D·∫° ch√†o anh. Anh c√≥ th·ªÉ tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i FPT Shop [t·∫°i ƒë√¢y](https://hddt.fptshop.com.vn/). N·∫øu anh c·∫ßn th√™m th√¥ng tin ho·∫∑c h·ªó tr·ª£ kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©.'\n",
      "D·∫° ch√†o anh. Anh c√≥ th·ªÉ tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i FPT Shop [t·∫°i ƒë√¢y](https://hddt.fptshop.com.vn/). N·∫øu anh c·∫ßn th√™m th√¥ng tin ho·∫∑c h·ªó tr·ª£ kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©.\n",
      "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-3ff1-7050-806a-181e9b2ba4bb\n",
      "2025-06-01 12:08:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:08:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 79\n",
      "2025-06-01 12:08:08 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: a598641d-6bae-4686-bf42-a34df626c189 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='D·∫° th∆∞a anh, theo quy ƒë·ªãnh c·ªßa FPT Shop, h√≥a ƒë∆°n mua h√†ng s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa c·ª≠a h√†ng trong v√≤ng 1 nƒÉm k·ªÉ t·ª´ ng√†y mua. Sau th·ªùi gian n√†y, h√≥a ƒë∆°n s·∫Ω kh√¥ng c√≤n kh·∫£ nƒÉng truy xu·∫•t. N·∫øu anh c·∫ßn h·ªó tr·ª£ th√™m th√¥ng tin v·ªÅ s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©. FPT Shop hi·ªán c√≥ nhi·ªÅu lo·∫°i s·∫£n ph·∫©m c√¥ng ngh·ªá nh∆∞ ƒëi·ªán tho·∫°i, laptop, m√°y t√≠nh b·∫£ng,... r·∫•t ƒëa d·∫°ng ·∫°.'\n",
      "D·∫° th∆∞a anh, theo quy ƒë·ªãnh c·ªßa FPT Shop, h√≥a ƒë∆°n mua h√†ng s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa c·ª≠a h√†ng trong v√≤ng 1 nƒÉm k·ªÉ t·ª´ ng√†y mua. Sau th·ªùi gian n√†y, h√≥a ƒë∆°n s·∫Ω kh√¥ng c√≤n kh·∫£ nƒÉng truy xu·∫•t. N·∫øu anh c·∫ßn h·ªó tr·ª£ th√™m th√¥ng tin v·ªÅ s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©. FPT Shop hi·ªán c√≥ nhi·ªÅu lo·∫°i s·∫£n ph·∫©m c√¥ng ngh·ªá nh∆∞ ƒëi·ªán tho·∫°i, laptop, m√°y t√≠nh b·∫£ng,... r·∫•t ƒëa d·∫°ng ·∫°.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "for turn in tc.turns:\n",
    "    turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context))\n",
    "    print(turn.actual_output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f6e08653f499e9f750202fd521a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The chatbot consistently uses 'em' for self-reference and addresses the male user as 'anh' in both turns, matching the user gender in context. The form of address remains consistent and respectful throughout the conversation.\n"
     ]
    }
   ],
   "source": [
    "# danh gia rieng le 1 testcase\n",
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "'''save the output of get_actual_answer for all testcase to json file for each model'''\n",
    "\n",
    "\n",
    "def eval_tc(_testcases,_metrics,iter_checkpoint):\n",
    "    evaluation_results = evaluate(\n",
    "        test_cases=_testcases,\n",
    "        metrics=_metrics,\n",
    "    )\n",
    "    # ƒëi·ªÉm s·ªë c·ªßa metric ƒë∆∞·ª£c l∆∞u trong m·ªói ƒë·ªëi t∆∞·ª£ng test case sau khi evaluate\n",
    "    score = 0\n",
    "    for result in evaluation_results: # evaluate() tr·∫£ v·ªÅ list c√°c test cases ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t\n",
    "        print(f\"Test Case ID: {result.id if result.id else 'N/A'}\") # ConversationalTestCase c√≥ th·ªÉ kh√¥ng c√≥ id tr·ª´ khi b·∫°n set\n",
    "        for metric_result in result.metrics: # M·ªói test case c√≥ th·ªÉ c√≥ nhi·ªÅu metric\n",
    "            if metric_result.name == pronoun_consistency_metric.name:\n",
    "                print(f\"  Metric: {metric_result.name}\")\n",
    "                print(f\"  Score: {metric_result.score}\")\n",
    "                if metric_result.reason: \n",
    "                    print(f\"  Reason: {metric_result.reason[:300]}...\") # In m·ªôt ph·∫ßn l√Ω do\n",
    "                print(\"-\" * 20)\n",
    "                score += metric_result.score\n",
    "    mean_score = score/len(evaluation_results)\n",
    "    print(f\"Mean score: {mean_score}\")\n",
    "            \n",
    "    \n",
    "    # get the mean score of all testcase\n",
    "    \n",
    "    #mean_score = evaluation_results.score.mean()\n",
    "    # save result to file\n",
    "    with open(f\"evaluation_results_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(evaluation_results, f)\n",
    "        json.dump(mean_score, f)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_lst = [\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6dn4:ckpt-step-50\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6ShS:ckpt-step-100\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao7Wp2\"]\n",
    "\n",
    "def get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        model = checkpoint_model\n",
    "\n",
    "        # 1 trong 2 cach de luu actual_output vao json file moi\n",
    "        #get_actual_answer_for_all_testcase_without_conversation_history(json_file,model,iter_checkpoint)\n",
    "        get_actual_answer_with_conversation_history(json_file,model,iter_checkpoint)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thay vi chi d√πng checkpoint cuoi c·ªßa fine-tuned model , d√πng to√†n b·ªô checkpoint ƒë·ªÉ ƒë√°nh gi√°\"\"\"\n",
    "def eval_all_checkpoint(deepeval_test_cases,checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        load_testcase_from_json(f'{json_file}_{iter_checkpoint}.json')\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        # evaluate\n",
    "        eval_tc(deepeval_test_cases,[pronoun_consistency_metric],iter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danh gia toan bo testcase\n",
    "#eval_all_checkpoint(deepeval_test_cases,checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" +\"User gender: unknown\"}\n",
    "]\n",
    "turns = [\n",
    "    {\"user_input\": \"Ch√∫ mu·ªën h·ªèi Shop c√≥ h·ªó tr·ª£ tr·∫£ g√≥p qua Home PayLater kh√¥ng?\"},\n",
    "    {\"user_input\": \"V·∫≠y c·ª≠a h√†ng c√≥ h·ªó tr·ª£ tr·∫£ g√≥p qua Kredivo kh√¥ng?\"}\n",
    "]\n",
    "user = create_user(\n",
    "            CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "        )\n",
    "thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "for turn in turns:\n",
    "    # Add user input to history\n",
    "    history.append({\"role\": \"user\", \"content\": turn[\"user_input\"]})\n",
    "    \n",
    "    # Set the model for this conversation\n",
    "    #openai_service._fine_tuning_model = gen_answer_model\n",
    "    \n",
    "    # Generate bot response using accumulated history\n",
    "    bot_response = gen_answer(\n",
    "        #thread_id=uuid4(),  # Generate new thread ID for each turn\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        #user_id=uuid4(),  # Generate new user ID for each turn\n",
    "        user_id=user.id,\n",
    "    )\n",
    "    turn.actual_output = bot_response\n",
    "    # Add bot response to history for next turn\n",
    "    history.append({\"role\": \"assistant\", \"content\": bot_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
