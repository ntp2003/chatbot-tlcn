{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.metrics import ConversationalGEval\n",
    "\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "import deepeval.models.llms.openai_model as deepeval_models\n",
    "from deepeval import evaluate\n",
    "gpt_41_mini = deepeval_models.GPTModel(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    timeout=60,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tc = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"tui mu·ªën h·ªèi c√°ch tra c·ª©u h√≥a ƒë∆°n ƒë√£ mua h√†ng\",\n",
    "            actual_output=\"D·∫° anh c√≥ th·ªÉ th·ª±c hi·ªán tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i [ƒë√¢y](https://hddt.fptshop.com.vn/).\",\n",
    "            # Kh√¥ng c·∫ßn context n·∫øu input ƒë√£ ƒë·ªß r√µ, nh∆∞ng criteria c·∫ßn x·ª≠ l√Ω ƒë∆∞·ª£c\n",
    "            context=[\"User gender: male\"] # C√≥ th·ªÉ th√™m n·∫øu mu·ªën r√µ r√†ng h∆°n\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"l√†m sao ƒë·ªÉ tra c·ª©u t√¨nh tr·∫°ng s·∫£n ph·∫©m g·ª≠i b·∫£o h√†nh t·∫°i FPT Shop?\",\n",
    "            actual_output=\"D·∫° anh c√≥ th·ªÉ tra c·ª©u t√¨nh tr·∫°ng m√°y g·ª≠i b·∫£o h√†nh b·∫•t c·ª© l√∫c n√†o [T·∫°i ƒë√¢y](https://fptshop.com.vn/kiem-tra-bao-hanh?tab=thong-tin-bao-hanh)..\",\n",
    "            context=[\"User gender: male\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"ƒê√°nh gi√° kh·∫£ nƒÉng c·ªßa chatbot trong vi·ªác s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† nh·∫•t qu√°n trong su·ªët cu·ªôc h·ªôi tho·∫°i. C·ª• th·ªÉ:\n",
    "    1. Chatbot (assistant) ph·∫£i LU√îN LU√îN t·ª± x∆∞ng l√† 'em'.\n",
    "    2. C√°ch chatbot g·ªçi ng∆∞·ªùi d√πng (user) ph·∫£i d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ho·∫∑c c√°ch ng∆∞·ªùi d√πng t·ª± x∆∞ng:\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'male' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'anh', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh'.\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'female' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch·ªã', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch·ªã'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch√∫', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch√∫' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'c√¥', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'c√¥' v√† t·ª± x∆∞ng 'ch√°u'. (L∆∞u √Ω: C·∫ßn ƒëi·ªÅu ch·ªânh n·∫øu model kh√¥ng ƒë∆∞·ª£c fine-tune ƒë·ªÉ x∆∞ng 'ch√°u'. N·∫øu model lu√¥n x∆∞ng 'em', th√¨ ti√™u ch√≠ n√†y c·∫ßn ph·∫£n √°nh ƒëi·ªÅu ƒë√≥, v√≠ d·ª•: \"N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch√∫', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch√∫' v√† v·∫´n t·ª± x∆∞ng 'em'\").\n",
    "        - N·∫øu 'User gender' l√† 'unknown' ho·∫∑c kh√¥ng ƒë∆∞·ª£c cung c·∫•p, v√† ng∆∞·ªùi d√πng kh√¥ng t·ª± x∆∞ng theo m·ªôt ƒë·∫°i t·ª´ c·ª• th·ªÉ n√†o ·ªü tr√™n, chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh/ch·ªã'.\n",
    "    3. Chatbot ph·∫£i duy tr√¨ c√°ch x∆∞ng h√¥ ƒë√£ thi·∫øt l·∫≠p v·ªõi ng∆∞·ªùi d√πng m·ªôt c√°ch nh·∫•t qu√°n trong c√°c l∆∞·ª£t tr·∫£ l·ªùi ti·∫øp theo, tr·ª´ khi c√≥ th√¥ng tin m·ªõi r√µ r√†ng v·ªÅ gi·ªõi t√≠nh ho·∫∑c c√°ch x∆∞ng h√¥ ∆∞u ti√™n c·ªßa ng∆∞·ªùi d√πng.\n",
    "    4. Kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng c√°c c√°ch x∆∞ng h√¥ kh√¥ng ph√π h·ª£p ho·∫∑c thi·∫øu t√¥n tr·ªçng.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # ƒê·ªÉ ph√¢n t√≠ch input c·ªßa user (v√≠ d·ª•: \"anh mu·ªën h·ªèi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # ƒê·ªÉ ph√¢n t√≠ch output c·ªßa model\n",
    "        # LLMTestCaseParams.CONTEXT,        # N·∫øu th√¥ng tin `User gender` ƒë∆∞·ª£c truy·ªÅn qua context cho m·ªói l∆∞·ª£t\n",
    "    ]\n",
    "    \n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ t·∫°o th√†nh c√¥ng 30 ConversationalTestCase objects.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from deepeval.test_case import LLMTestCase, ConversationalTestCase\n",
    "\n",
    "\n",
    "try:\n",
    "        #parsed_data = json.loads(generated_json_string)\n",
    "        # load data from json file\n",
    "        with open(\"conversation_tone.json\", \"r\") as f:\n",
    "            parsed_data = json.load(f)\n",
    "        deepeval_test_cases = []\n",
    "        for conv_data in parsed_data:\n",
    "            llm_turns = []\n",
    "            for turn_data in conv_data.get(\"turns\", []):\n",
    "                user_input = turn_data.get(\"user_input\")\n",
    "                gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  #N√™n l√† \"\"\n",
    "\n",
    "                current_context = []\n",
    "                if gender_context_val and gender_context_val != \"null\":  #Ki·ªÉm tra null d∆∞·ªõi d·∫°ng chu·ªói\n",
    "                    current_context.append(f\"User gender: {gender_context_val}\")\n",
    "            \n",
    "                if user_input:  #Ch·ªâ th√™m turn n·∫øu c√≥ user_input\n",
    "                    llm_turns.append(\n",
    "                        LLMTestCase(\n",
    "                            input=user_input,\n",
    "                            actual_output=actual_output_placeholder, # S·∫Ω ƒë∆∞·ª£c ƒëi·ªÅn sau\n",
    "                            context=current_context if current_context else None  # DeepEval c√≥ th·ªÉ mu·ªën None n·∫øu context r·ªóng\n",
    "                        )\n",
    "                    )\n",
    "            if llm_turns:  #Ch·ªâ th√™m ConversationalTestCase n·∫øu c√≥ turns h·ª£p l·ªá\n",
    "                deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ d√πng messages\n",
    "                                                                                    #(ho·∫∑c `turns=llm_turns` cho phi√™n b·∫£n c≈© h∆°n)\n",
    "\n",
    "        print(f\"ƒê√£ t·∫°o th√†nh c√¥ng {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "        #c√≥ th·ªÉ d√πng deepeval_test_cases ƒë·ªÉ ch·∫°y ƒë√°nh gi√° sau khi ƒëi·ªÅn actual_output\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"L·ªói gi·∫£i m√£ JSON: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:39:56 - Loaded .env file\n",
      "2025-06-01 12:40:00 - >>> {\"query\": \"query DefaultEntity {\\n  viewer {\\n    username\\n    defaultEntity {\\n      name\\n    }\\n  }\\n}\"}\n",
      "2025-06-01 12:40:01 - <<< {\"data\":{\"viewer\":{\"username\":\"phatnguyen-041203\",\"defaultEntity\":{\"name\":\"tlcn\"}}}}\n",
      "weave version 0.51.49 is available!  To upgrade, please run:\n",
      " $ pip install weave --upgrade\n",
      "Logged in as Weights & Biases user: phatnguyen-041203.\n",
      "View Weave data at https://wandb.ai/tlcn/CHATBOT-TLCN/weave\n",
      "2025-06-01 12:40:02 - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "import service.openai as openai_service\n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str,gen_answer_model=None) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat model cho gen_answer\n",
    "    # Add gender context to the conversation\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + gender_context},\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"ƒê√°nh gi√° kh·∫£ nƒÉng c·ªßa chatbot trong vi·ªác s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† nh·∫•t qu√°n trong su·ªët cu·ªôc h·ªôi tho·∫°i. C·ª• th·ªÉ:\n",
    "    1. Chatbot (assistant) trong 'actual_output' ph·∫£i LU√îN LU√îN t·ª± x∆∞ng l√† 'em'.  V√≠ d·ª•: 'd·∫° em ch√†o anh', 'em c√≥ th·ªÉ gi√∫p g√¨ ·∫°'. KH√îNG ƒë∆∞·ª£c d√πng 't√¥i', 'm√¨nh'\n",
    "    2. C√°ch chatbot g·ªçi ng∆∞·ªùi d√πng (user) ph·∫£i d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ho·∫∑c c√°ch ng∆∞·ªùi d√πng t·ª± x∆∞ng:\n",
    "        - N·∫øu 'User gender ƒë∆∞·ª£c cung c·∫•p l√† 'male' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'anh', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh'.\n",
    "        - N·∫øu 'User gend'er' ƒë∆∞·ª£c cung c·∫•p l√† 'female' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch·ªã', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch·ªã'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch√∫', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch√∫' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'c√¥', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'c√¥' v√† t·ª± x∆∞ng 'ch√°u'. \n",
    "        - N·∫øu 'User gender' l√† 'unknown' ho·∫∑c kh√¥ng ƒë∆∞·ª£c cung c·∫•p, v√† ng∆∞·ªùi d√πng kh√¥ng t·ª± x∆∞ng theo m·ªôt ƒë·∫°i t·ª´ c·ª• th·ªÉ n√†o ·ªü tr√™n, chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh/ch·ªã'.\n",
    "    3. T√≠nh nh·∫•t qu√°n: Chatbot ph·∫£i duy tr√¨ c√°ch x∆∞ng h√¥ ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p v·ªõi ng∆∞·ªùi d√πng m·ªôt c√°ch nh·∫•t qu√°n trong c√°c l∆∞·ª£t tr·∫£ l·ªùi ti·∫øp theo trong c√πng m·ªôt cu·ªôc h·ªôi tho·∫°i, tr·ª´ khi c√≥ th√¥ng tin m·ªõi r√µ r√†ng thay ƒë·ªïi c√°ch x∆∞ng h√¥.\n",
    "    4. Kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng c√°c c√°ch x∆∞ng h√¥ kh√¥ng ph√π h·ª£p ho·∫∑c thi·∫øu t√¥n tr·ªçng.\n",
    "      H∆Ø·ªöNG D·∫™N CH·∫§M ƒêI·ªÇM:\n",
    "    - ƒêi·ªÉm 1.0: Tu√¢n th·ªß ho√†n h·∫£o t·∫•t c·∫£ c√°c quy t·∫Øc tr√™n trong m·ªçi l∆∞·ª£t c·ªßa h·ªôi tho·∫°i.\n",
    "    - Ph·∫°t n·∫∑ng (ƒëi·ªÉm g·∫ßn 0): N·∫øu chatbot t·ª± x∆∞ng sai (v√≠ d·ª•: x∆∞ng 't√¥i' thay v√¨ 'em').\n",
    "    - Ph·∫°t n·∫∑ng (ƒëi·ªÉm g·∫ßn 0): N·∫øu chatbot g·ªçi sai ng∆∞·ªùi d√πng m·ªôt c√°ch r√µ r√†ng (v√≠ d·ª•: context l√† 'User gender: male' nh∆∞ng chatbot g·ªçi l√† 'ch·ªã').\n",
    "    - Ph·∫°t nh·∫π h∆°n: N·∫øu chatbot d√πng 'anh/ch·ªã' trong tr∆∞·ªùng h·ª£p c√≥ th·ªÉ suy lu·∫≠n gi·ªõi t√≠nh t·ª´ input nh∆∞ng kh√¥ng r√µ r√†ng 100%.\n",
    "    - Xem x√©t to√†n b·ªô cu·ªôc h·ªôi tho·∫°i ƒë·ªÉ ƒë√°nh gi√° t√≠nh nh·∫•t qu√°n.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # ƒê·ªÉ ph√¢n t√≠ch input c·ªßa user (v√≠ d·ª•: \"anh mu·ªën h·ªèi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # ƒê·ªÉ ph√¢n t√≠ch output c·ªßa model\n",
    "        LLMTestCaseParams.CONTEXT,        # N·∫øu th√¥ng tin `User gender` ƒë∆∞·ª£c truy·ªÅn qua context cho m·ªói l∆∞·ª£t\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anh mu·ªën h·ªèi c√°ch tra c·ª©u v·ªÅ h√≥a ƒë∆°n ƒë√£ mua h√†ng t·∫°i FPT Shop?\n",
      "User gender: male\n",
      "N·∫øu h√≥a ƒë∆°n ƒë√≥ mua h∆°n 1 nƒÉm r·ªìi th√¨ c√≥ t√¨m l·∫°i ƒë∆∞·ª£c kh√¥ng shop?\n",
      "User gender: male\n"
     ]
    }
   ],
   "source": [
    "tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    print(turn.input)\n",
    "    # turn list to str\n",
    "    turn_str = \"\"\n",
    "    for t in turn.context:\n",
    "        turn_str += t\n",
    "    print(turn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-165e-7c72-bfd0-d513b251ee06\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 12\n",
      "faq id : 16\n",
      "faq id : 62\n",
      "faq id : 18\n",
      "2025-06-01 12:07:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: f6eb87ad-616a-4b58-a7e3-126f60c8f886 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='D·∫° ch√†o anh. Anh c√≥ th·ªÉ tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i FPT Shop [t·∫°i ƒë√¢y](https://hddt.fptshop.com.vn/). N·∫øu anh c·∫ßn th√™m th√¥ng tin ho·∫∑c h·ªó tr·ª£ kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©.'\n",
      "D·∫° ch√†o anh. Anh c√≥ th·ªÉ tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i FPT Shop [t·∫°i ƒë√¢y](https://hddt.fptshop.com.vn/). N·∫øu anh c·∫ßn th√™m th√¥ng tin ho·∫∑c h·ªó tr·ª£ kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©.\n",
      "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-3ff1-7050-806a-181e9b2ba4bb\n",
      "2025-06-01 12:08:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:08:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 79\n",
      "2025-06-01 12:08:08 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: a598641d-6bae-4686-bf42-a34df626c189 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='D·∫° th∆∞a anh, theo quy ƒë·ªãnh c·ªßa FPT Shop, h√≥a ƒë∆°n mua h√†ng s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa c·ª≠a h√†ng trong v√≤ng 1 nƒÉm k·ªÉ t·ª´ ng√†y mua. Sau th·ªùi gian n√†y, h√≥a ƒë∆°n s·∫Ω kh√¥ng c√≤n kh·∫£ nƒÉng truy xu·∫•t. N·∫øu anh c·∫ßn h·ªó tr·ª£ th√™m th√¥ng tin v·ªÅ s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©. FPT Shop hi·ªán c√≥ nhi·ªÅu lo·∫°i s·∫£n ph·∫©m c√¥ng ngh·ªá nh∆∞ ƒëi·ªán tho·∫°i, laptop, m√°y t√≠nh b·∫£ng,... r·∫•t ƒëa d·∫°ng ·∫°.'\n",
      "D·∫° th∆∞a anh, theo quy ƒë·ªãnh c·ªßa FPT Shop, h√≥a ƒë∆°n mua h√†ng s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa c·ª≠a h√†ng trong v√≤ng 1 nƒÉm k·ªÉ t·ª´ ng√†y mua. Sau th·ªùi gian n√†y, h√≥a ƒë∆°n s·∫Ω kh√¥ng c√≤n kh·∫£ nƒÉng truy xu·∫•t. N·∫øu anh c·∫ßn h·ªó tr·ª£ th√™m th√¥ng tin v·ªÅ s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©. FPT Shop hi·ªán c√≥ nhi·ªÅu lo·∫°i s·∫£n ph·∫©m c√¥ng ngh·ªá nh∆∞ ƒëi·ªán tho·∫°i, laptop, m√°y t√≠nh b·∫£ng,... r·∫•t ƒëa d·∫°ng ·∫°.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for turn in tc.turns:\n",
    "    turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context))\n",
    "    print(turn.actual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f6e08653f499e9f750202fd521a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The chatbot consistently uses 'em' for self-reference and addresses the male user as 'anh' in both turns, matching the user gender in context. The form of address remains consistent and respectful throughout the conversation.\n"
     ]
    }
   ],
   "source": [
    "# danh gia rieng le 1 testcase\n",
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''function to get_actual_answer for all testcase'''\n",
    "def get_actual_answer_for_all_testcase(deepeval_test_cases,gen_answer_model):\n",
    "    for conversational_test_case in deepeval_test_cases:\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "\n",
    "def eval_tc(_testcases,_metrics,iter_checkpoint):\n",
    "    evaluation_results = evaluate(\n",
    "        test_cases=_testcases,\n",
    "        metrics=_metrics,\n",
    "    )\n",
    "    # ƒëi·ªÉm s·ªë c·ªßa metric ƒë∆∞·ª£c l∆∞u trong m·ªói ƒë·ªëi t∆∞·ª£ng test case sau khi evaluate\n",
    "    score = 0\n",
    "    for result in evaluation_results: # evaluate() tr·∫£ v·ªÅ list c√°c test cases ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t\n",
    "        print(f\"Test Case ID: {result.id if result.id else 'N/A'}\") # ConversationalTestCase c√≥ th·ªÉ kh√¥ng c√≥ id tr·ª´ khi b·∫°n set\n",
    "        for metric_result in result.metrics: # M·ªói test case c√≥ th·ªÉ c√≥ nhi·ªÅu metric\n",
    "            if metric_result.name == pronoun_consistency_metric.name:\n",
    "                print(f\"  Metric: {metric_result.name}\")\n",
    "                print(f\"  Score: {metric_result.score}\")\n",
    "                if metric_result.reason: \n",
    "                    print(f\"  Reason: {metric_result.reason[:300]}...\") # In m·ªôt ph·∫ßn l√Ω do\n",
    "                print(\"-\" * 20)\n",
    "                score += metric_result.score\n",
    "    mean_score = score/len(evaluation_results)\n",
    "    print(f\"Mean score: {mean_score}\")\n",
    "            \n",
    "    # get the mean score of all testcase\n",
    "    \n",
    "    #mean_score = evaluation_results.score.mean()\n",
    "    # save result to file\n",
    "    with open(f\"evaluation_results_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(evaluation_results, f)\n",
    "        json.dump(mean_score, f)\n",
    "\n",
    "\n",
    "\"\"\"Thay vi chi d√πng checkpoint cuoi c·ªßa fine-tuned model , d√πng to√†n b·ªô checkpoint ƒë·ªÉ ƒë√°nh gi√°\"\"\"\n",
    "checkpoint_lst = [\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6dn4:ckpt-step-50\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6ShS:ckpt-step-100\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao7Wp2\"]\n",
    "def eval_all_checkpoint(deepeval_test_cases,checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model  in enumerate(checkpoint_lst):\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        model = checkpoint_model\n",
    "        get_actual_answer_for_all_testcase(deepeval_test_cases,model)\n",
    "        # evaluate\n",
    "        eval_tc(deepeval_test_cases,[pronoun_consistency_metric],iter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danh gia toan bo testcase\n",
    "eval_all_checkpoint(deepeval_test_cases,checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
