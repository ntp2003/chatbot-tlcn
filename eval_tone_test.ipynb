{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.metrics import ConversationalGEval\n",
    "\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "import deepeval.models.llms.openai_model as deepeval_models\n",
    "from deepeval import evaluate\n",
    "gpt_41_mini = deepeval_models.GPTModel(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    timeout=60,\n",
    "    #_openai_api_key=\"sk-BJpqmcWfn3O9bvr2eryf6Uyf1m7VpSQpL7cNxGGlZccRrfA1\",\n",
    "    #base_url=\"https://open.keyai.shop/v1\"\n",
    ")\n",
    "json_file = 'conversation_tone.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deepeval.test_case.llm_test_case import LLMTestCase\n",
    "from deepeval.test_case.conversational_test_case import ConversationalTestCase\n",
    "from typing import List\n",
    "'''load testcase (with actual_output generated or not) from json file'''\n",
    "def load_testcase_from_json(json_file) -> List[ConversationalTestCase]:\n",
    "    try:\n",
    "            #parsed_data = json.loads(generated_json_string)\n",
    "            # load data from json file\n",
    "            with open( json_file,\"r\") as f:\n",
    "                parsed_data = json.load(f)\n",
    "            deepeval_test_cases = []\n",
    "            for conv_data in parsed_data:\n",
    "                llm_turns = []\n",
    "                for turn_data in conv_data.get(\"turns\", []):\n",
    "                    user_input = turn_data.get(\"user_input\")\n",
    "                    gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                    actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  \n",
    "\n",
    "                    current_context = []\n",
    "                    if gender_context_val and gender_context_val != \"null\":  #Ki·ªÉm tra null d∆∞·ªõi d·∫°ng chu·ªói\n",
    "                        current_context.append(f\"User gender: {gender_context_val}\")\n",
    "                \n",
    "                    if user_input:  #Ch·ªâ th√™m turn n·∫øu c√≥ user_input\n",
    "                        llm_turns.append(\n",
    "                            LLMTestCase(\n",
    "                                input=user_input,\n",
    "                                actual_output=actual_output_placeholder, # S·∫Ω ƒë∆∞·ª£c ƒëi·ªÅn sau\n",
    "                                context=current_context if current_context else None  # DeepEval c√≥ th·ªÉ mu·ªën None n·∫øu context r·ªóng\n",
    "                            )\n",
    "                        )\n",
    "                if llm_turns:  #Ch·ªâ th√™m ConversationalTestCase n·∫øu c√≥ turns h·ª£p l·ªá\n",
    "                    deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ d√πng messages\n",
    "                                                                                        #(ho·∫∑c `turns=llm_turns` cho phi√™n b·∫£n c≈© h∆°n)\n",
    "\n",
    "            print(f\"ƒê√£ load th√†nh c√¥ng {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "            return deepeval_test_cases\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"L·ªói gi·∫£i m√£ JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "import service.openai as openai_service\n",
    "from openai.types.chat_model import ChatModel\n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str,gen_answer_model:ChatModel=None) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "    # Add gender context to the conversation\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + gender_context},\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n",
    "\n",
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str\n",
    "\n",
    "\n",
    "def get_actual_answer_for_all_testcase_without_conversation_history(json_file:str,gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    #deepeval_test_cases = load_testcase_from_json(json_file) # load test case with actual_output werent generated\n",
    "    '''\n",
    "    get_actual_answer for all testcase\n",
    "    iter_checkpoint is the index of the checkpoint fine-tuned model\n",
    "    gen_answer_model is the fine-tuned model to use for generating responses\n",
    "    '''\n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    for conversational_test_case in conversations:\n",
    "        processed_turns = []\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "\n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conversational_test_case.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        '''write to json file'''\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n",
    "\n",
    "def get_actual_answer_with_conversation_history(json_file: str, gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    \n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "\n",
    "    for conv in conversations:\n",
    "        processed_turns = []\n",
    "        turns = conv.turns\n",
    "        user = create_user(\n",
    "            CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "        )\n",
    "        thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "        # Initialize conversation history with system message\n",
    "        history = [\n",
    "            {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + turns[0][\"user_gender_context\"]}\n",
    "        ]\n",
    "        \n",
    "        for turn in turns:\n",
    "            # Add user input to history\n",
    "            history.append({\"role\": \"user\", \"content\": turn[\"user_input\"]})\n",
    "            \n",
    "            # Set the model for this conversation\n",
    "            #openai_service._fine_tuning_model = gen_answer_model\n",
    "            \n",
    "            # Generate bot response using accumulated history\n",
    "            bot_response = gen_answer(\n",
    "                #thread_id=uuid4(),  # Generate new thread ID for each turn\n",
    "                thread_id=thread.id,\n",
    "                history=history,\n",
    "                #user_id=uuid4(),  # Generate new user ID for each turn\n",
    "                user_id=user.id,\n",
    "            )\n",
    "            turn.actual_output = bot_response\n",
    "            # Add bot response to history for next turn\n",
    "            history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "            \n",
    "            # Store processed turn\n",
    "            \n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "        \n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conv.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"{json_file}_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' function to get actual_output for all testcase and write to json file'''\n",
    "'''\n",
    "def get_actual_output_for_all_testcase(deepeval_test_cases,gen_answer_model,iter_checkpoint):\n",
    "    for conversational_test_case in deepeval_test_cases:\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "        with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "            json.dump(conversational_test_case, f)\n",
    "'''            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"ƒê√°nh gi√° kh·∫£ nƒÉng c·ªßa chatbot trong vi·ªác s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† nh·∫•t qu√°n trong su·ªët cu·ªôc h·ªôi tho·∫°i. C·ª• th·ªÉ:\n",
    "    1. Chatbot (assistant) trong 'actual_output' ph·∫£i LU√îN LU√îN t·ª± x∆∞ng l√† 'em'.  V√≠ d·ª•: 'd·∫° em ch√†o anh', 'em c√≥ th·ªÉ gi√∫p g√¨ ·∫°'. KH√îNG ƒë∆∞·ª£c d√πng 't√¥i', 'm√¨nh'\n",
    "    2. C√°ch chatbot g·ªçi ng∆∞·ªùi d√πng (user) ph·∫£i d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ho·∫∑c c√°ch ng∆∞·ªùi d√πng t·ª± x∆∞ng:\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'male' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'anh' nh∆∞ 'anh mu·ªën h·ªèi...', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh'.\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'female' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch·ªã' nh∆∞ 'ch·ªã mu·ªën h·ªèi...', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch·ªã'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch√∫', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch√∫' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'b√°c', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'b√°c' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'c√¥', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'c√¥' v√† t·ª± x∆∞ng 'ch√°u'. \n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'unknown' ho·∫∑c kh√¥ng ƒë∆∞·ª£c cung c·∫•p, v√† ng∆∞·ªùi d√πng kh√¥ng t·ª± x∆∞ng theo m·ªôt ƒë·∫°i t·ª´ c·ª• th·ªÉ n√†o ·ªü tr√™n, chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh/ch·ªã'.\n",
    "\n",
    "    3. T√≠nh nh·∫•t qu√°n: Chatbot ph·∫£i duy tr√¨ c√°ch x∆∞ng h√¥ ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p v·ªõi ng∆∞·ªùi d√πng m·ªôt c√°ch nh·∫•t qu√°n trong c√°c l∆∞·ª£t tr·∫£ l·ªùi ti·∫øp theo trong c√πng m·ªôt cu·ªôc h·ªôi tho·∫°i, tr·ª´ khi c√≥ th√¥ng tin m·ªõi r√µ r√†ng thay ƒë·ªïi c√°ch x∆∞ng h√¥.\n",
    "    4. Kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng c√°c c√°ch x∆∞ng h√¥ kh√¥ng ph√π h·ª£p ho·∫∑c thi·∫øu t√¥n tr·ªçng.\n",
    "      H∆Ø·ªöNG D·∫™N CH·∫§M ƒêI·ªÇM:\n",
    "    - ƒêi·ªÉm 1.0: Tu√¢n th·ªß ho√†n h·∫£o t·∫•t c·∫£ c√°c quy t·∫Øc tr√™n trong m·ªçi l∆∞·ª£t c·ªßa h·ªôi tho·∫°i.\n",
    "    - Ph·∫°t n·∫∑ng (ƒëi·ªÉm g·∫ßn 0): N·∫øu chatbot t·ª± x∆∞ng sai (v√≠ d·ª•: x∆∞ng 't√¥i' thay v√¨ 'em').\n",
    "    - Ph·∫°t n·∫∑ng (ƒëi·ªÉm g·∫ßn 0): N·∫øu chatbot g·ªçi sai ng∆∞·ªùi d√πng m·ªôt c√°ch r√µ r√†ng (v√≠ d·ª•: context l√† 'User gender: male' nh∆∞ng chatbot g·ªçi l√† 'ch·ªã').\n",
    "    - Xem x√©t to√†n b·ªô cu·ªôc h·ªôi tho·∫°i ƒë·ªÉ ƒë√°nh gi√° t√≠nh nh·∫•t qu√°n.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # ƒê·ªÉ ph√¢n t√≠ch input c·ªßa user (v√≠ d·ª•: \"anh mu·ªën h·ªèi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # ƒê·ªÉ ph√¢n t√≠ch output c·ªßa model\n",
    "        LLMTestCaseParams.CONTEXT,        # N·∫øu th√¥ng tin `User gender` ƒë∆∞·ª£c truy·ªÅn qua context cho m·ªói l∆∞·ª£t\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d758168db9bf4a5586b1b3b754632ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c0b-d397-7fe3-bb4c-7b37d5647ce2\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c0b-d397-7fe3-bb4c-7b37d5647ce2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 15:11:06 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c0b-e656-7f83-b889-b13fe8f44c27\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c0b-e656-7f83-b889-b13fe8f44c27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 15:11:09 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40709943317536884 The chatbot consistently addresses the user as 'ch·ªã' despite unknown user gender, which is acceptable but not ideal. However, the chatbot fails to use the required self-reference 'em' or 'ch√°u' and instead uses no self-reference at all, violating step 1. The forms of address are consistent and not disrespectful.\n"
     ]
    }
   ],
   "source": [
    "test_case = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"Ch·ªã mu·ªën h·ªèi c√°ch tra c·ª©u ƒëi·ªÉm mua h√†ng ƒë√£ t√≠ch ƒë∆∞·ª£c t·∫°i FPT Shop .\",\n",
    "            actual_output= \" Ch·ªã c√≥ th·ªÉ th·ª±c hi·ªán tra c·ª©u ƒëi·ªÉm t√≠ch [t·∫°i ƒë√¢y](https://fptshop.com.vn/tai-khoan/lich-su-tich-diem) b·∫±ng c√°ch ƒëƒÉng nh·∫≠p s·ªë ƒëi·ªán tho·∫°i mua h√†ng c·ªßa ch·ªã.\",\n",
    "            # Kh√¥ng c·∫ßn context n·∫øu input ƒë√£ ƒë·ªß r√µ, nh∆∞ng criteria c·∫ßn x·ª≠ l√Ω ƒë∆∞·ª£c\n",
    "            # context=[\"User gender: female\"] # C√≥ th·ªÉ th√™m n·∫øu mu·ªën r√µ r√†ng h∆°n\n",
    "            context=[\"User gender: unknown\"]\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"V·∫≠y c√≤n tra c·ª©u v·ªÅ th√¥ng tin tr√∫ng th∆∞·ªüng c·ªßa FPT Shop khi tham gia c√°c ch∆∞∆°ng tr√¨nh mini game?\",\n",
    "            actual_output=\"Ch·ªã c√≥ th·ªÉ th·ª±c hi·ªán tra c·ª©u [t·∫°i ƒë√¢y](https://fptshop.com.vn/khuyen-mai/thong-tin-trao-thuong)\",\n",
    "            context=[\"User gender: unknown\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "pronoun_consistency_metric.measure(test_case)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9405cbf4722f4c09be72d85799fd9ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c6a-1820-7031-8442-19dcd178b626\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c6a-1820-7031-8442-19dcd178b626\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:54:03 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c6a-26b2-7680-a1a1-4bb3b6c56b86\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c6a-26b2-7680-a1a1-4bb3b6c56b86\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:54:06 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7731471304702164 The chatbot consistently uses 'em' for self-reference and addresses the user as 'Ch·ªã' based on the user's input, which is appropriate. However, the user gender is unknown in context, so the chatbot's choice to use 'Ch·ªã' may not fully align with the evaluation step requiring correct addressing based on user gender or self-reference. Pronoun usage is consistent and respectful throughout.\n"
     ]
    }
   ],
   "source": [
    "test_case1 = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"Ch·ªã mu·ªën h·ªèi c√°ch tra c·ª©u ƒëi·ªÉm mua h√†ng ƒë√£ t√≠ch ƒë∆∞·ª£c t·∫°i FPT Shop .\",\n",
    "            actual_output= \" Ch·ªã c√≥ th·ªÉ th·ª±c hi·ªán tra c·ª©u ƒëi·ªÉm t√≠ch [t·∫°i ƒë√¢y](https://fptshop.com.vn/tai-khoan/lich-su-tich-diem) b·∫±ng c√°ch ƒëƒÉng nh·∫≠p s·ªë ƒëi·ªán tho·∫°i mua h√†ng c·ªßa ch·ªã.Ch·ªã c·∫ßn em h·ªó tr·ª£ g√¨ n·ªØa kh√¥ng ·∫°?\",\n",
    "            # Kh√¥ng c·∫ßn context n·∫øu input ƒë√£ ƒë·ªß r√µ, nh∆∞ng criteria c·∫ßn x·ª≠ l√Ω ƒë∆∞·ª£c\n",
    "            # context=[\"User gender: female\"] # C√≥ th·ªÉ th√™m n·∫øu mu·ªën r√µ r√†ng h∆°n\n",
    "            context=[\"User gender: unknown\"]\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"V·∫≠y c√≤n tra c·ª©u v·ªÅ th√¥ng tin tr√∫ng th∆∞·ªüng c·ªßa FPT Shop khi tham gia c√°c ch∆∞∆°ng tr√¨nh mini game?\",\n",
    "            actual_output=\"Ch·ªã c√≥ th·ªÉ th·ª±c hi·ªán tra c·ª©u [t·∫°i ƒë√¢y](https://fptshop.com.vn/khuyen-mai/thong-tin-trao-thuong). Ch·ªã c·∫ßn em h·ªó tr·ª£ g√¨ n·ªØa kh√¥ng ·∫°?\",\n",
    "            context=[\"User gender: unknown\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "pronoun_consistency_metric.measure(test_case1)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anh mu·ªën h·ªèi c√°ch tra c·ª©u v·ªÅ h√≥a ƒë∆°n ƒë√£ mua h√†ng t·∫°i FPT Shop?\n",
      "User gender: male\n",
      "N·∫øu h√≥a ƒë∆°n ƒë√≥ mua h∆°n 1 nƒÉm r·ªìi th√¨ c√≥ t√¨m l·∫°i ƒë∆∞·ª£c kh√¥ng shop?\n",
      "User gender: male\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    print(turn.input)\n",
    "    # turn list to str\n",
    "    turn_str = \"\"\n",
    "    for t in turn.context:\n",
    "        turn_str += t\n",
    "    print(turn_str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-165e-7c72-bfd0-d513b251ee06\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 12\n",
      "faq id : 16\n",
      "faq id : 62\n",
      "faq id : 18\n",
      "2025-06-01 12:07:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: f6eb87ad-616a-4b58-a7e3-126f60c8f886 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='D·∫° ch√†o anh. Anh c√≥ th·ªÉ tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i FPT Shop [t·∫°i ƒë√¢y](https://hddt.fptshop.com.vn/). N·∫øu anh c·∫ßn th√™m th√¥ng tin ho·∫∑c h·ªó tr·ª£ kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©.'\n",
      "D·∫° ch√†o anh. Anh c√≥ th·ªÉ tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i FPT Shop [t·∫°i ƒë√¢y](https://hddt.fptshop.com.vn/). N·∫øu anh c·∫ßn th√™m th√¥ng tin ho·∫∑c h·ªó tr·ª£ kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©.\n",
      "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-3ff1-7050-806a-181e9b2ba4bb\n",
      "2025-06-01 12:08:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:08:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 79\n",
      "2025-06-01 12:08:08 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: a598641d-6bae-4686-bf42-a34df626c189 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='D·∫° th∆∞a anh, theo quy ƒë·ªãnh c·ªßa FPT Shop, h√≥a ƒë∆°n mua h√†ng s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa c·ª≠a h√†ng trong v√≤ng 1 nƒÉm k·ªÉ t·ª´ ng√†y mua. Sau th·ªùi gian n√†y, h√≥a ƒë∆°n s·∫Ω kh√¥ng c√≤n kh·∫£ nƒÉng truy xu·∫•t. N·∫øu anh c·∫ßn h·ªó tr·ª£ th√™m th√¥ng tin v·ªÅ s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©. FPT Shop hi·ªán c√≥ nhi·ªÅu lo·∫°i s·∫£n ph·∫©m c√¥ng ngh·ªá nh∆∞ ƒëi·ªán tho·∫°i, laptop, m√°y t√≠nh b·∫£ng,... r·∫•t ƒëa d·∫°ng ·∫°.'\n",
      "D·∫° th∆∞a anh, theo quy ƒë·ªãnh c·ªßa FPT Shop, h√≥a ƒë∆°n mua h√†ng s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa c·ª≠a h√†ng trong v√≤ng 1 nƒÉm k·ªÉ t·ª´ ng√†y mua. Sau th·ªùi gian n√†y, h√≥a ƒë∆°n s·∫Ω kh√¥ng c√≤n kh·∫£ nƒÉng truy xu·∫•t. N·∫øu anh c·∫ßn h·ªó tr·ª£ th√™m th√¥ng tin v·ªÅ s·∫£n ph·∫©m ho·∫∑c d·ªãch v·ª• kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©. FPT Shop hi·ªán c√≥ nhi·ªÅu lo·∫°i s·∫£n ph·∫©m c√¥ng ngh·ªá nh∆∞ ƒëi·ªán tho·∫°i, laptop, m√°y t√≠nh b·∫£ng,... r·∫•t ƒëa d·∫°ng ·∫°.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "for turn in tc.turns:\n",
    "    turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context))\n",
    "    print(turn.actual_output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f6e08653f499e9f750202fd521a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The chatbot consistently uses 'em' for self-reference and addresses the male user as 'anh' in both turns, matching the user gender in context. The form of address remains consistent and respectful throughout the conversation.\n"
     ]
    }
   ],
   "source": [
    "# danh gia rieng le 1 testcase\n",
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "'''save the output of get_actual_answer for all testcase to json file for each model'''\n",
    "\n",
    "\n",
    "def eval_tc(_testcases,_metrics,iter_checkpoint):\n",
    "    evaluation_results = evaluate(\n",
    "        test_cases=_testcases,\n",
    "        metrics=_metrics,\n",
    "    )\n",
    "    # ƒëi·ªÉm s·ªë c·ªßa metric ƒë∆∞·ª£c l∆∞u trong m·ªói ƒë·ªëi t∆∞·ª£ng test case sau khi evaluate\n",
    "    score = 0\n",
    "    for result in evaluation_results: # evaluate() tr·∫£ v·ªÅ list c√°c test cases ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t\n",
    "        print(f\"Test Case ID: {result.id if result.id else 'N/A'}\") # ConversationalTestCase c√≥ th·ªÉ kh√¥ng c√≥ id tr·ª´ khi b·∫°n set\n",
    "        for metric_result in result.metrics: # M·ªói test case c√≥ th·ªÉ c√≥ nhi·ªÅu metric\n",
    "            if metric_result.name == pronoun_consistency_metric.name:\n",
    "                print(f\"  Metric: {metric_result.name}\")\n",
    "                print(f\"  Score: {metric_result.score}\")\n",
    "                if metric_result.reason: \n",
    "                    print(f\"  Reason: {metric_result.reason[:300]}...\") # In m·ªôt ph·∫ßn l√Ω do\n",
    "                print(\"-\" * 20)\n",
    "                score += metric_result.score\n",
    "    mean_score = score/len(evaluation_results)\n",
    "    print(f\"Mean score: {mean_score}\")\n",
    "            \n",
    "    \n",
    "    # get the mean score of all testcase\n",
    "    \n",
    "    #mean_score = evaluation_results.score.mean()\n",
    "    # save result to file\n",
    "    with open(f\"evaluation_results_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(evaluation_results, f)\n",
    "        json.dump(mean_score, f)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_lst = [\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6dn4:ckpt-step-50\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6ShS:ckpt-step-100\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao7Wp2\"]\n",
    "\n",
    "def get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        model = checkpoint_model\n",
    "\n",
    "        # 1 trong 2 cach de luu actual_output vao json file moi\n",
    "        #get_actual_answer_for_all_testcase_without_conversation_history(json_file,model,iter_checkpoint)\n",
    "        get_actual_answer_with_conversation_history(json_file,model,iter_checkpoint)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thay vi chi d√πng checkpoint cuoi c·ªßa fine-tuned model , d√πng to√†n b·ªô checkpoint ƒë·ªÉ ƒë√°nh gi√°\"\"\"\n",
    "def eval_all_checkpoint(deepeval_test_cases,checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        load_testcase_from_json(f'{json_file}_{iter_checkpoint}.json')\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        # evaluate\n",
    "        eval_tc(deepeval_test_cases,[pronoun_consistency_metric],iter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danh gia toan bo testcase\n",
    "#eval_all_checkpoint(deepeval_test_cases,checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
