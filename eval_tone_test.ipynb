{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.metrics import ConversationalGEval\n",
    "\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "import deepeval.models.llms.openai_model as deepeval_models\n",
    "from deepeval import evaluate\n",
    "gpt_41_mini = deepeval_models.GPTModel(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    timeout=60,\n",
    "    #_openai_api_key=\"sk-BJpqmcWfn3O9bvr2eryf6Uyf1m7VpSQpL7cNxGGlZccRrfA1\",\n",
    "    #base_url=\"https://open.keyai.shop/v1\"\n",
    ")\n",
    "json_file = 'conversation_tone.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deepeval.test_case.llm_test_case import LLMTestCase\n",
    "from deepeval.test_case.conversational_test_case import ConversationalTestCase\n",
    "from typing import List\n",
    "'''load testcase (with actual_output generated or not) from json file'''\n",
    "def load_testcase_from_json(json_file) -> List[ConversationalTestCase]:\n",
    "    try:\n",
    "            #parsed_data = json.loads(generated_json_string)\n",
    "            # load data from json file\n",
    "            with open( json_file,\"r\") as f:\n",
    "                parsed_data = json.load(f)\n",
    "            deepeval_test_cases = []\n",
    "            for conv_data in parsed_data:\n",
    "                llm_turns = []\n",
    "                for turn_data in conv_data.get(\"turns\", []):\n",
    "                    user_input = turn_data.get(\"user_input\")\n",
    "                    gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                    actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  \n",
    "\n",
    "                    current_context = []\n",
    "                    if gender_context_val and gender_context_val != \"null\":  #Kiểm tra null dưới dạng chuỗi\n",
    "                        current_context.append(f\"User gender: {gender_context_val}\")\n",
    "                \n",
    "                    if user_input:  #Chỉ thêm turn nếu có user_input\n",
    "                        llm_turns.append(\n",
    "                            LLMTestCase(\n",
    "                                input=user_input,\n",
    "                                actual_output=actual_output_placeholder, # Sẽ được điền sau\n",
    "                                context=current_context if current_context else None  # DeepEval có thể muốn None nếu context rỗng\n",
    "                            )\n",
    "                        )\n",
    "                if llm_turns:  #Chỉ thêm ConversationalTestCase nếu có turns hợp lệ\n",
    "                    deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ dùng messages\n",
    "                                                                                        #(hoặc `turns=llm_turns` cho phiên bản cũ hơn)\n",
    "\n",
    "            print(f\"Đã load thành công {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "            return deepeval_test_cases\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Lỗi giải mã JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định khi xử lý: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "import service.openai as openai_service\n",
    "from openai.types.chat_model import ChatModel\n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str,gen_answer_model:ChatModel=None) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "    # Add gender context to the conversation\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + gender_context},\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n",
    "\n",
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str\n",
    "\n",
    "\n",
    "def get_actual_answer_for_all_testcase_without_conversation_history(json_file:str,gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    #deepeval_test_cases = load_testcase_from_json(json_file) # load test case with actual_output werent generated\n",
    "    '''\n",
    "    get_actual_answer for all testcase\n",
    "    iter_checkpoint is the index of the checkpoint fine-tuned model\n",
    "    gen_answer_model is the fine-tuned model to use for generating responses\n",
    "    '''\n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    for conversational_test_case in conversations:\n",
    "        processed_turns = []\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "\n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conversational_test_case.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        '''write to json file'''\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n",
    "\n",
    "def get_actual_answer_with_conversation_history(json_file: str, gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    \n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "\n",
    "    for conv in conversations:\n",
    "        processed_turns = []\n",
    "        turns = conv.turns\n",
    "        user = create_user(\n",
    "            CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "        )\n",
    "        thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "        # Initialize conversation history with system message\n",
    "        history = [\n",
    "            {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + turns[0][\"user_gender_context\"]}\n",
    "        ]\n",
    "        \n",
    "        for turn in turns:\n",
    "            # Add user input to history\n",
    "            history.append({\"role\": \"user\", \"content\": turn[\"user_input\"]})\n",
    "            \n",
    "            # Set the model for this conversation\n",
    "            #openai_service._fine_tuning_model = gen_answer_model\n",
    "            \n",
    "            # Generate bot response using accumulated history\n",
    "            bot_response = gen_answer(\n",
    "                #thread_id=uuid4(),  # Generate new thread ID for each turn\n",
    "                thread_id=thread.id,\n",
    "                history=history,\n",
    "                #user_id=uuid4(),  # Generate new user ID for each turn\n",
    "                user_id=user.id,\n",
    "            )\n",
    "            turn.actual_output = bot_response\n",
    "            # Add bot response to history for next turn\n",
    "            history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "            \n",
    "            # Store processed turn\n",
    "            \n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "        \n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conv.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"{json_file}_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' function to get actual_output for all testcase and write to json file'''\n",
    "'''\n",
    "def get_actual_output_for_all_testcase(deepeval_test_cases,gen_answer_model,iter_checkpoint):\n",
    "    for conversational_test_case in deepeval_test_cases:\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "        with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "            json.dump(conversational_test_case, f)\n",
    "'''            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"Đánh giá khả năng của chatbot trong việc sử dụng đại từ nhân xưng tiếng Việt một cách chính xác và nhất quán trong suốt cuộc hội thoại. Cụ thể:\n",
    "    1. Chatbot (assistant) trong 'actual_output' phải LUÔN LUÔN tự xưng là 'em'.  Ví dụ: 'dạ em chào anh', 'em có thể giúp gì ạ'. KHÔNG được dùng 'tôi', 'mình'\n",
    "    2. Cách chatbot gọi người dùng (user) phải dựa trên thông tin được cung cấp hoặc cách người dùng tự xưng:\n",
    "        - Nếu 'User gender' được cung cấp là 'male' hoặc người dùng tự xưng là 'anh' như 'anh muốn hỏi...', chatbot phải gọi người dùng là 'anh'.\n",
    "        - Nếu 'User gender' được cung cấp là 'female' hoặc người dùng tự xưng là 'chị' như 'chị muốn hỏi...', chatbot phải gọi người dùng là 'chị'.\n",
    "        - Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'bác', chatbot phải gọi người dùng là 'bác' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'cô', chatbot phải gọi người dùng là 'cô' và tự xưng 'cháu'. \n",
    "        - Nếu 'User gender' được cung cấp là 'unknown' hoặc không được cung cấp, và người dùng không tự xưng theo một đại từ cụ thể nào ở trên, chatbot phải gọi người dùng là 'anh/chị'.\n",
    "\n",
    "    3. Tính nhất quán: Chatbot phải duy trì cách xưng hô đã được thiết lập với người dùng một cách nhất quán trong các lượt trả lời tiếp theo trong cùng một cuộc hội thoại, trừ khi có thông tin mới rõ ràng thay đổi cách xưng hô.\n",
    "    4. Không được sử dụng các cách xưng hô không phù hợp hoặc thiếu tôn trọng.\n",
    "      HƯỚNG DẪN CHẤM ĐIỂM:\n",
    "    - Điểm 1.0: Tuân thủ hoàn hảo tất cả các quy tắc trên trong mọi lượt của hội thoại.\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot tự xưng sai (ví dụ: xưng 'tôi' thay vì 'em').\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot gọi sai người dùng một cách rõ ràng (ví dụ: context là 'User gender: male' nhưng chatbot gọi là 'chị').\n",
    "    - Xem xét toàn bộ cuộc hội thoại để đánh giá tính nhất quán.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # Để phân tích input của user (ví dụ: \"anh muốn hỏi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # Để phân tích output của model\n",
    "        LLMTestCaseParams.CONTEXT,        # Nếu thông tin `User gender` được truyền qua context cho mỗi lượt\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d758168db9bf4a5586b1b3b754632ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c0b-d397-7fe3-bb4c-7b37d5647ce2\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c0b-d397-7fe3-bb4c-7b37d5647ce2\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 15:11:06 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c0b-e656-7f83-b889-b13fe8f44c27\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c0b-e656-7f83-b889-b13fe8f44c27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 15:11:09 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40709943317536884 The chatbot consistently addresses the user as 'chị' despite unknown user gender, which is acceptable but not ideal. However, the chatbot fails to use the required self-reference 'em' or 'cháu' and instead uses no self-reference at all, violating step 1. The forms of address are consistent and not disrespectful.\n"
     ]
    }
   ],
   "source": [
    "test_case = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"Chị muốn hỏi cách tra cứu điểm mua hàng đã tích được tại FPT Shop .\",\n",
    "            actual_output= \" Chị có thể thực hiện tra cứu điểm tích [tại đây](https://fptshop.com.vn/tai-khoan/lich-su-tich-diem) bằng cách đăng nhập số điện thoại mua hàng của chị.\",\n",
    "            # Không cần context nếu input đã đủ rõ, nhưng criteria cần xử lý được\n",
    "            # context=[\"User gender: female\"] # Có thể thêm nếu muốn rõ ràng hơn\n",
    "            context=[\"User gender: unknown\"]\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"Vậy còn tra cứu về thông tin trúng thưởng của FPT Shop khi tham gia các chương trình mini game?\",\n",
    "            actual_output=\"Chị có thể thực hiện tra cứu [tại đây](https://fptshop.com.vn/khuyen-mai/thong-tin-trao-thuong)\",\n",
    "            context=[\"User gender: unknown\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "pronoun_consistency_metric.measure(test_case)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9405cbf4722f4c09be72d85799fd9ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c6a-1820-7031-8442-19dcd178b626\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c6a-1820-7031-8442-19dcd178b626\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:54:03 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c6a-26b2-7680-a1a1-4bb3b6c56b86\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972c6a-26b2-7680-a1a1-4bb3b6c56b86\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 16:54:06 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7731471304702164 The chatbot consistently uses 'em' for self-reference and addresses the user as 'Chị' based on the user's input, which is appropriate. However, the user gender is unknown in context, so the chatbot's choice to use 'Chị' may not fully align with the evaluation step requiring correct addressing based on user gender or self-reference. Pronoun usage is consistent and respectful throughout.\n"
     ]
    }
   ],
   "source": [
    "test_case1 = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"Chị muốn hỏi cách tra cứu điểm mua hàng đã tích được tại FPT Shop .\",\n",
    "            actual_output= \" Chị có thể thực hiện tra cứu điểm tích [tại đây](https://fptshop.com.vn/tai-khoan/lich-su-tich-diem) bằng cách đăng nhập số điện thoại mua hàng của chị.Chị cần em hỗ trợ gì nữa không ạ?\",\n",
    "            # Không cần context nếu input đã đủ rõ, nhưng criteria cần xử lý được\n",
    "            # context=[\"User gender: female\"] # Có thể thêm nếu muốn rõ ràng hơn\n",
    "            context=[\"User gender: unknown\"]\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"Vậy còn tra cứu về thông tin trúng thưởng của FPT Shop khi tham gia các chương trình mini game?\",\n",
    "            actual_output=\"Chị có thể thực hiện tra cứu [tại đây](https://fptshop.com.vn/khuyen-mai/thong-tin-trao-thuong). Chị cần em hỗ trợ gì nữa không ạ?\",\n",
    "            context=[\"User gender: unknown\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "pronoun_consistency_metric.measure(test_case1)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anh muốn hỏi cách tra cứu về hóa đơn đã mua hàng tại FPT Shop?\n",
      "User gender: male\n",
      "Nếu hóa đơn đó mua hơn 1 năm rồi thì có tìm lại được không shop?\n",
      "User gender: male\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    print(turn.input)\n",
    "    # turn list to str\n",
    "    turn_str = \"\"\n",
    "    for t in turn.context:\n",
    "        turn_str += t\n",
    "    print(turn_str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-165e-7c72-bfd0-d513b251ee06\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 12\n",
      "faq id : 16\n",
      "faq id : 62\n",
      "faq id : 18\n",
      "2025-06-01 12:07:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: f6eb87ad-616a-4b58-a7e3-126f60c8f886 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='Dạ chào anh. Anh có thể tra cứu hóa đơn mua hàng tại FPT Shop [tại đây](https://hddt.fptshop.com.vn/). Nếu anh cần thêm thông tin hoặc hỗ trợ khác, đừng ngần ngại cho em biết nhé.'\n",
      "Dạ chào anh. Anh có thể tra cứu hóa đơn mua hàng tại FPT Shop [tại đây](https://hddt.fptshop.com.vn/). Nếu anh cần thêm thông tin hoặc hỗ trợ khác, đừng ngần ngại cho em biết nhé.\n",
      "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-3ff1-7050-806a-181e9b2ba4bb\n",
      "2025-06-01 12:08:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:08:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 79\n",
      "2025-06-01 12:08:08 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: a598641d-6bae-4686-bf42-a34df626c189 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='Dạ thưa anh, theo quy định của FPT Shop, hóa đơn mua hàng sẽ được lưu trữ trong hệ thống của cửa hàng trong vòng 1 năm kể từ ngày mua. Sau thời gian này, hóa đơn sẽ không còn khả năng truy xuất. Nếu anh cần hỗ trợ thêm thông tin về sản phẩm hoặc dịch vụ khác, đừng ngần ngại cho em biết nhé. FPT Shop hiện có nhiều loại sản phẩm công nghệ như điện thoại, laptop, máy tính bảng,... rất đa dạng ạ.'\n",
      "Dạ thưa anh, theo quy định của FPT Shop, hóa đơn mua hàng sẽ được lưu trữ trong hệ thống của cửa hàng trong vòng 1 năm kể từ ngày mua. Sau thời gian này, hóa đơn sẽ không còn khả năng truy xuất. Nếu anh cần hỗ trợ thêm thông tin về sản phẩm hoặc dịch vụ khác, đừng ngần ngại cho em biết nhé. FPT Shop hiện có nhiều loại sản phẩm công nghệ như điện thoại, laptop, máy tính bảng,... rất đa dạng ạ.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "for turn in tc.turns:\n",
    "    turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context))\n",
    "    print(turn.actual_output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f6e08653f499e9f750202fd521a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The chatbot consistently uses 'em' for self-reference and addresses the male user as 'anh' in both turns, matching the user gender in context. The form of address remains consistent and respectful throughout the conversation.\n"
     ]
    }
   ],
   "source": [
    "# danh gia rieng le 1 testcase\n",
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "'''save the output of get_actual_answer for all testcase to json file for each model'''\n",
    "\n",
    "\n",
    "def eval_tc(_testcases,_metrics,iter_checkpoint):\n",
    "    evaluation_results = evaluate(\n",
    "        test_cases=_testcases,\n",
    "        metrics=_metrics,\n",
    "    )\n",
    "    # điểm số của metric được lưu trong mỗi đối tượng test case sau khi evaluate\n",
    "    score = 0\n",
    "    for result in evaluation_results: # evaluate() trả về list các test cases đã được cập nhật\n",
    "        print(f\"Test Case ID: {result.id if result.id else 'N/A'}\") # ConversationalTestCase có thể không có id trừ khi bạn set\n",
    "        for metric_result in result.metrics: # Mỗi test case có thể có nhiều metric\n",
    "            if metric_result.name == pronoun_consistency_metric.name:\n",
    "                print(f\"  Metric: {metric_result.name}\")\n",
    "                print(f\"  Score: {metric_result.score}\")\n",
    "                if metric_result.reason: \n",
    "                    print(f\"  Reason: {metric_result.reason[:300]}...\") # In một phần lý do\n",
    "                print(\"-\" * 20)\n",
    "                score += metric_result.score\n",
    "    mean_score = score/len(evaluation_results)\n",
    "    print(f\"Mean score: {mean_score}\")\n",
    "            \n",
    "    \n",
    "    # get the mean score of all testcase\n",
    "    \n",
    "    #mean_score = evaluation_results.score.mean()\n",
    "    # save result to file\n",
    "    with open(f\"evaluation_results_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(evaluation_results, f)\n",
    "        json.dump(mean_score, f)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_lst = [\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6dn4:ckpt-step-50\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6ShS:ckpt-step-100\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao7Wp2\"]\n",
    "\n",
    "def get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        model = checkpoint_model\n",
    "\n",
    "        # 1 trong 2 cach de luu actual_output vao json file moi\n",
    "        #get_actual_answer_for_all_testcase_without_conversation_history(json_file,model,iter_checkpoint)\n",
    "        get_actual_answer_with_conversation_history(json_file,model,iter_checkpoint)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thay vi chi dùng checkpoint cuoi của fine-tuned model , dùng toàn bộ checkpoint để đánh giá\"\"\"\n",
    "def eval_all_checkpoint(deepeval_test_cases,checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        load_testcase_from_json(f'{json_file}_{iter_checkpoint}.json')\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        # evaluate\n",
    "        eval_tc(deepeval_test_cases,[pronoun_consistency_metric],iter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danh gia toan bo testcase\n",
    "#eval_all_checkpoint(deepeval_test_cases,checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
