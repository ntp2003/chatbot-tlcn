{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase, ConversationalTestCase\n",
    "from deepeval.synthesizer import Synthesizer\n",
    "from deepeval.dataset import Golden\n",
    "from deepeval.synthesizer.config import StylingConfig\n",
    "from repositories.faq import get_all as get_all_faqs\n",
    "from models.faq import FAQModel\n",
    "import json\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=\"sk-BJpqmcWfn3O9bvr2eryf6Uyf1m7VpSQpL7cNxGGlZccRrfA1\",base_url=\"https://open.keyai.shop/v1\")\n",
    "faqs = get_all_faqs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs_questions = [faq.question for faq in faqs]\n",
    "faq_questions_string = \"\\\\n-\".join([f\"- {question}\" for question in faqs_questions])\n",
    "prompt_template = \"\"\"\n",
    "B·∫°n l√† m·ªôt Chuy√™n gia Thi·∫øt k·∫ø Test Case AI, chuy√™n t·∫°o ra c√°c k·ªãch b·∫£n h·ªôi tho·∫°i ƒëa d·∫°ng v√† th·ª±c t·∫ø ƒë·ªÉ ƒë√°nh gi√° chatbot ti·∫øng Vi·ªát.\n",
    "\n",
    "NHI·ªÜM V·ª§:\n",
    "M·ª•c ti√™u c·ªßa b·∫°n l√† t·∫°o ra m·ªôt b·ªô d·ªØ li·ªáu g·ªìm ch√≠nh x√°c 30 k·ªãch b·∫£n `ConversationalTestCase` . M·ªói k·ªãch b·∫£n s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ki·ªÉm tra kh·∫£ nƒÉng c·ªßa chatbot trong vi·ªác x·ª≠ l√Ω c√°c truy v·∫•n kh√°c nhau t·ª´ ng∆∞·ªùi d√πng v√† c√°ch s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng ƒë√∫ng ƒë·∫Øn d·ª±a tr√™n user_gender ho·∫∑c pronoun trong user_input.\n",
    "\n",
    "DANH S√ÅCH C√ÇU H·ªéI FAQ THAM KH·∫¢O (S·ª≠ d·ª•ng ƒë·ªÉ simulate c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng):\n",
    "{faq_questions_string}\n",
    "\n",
    "Y√äU C·∫¶U CHI TI·∫æT CHO M·ªñI `ConversationalTestCase`:\n",
    "M·ªói `ConversationalTestCase` ph·∫£i l√† m·ªôt ƒë·ªëi t∆∞·ª£ng JSON v√† c√≥ c√°c ƒë·∫∑c ƒëi·ªÉm sau:\n",
    "1.  M·ªôt tr∆∞·ªùng `conversation_id` (chu·ªói, v√≠ d·ª•: \"conv_01\", \"conv_02\", ... , \"conv_30\").\n",
    "2.  M·ªôt tr∆∞·ªùng `turns` (danh s√°ch). Danh s√°ch n√†y ph·∫£i ch·ª©a t·ª´ 1 ƒë·∫øn 4 ƒë·ªëi t∆∞·ª£ng, m·ªói ƒë·ªëi t∆∞·ª£ng ƒë·∫°i di·ªán cho m·ªôt l∆∞·ª£t c·ªßa ng∆∞·ªùi d√πng v√† s·∫Ω ƒë∆∞·ª£c d√πng ƒë·ªÉ t·∫°o m·ªôt `LLMTestCase` sau n√†y.\n",
    "3.  ƒê·ªëi v·ªõi m·ªói ƒë·ªëi t∆∞·ª£ng \"turn\" trong danh s√°ch `turns`:\n",
    "    a.  `user_input` (chu·ªói): T·∫°o m·ªôt c√¢u h·ªèi t·ª± nhi√™n t·ª´ ph√≠a ng∆∞·ªùi d√πng. C√¢u h·ªèi n√†y N√äN ƒë∆∞·ª£c l·∫•y c·∫£m h·ª©ng t·ª´ ho·∫∑c d·∫´n d·∫Øt ƒë·∫øn m·ªôt trong c√°c c√¢u h·ªèi trong \"DANH S√ÅCH C√ÇU H·ªéI FAQ THAM KH·∫¢O\" ·ªü tr√™n.\n",
    "        -   **Quan tr·ªçng:** C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng PH·∫¢I s·ª≠ d·ª•ng ƒëa d·∫°ng c√°c ƒë·∫°i t·ª´ nh√¢n x∆∞ng ti·∫øng Vi·ªát ƒë·ªÉ t·ª± x∆∞ng, v√≠ d·ª•: \"anh\", \"ch·ªã\", \"c√¥\", \"ch√∫\", \"b√°c\", \"em\", \"tui\", \"t√¥i\", \"m√¨nh\".\n",
    "        -   C≈©ng bao g·ªìm c√°c tr∆∞·ªùng h·ª£p ng∆∞·ªùi d√πng KH√îNG s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng r√µ r√†ng (v√≠ d·ª•: \"L√†m th·∫ø n√†o ƒë·ªÉ...\", \"Cho h·ªèi v·ªÅ...\", \"S·∫£n ph·∫©m n√†y c√≤n kh√¥ng?\").\n",
    "        -   ƒê·∫£m b·∫£o s·ª± ƒëa d·∫°ng v√† ph√¢n b·ªï h·ª£p l√Ω c√°c lo·∫°i ƒë·∫°i t·ª´ n√†y trong to√†n b·ªô 30 k·ªãch b·∫£n.\n",
    "        -   V√≠ d·ª•: \"Anh mu·ªën h·ªèi c√°ch tra c·ª©u v·ªÅ h√≥a ƒë∆°n ƒë√£ mua h√†ng t·∫°i FPT Shop?\", \"L√†m th·∫ø n√†o ƒë·ªÉ ki·ªÉm tra ƒë∆∞·ª£c t√¨nh tr·∫°ng m√°y ƒë√£ g·ª≠i ƒëi b·∫£o h√†nh t·∫°i FPT Shop?\", \"Em ∆°i, ch·ªã c·∫ßn h·ªó tr·ª£ v·ªÅ v·∫•n ƒë·ªÅ t√†i kho·∫£n.\", \"Ch√∫ h·ªèi ch√∫t, c·ª≠a h√†ng m√¨nh c√≥ ch√≠nh s√°ch cho kh√°ch h√†ng th√¢n thi·∫øt kh√¥ng?\"\n",
    "    b.  `user_gender_context` (chu·ªói ho·∫∑c null): Ch·ªâ ƒë·ªãnh ng·ªØ c·∫£nh gi·ªõi t√≠nh c·ªßa ng∆∞·ªùi d√πng cho l∆∞·ª£t ƒë√≥. Gi√° tr·ªã c√≥ th·ªÉ l√† m·ªôt trong c√°c chu·ªói: \"male\", \"female\", \"unknown\". Trong m·ªôt s·ªë tr∆∞·ªùng h·ª£p, gi√° tr·ªã n√†y c√≥ th·ªÉ l√† `null` (ho·∫∑c tr∆∞·ªùng n√†y c√≥ th·ªÉ kh√¥ng xu·∫•t hi·ªán), cho bi·∫øt kh√¥ng c√≥ th√¥ng tin gi·ªõi t√≠nh c·ª• th·ªÉ n√†o ƒë∆∞·ª£c cung c·∫•p cho l∆∞·ª£t ƒë√≥. Ph√¢n b·ªï c√°c t√πy ch·ªçn n√†y m·ªôt c√°ch th·ª±c t·∫ø v√† ƒëa d·∫°ng.\n",
    "    c.  `bot_actual_output_placeholder` (chu·ªói): Tr∆∞·ªùng n√†y PH·∫¢I LU√îN LU√îN l√† m·ªôt chu·ªói r·ªóng (`\"\"`). N√≥ s·∫Ω ƒë∆∞·ª£c ƒëi·ªÅn v√†o sau b·ªüi ph·∫£n h·ªìi th·ª±c t·∫ø c·ªßa chatbot.\n",
    "\n",
    "Y√äU C·∫¶U CHO TO√ÄN B·ªò B·ªò D·ªÆ LI·ªÜU (30 `ConversationalTestCase`):\n",
    "1.  T·∫°o ra CH√çNH X√ÅC 30 k·ªãch b·∫£n `ConversationalTestCase`.\n",
    "2.  ƒê·∫£m b·∫£o s·ª± ƒëa d·∫°ng cao trong to√†n b·ªô 30 k·ªãch b·∫£n v·ªÅ c√°c m·∫∑t sau:\n",
    "    * B·∫Øt bu·ªôc d·ª±a tr√™n DANH S√ÅCH C√ÇU H·ªéI FAQ THAM KH·∫¢O g·ªëc ·ªü tr√™n.\n",
    "    * S·ªë l∆∞·ª£ng \"turns\" trong m·ªói h·ªôi tho·∫°i (t·ª´ 1 ƒë·∫øn 4).\n",
    "    * ƒê·∫°i t·ª´ nh√¢n x∆∞ng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong `user_input`.\n",
    "    * Gi√° tr·ªã `user_gender_context` ƒë∆∞·ª£c cung c·∫•p cho m·ªói l∆∞·ª£t.\n",
    "    * Phong c√°ch h·ªèi c·ªßa ng∆∞·ªùi d√πng (trang tr·ªçng, th√¢n m·∫≠t, tr·ª±c ti·∫øp, v.v.).\n",
    "\n",
    "ƒê·ªäNH D·∫†NG ƒê·∫¶U RA:\n",
    "Tr·∫£ v·ªÅ TO√ÄN B·ªò b·ªô d·ªØ li·ªáu d∆∞·ªõi d·∫°ng M·ªòT M·∫¢NG JSON DUY NH·∫§T (a single JSON array). M·ªói ph·∫ßn t·ª≠ c·ªßa m·∫£ng l√† m·ªôt ƒë·ªëi t∆∞·ª£ng JSON ƒë·∫°i di·ªán cho m·ªôt `ConversationalTestCase`, tu√¢n th·ªß c·∫•u tr√∫c ƒë√£ m√¥ t·∫£ ·ªü tr√™n (v·ªõi c√°c kh√≥a `conversation_id`, `turns`; v√† trong m·ªói turn l√† `user_input`, `user_gender_context`, `bot_actual_output_placeholder`).\n",
    "\n",
    "V√ç D·ª§ V·ªÄ C·∫§U TR√öC CHO M·ªòT `ConversationalTestCase` TRONG M·∫¢NG JSON:\n",
    "```json\n",
    "{\n",
    "  \"conversation_id\": \"conv_01\",\n",
    "  \"turns\": [\n",
    "    {\n",
    "      \"user_input\": \"Anh mu·ªën h·ªèi c√°ch tra c·ª©u v·ªÅ h√≥a ƒë∆°n ƒë√£ mua h√†ng t·∫°i FPT Shop?\",\n",
    "      \"user_gender_context\": \"male\",\n",
    "      \"bot_actual_output_placeholder\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"user_input\": \"N·∫øu h√≥a ƒë∆°n ƒë√≥ mua h∆°n 1 nƒÉm r·ªìi th√¨ c√≥ t√¨m l·∫°i ƒë∆∞·ª£c kh√¥ng shop?\",\n",
    "      \"user_gender_context\": \"male\",\n",
    "      \"bot_actual_output_placeholder\": \"\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#final_prompt = prompt_template.format(faq_questions_string=faq_questions_string)\n",
    "final_prompt = prompt_template.replace(\"{faq_questions_string}\", faq_questions_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"B·∫°n l√† m·ªôt AI h·ªó tr·ª£ t·∫°o d·ªØ li·ªáu test case cho deepeval ƒë√°nh gi√° chatbot ti·∫øng vi·ªát.\"},\n",
    "            {\"role\": \"user\", \"content\": final_prompt}\n",
    "        ],\n",
    "         # response_format={\"type\": \"json_object\"}, # N·∫øu model h·ªó tr·ª£ v√† b·∫°n mu·ªën JSON object ch·ª©a array\n",
    "        temperature=0. # ƒêi·ªÅu ch·ªânh ƒë·ªÉ c√≥ s·ª± ƒëa d·∫°ng\n",
    "    )\n",
    "generated_json_string = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated JSON string to a file\n",
    "with open(\"conversation_tone.json\", \"w\") as f:\n",
    "    f.write(generated_json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω: ConversationalTestCase.__init__() got an unexpected keyword argument 'messages'\n"
     ]
    }
   ],
   "source": [
    "cleaned_json_string = generated_json_string\n",
    "\n",
    "# Remove the Markdown code block delimiters\n",
    "# Common patterns are \"```json\\n\" at the start and \"\\n```\" at the end\n",
    "# Or just \"```json\" and \"```\" if there are no newlines separating them from the content\n",
    "\n",
    "# More robust cleaning:\n",
    "# 1. Remove \"```json\" from the start.\n",
    "# 2. Remove \"```\" from the end.\n",
    "# 3. Strip any surrounding whitespace (including newlines) that might be left.\n",
    "\n",
    "if cleaned_json_string.startswith(\"```json\"):\n",
    "    cleaned_json_string = cleaned_json_string[len(\"```json\"):]\n",
    "elif cleaned_json_string.startswith(\"```\"): # If it's just ``` without 'json'\n",
    "    cleaned_json_string = cleaned_json_string[len(\"```\"):]\n",
    "\n",
    "if cleaned_json_string.endswith(\"```\"):\n",
    "    cleaned_json_string = cleaned_json_string[:-len(\"```\")]\n",
    "\n",
    "# Strip whitespace (like newlines or spaces) from the beginning and end\n",
    "cleaned_json_string = cleaned_json_string.strip()\n",
    "# --- End of fix ---\n",
    "\n",
    "try:\n",
    "    parsed_data = json.loads(cleaned_json_string) # Use the cleaned string\n",
    "    deepeval_test_cases = []\n",
    "    for conv_data in parsed_data:\n",
    "        llm_turns = []\n",
    "        for turn_data in conv_data.get(\"turns\", []):\n",
    "            user_input = turn_data.get(\"user_input\")\n",
    "            gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "            actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")\n",
    "\n",
    "            current_context = []\n",
    "            if gender_context_val and gender_context_val != \"null\": #Check for string \"null\"\n",
    "                current_context.append(f\"User gender: {gender_context_val}\")\n",
    "            \n",
    "            if user_input: #Only add turn if user_input exists\n",
    "                llm_turns.append(\n",
    "                    LLMTestCase(\n",
    "                        input=user_input,\n",
    "                        actual_output=actual_output_placeholder, # Will be filled later\n",
    "                        context=current_context if current_context else None\n",
    "                    )\n",
    "                )\n",
    "        if llm_turns: #Only add ConversationalTestCase if there are valid turns\n",
    "            deepeval_test_cases.append(ConversationalTestCase(messages=llm_turns))\n",
    "\n",
    "    print(f\"ƒê√£ t·∫°o th√†nh c√¥ng {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "    # Now you can use deepeval_test_cases to run evaluations after filling actual_output\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"L·ªói gi·∫£i m√£ JSON: {e}\")\n",
    "    # Print the cleaned string for better debugging if error persists\n",
    "    print(f\"D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch (m·ªôt ph·∫ßn): {cleaned_json_string[:500]}...\")\n",
    "    print(f\"D·ªØ li·ªáu g·ªëc (m·ªôt ph·∫ßn): {generated_json_string[:500]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ t·∫°o th√†nh c√¥ng 30 ConversationalTestCase objects.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from deepeval.test_case import LLMTestCase, ConversationalTestCase\n",
    "\n",
    "\n",
    "try:\n",
    "        #parsed_data = json.loads(generated_json_string)\n",
    "        # load data from json file\n",
    "        with open(\"conversation_tone.json\", \"r\") as f:\n",
    "            parsed_data = json.load(f)\n",
    "        deepeval_test_cases = []\n",
    "        for conv_data in parsed_data:\n",
    "            llm_turns = []\n",
    "            for turn_data in conv_data.get(\"turns\", []):\n",
    "                user_input = turn_data.get(\"user_input\")\n",
    "                gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  #N√™n l√† \"\"\n",
    "\n",
    "                current_context = []\n",
    "                if gender_context_val and gender_context_val != \"null\":  #Ki·ªÉm tra null d∆∞·ªõi d·∫°ng chu·ªói\n",
    "                    current_context.append(f\"User gender: {gender_context_val}\")\n",
    "            \n",
    "                if user_input:  #Ch·ªâ th√™m turn n·∫øu c√≥ user_input\n",
    "                    llm_turns.append(\n",
    "                        LLMTestCase(\n",
    "                            input=user_input,\n",
    "                            actual_output=actual_output_placeholder, # S·∫Ω ƒë∆∞·ª£c ƒëi·ªÅn sau\n",
    "                            context=current_context if current_context else None  # DeepEval c√≥ th·ªÉ mu·ªën None n·∫øu context r·ªóng\n",
    "                        )\n",
    "                    )\n",
    "            if llm_turns:  #Ch·ªâ th√™m ConversationalTestCase n·∫øu c√≥ turns h·ª£p l·ªá\n",
    "                deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ d√πng messages\n",
    "                                                                                    #(ho·∫∑c `turns=llm_turns` cho phi√™n b·∫£n c≈© h∆°n)\n",
    "\n",
    "        print(f\"ƒê√£ t·∫°o th√†nh c√¥ng {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "        #B√¢y gi·ªù b·∫°n c√≥ th·ªÉ d√πng deepeval_test_cases ƒë·ªÉ ch·∫°y ƒë√°nh gi√° sau khi ƒëi·ªÅn actual_output\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"L·ªói gi·∫£i m√£ JSON: {e}\")\n",
    "    print(f\"D·ªØ li·ªáu nh·∫≠n ƒë∆∞·ª£c: {generated_json_string[:500]}...\")  #In m·ªôt ph·∫ßn d·ªØ li·ªáu l·ªói\n",
    "except Exception as e:\n",
    "    print(f\"L·ªói kh√¥ng x√°c ƒë·ªãnh khi x·ª≠ l√Ω: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.metrics import ConversationalGEval\n",
    "\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 11:43:25 - Loaded .env file\n",
      "2025-06-01 11:43:29 - >>> {\"query\": \"query DefaultEntity {\\n  viewer {\\n    username\\n    defaultEntity {\\n      name\\n    }\\n  }\\n}\"}\n",
      "2025-06-01 11:43:30 - <<< {\"data\":{\"viewer\":{\"username\":\"phatnguyen-041203\",\"defaultEntity\":{\"name\":\"tlcn\"}}}}\n",
      "weave version 0.51.49 is available!  To upgrade, please run:\n",
      " $ pip install weave --upgrade\n",
      "Logged in as Weights & Biases user: phatnguyen-041203.\n",
      "View Weave data at https://wandb.ai/tlcn/CHATBOT-TLCN/weave\n",
      "2025-06-01 11:43:31 - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "\n",
    "    # Add gender context to the conversation\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + gender_context},\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"ƒê√°nh gi√° kh·∫£ nƒÉng c·ªßa chatbot trong vi·ªác s·ª≠ d·ª•ng ƒë·∫°i t·ª´ nh√¢n x∆∞ng ti·∫øng Vi·ªát m·ªôt c√°ch ch√≠nh x√°c v√† nh·∫•t qu√°n trong su·ªët cu·ªôc h·ªôi tho·∫°i. C·ª• th·ªÉ:\n",
    "    1. Chatbot (assistant) trong 'actual_output' ph·∫£i LU√îN LU√îN t·ª± x∆∞ng l√† 'em'.  V√≠ d·ª•: 'd·∫° em ch√†o anh', 'em c√≥ th·ªÉ gi√∫p g√¨ ·∫°'. KH√îNG ƒë∆∞·ª£c d√πng 't√¥i', 'm√¨nh'\n",
    "    2. C√°ch chatbot g·ªçi ng∆∞·ªùi d√πng (user) ph·∫£i d·ª±a tr√™n th√¥ng tin ƒë∆∞·ª£c cung c·∫•p ho·∫∑c c√°ch ng∆∞·ªùi d√πng t·ª± x∆∞ng:\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'male' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'anh', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh'.\n",
    "        - N·∫øu 'User gender' ƒë∆∞·ª£c cung c·∫•p l√† 'female' ho·∫∑c ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch·ªã', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch·ªã'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'ch√∫', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'ch√∫' v√† t·ª± x∆∞ng 'ch√°u'.\n",
    "        - N·∫øu ng∆∞·ªùi d√πng t·ª± x∆∞ng l√† 'c√¥', chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'c√¥' v√† t·ª± x∆∞ng 'ch√°u'. \n",
    "        - N·∫øu 'User gender' l√† 'unknown' ho·∫∑c kh√¥ng ƒë∆∞·ª£c cung c·∫•p, v√† ng∆∞·ªùi d√πng kh√¥ng t·ª± x∆∞ng theo m·ªôt ƒë·∫°i t·ª´ c·ª• th·ªÉ n√†o ·ªü tr√™n, chatbot ph·∫£i g·ªçi ng∆∞·ªùi d√πng l√† 'anh/ch·ªã'.\n",
    "    3. T√≠nh nh·∫•t qu√°n: Chatbot ph·∫£i duy tr√¨ c√°ch x∆∞ng h√¥ ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p v·ªõi ng∆∞·ªùi d√πng m·ªôt c√°ch nh·∫•t qu√°n trong c√°c l∆∞·ª£t tr·∫£ l·ªùi ti·∫øp theo trong c√πng m·ªôt cu·ªôc h·ªôi tho·∫°i, tr·ª´ khi c√≥ th√¥ng tin m·ªõi r√µ r√†ng thay ƒë·ªïi c√°ch x∆∞ng h√¥.\n",
    "    4. Kh√¥ng ƒë∆∞·ª£c s·ª≠ d·ª•ng c√°c c√°ch x∆∞ng h√¥ kh√¥ng ph√π h·ª£p ho·∫∑c thi·∫øu t√¥n tr·ªçng.\n",
    "      H∆Ø·ªöNG D·∫™N CH·∫§M ƒêI·ªÇM:\n",
    "    - ƒêi·ªÉm 1.0: Tu√¢n th·ªß ho√†n h·∫£o t·∫•t c·∫£ c√°c quy t·∫Øc tr√™n trong m·ªçi l∆∞·ª£t c·ªßa h·ªôi tho·∫°i.\n",
    "    - Ph·∫°t n·∫∑ng (ƒëi·ªÉm g·∫ßn 0): N·∫øu chatbot t·ª± x∆∞ng sai (v√≠ d·ª•: x∆∞ng 't√¥i' thay v√¨ 'em').\n",
    "    - Ph·∫°t n·∫∑ng (ƒëi·ªÉm g·∫ßn 0): N·∫øu chatbot g·ªçi sai ng∆∞·ªùi d√πng m·ªôt c√°ch r√µ r√†ng (v√≠ d·ª•: context l√† 'User gender: male' nh∆∞ng chatbot g·ªçi l√† 'ch·ªã').\n",
    "    - Ph·∫°t nh·∫π h∆°n: N·∫øu chatbot d√πng 'anh/ch·ªã' trong tr∆∞·ªùng h·ª£p c√≥ th·ªÉ suy lu·∫≠n gi·ªõi t√≠nh t·ª´ input nh∆∞ng kh√¥ng r√µ r√†ng 100%.\n",
    "    - Xem x√©t to√†n b·ªô cu·ªôc h·ªôi tho·∫°i ƒë·ªÉ ƒë√°nh gi√° t√≠nh nh·∫•t qu√°n.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # ƒê·ªÉ ph√¢n t√≠ch input c·ªßa user (v√≠ d·ª•: \"anh mu·ªën h·ªèi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # ƒê·ªÉ ph√¢n t√≠ch output c·ªßa model\n",
    "        LLMTestCaseParams.CONTEXT,        # N·∫øu th√¥ng tin `User gender` ƒë∆∞·ª£c truy·ªÅn qua context cho m·ªói l∆∞·ª£t\n",
    "    ]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anh mu·ªën h·ªèi c√°ch tra c·ª©u v·ªÅ h√≥a ƒë∆°n ƒë√£ mua h√†ng t·∫°i FPT Shop?\n",
      "User gender: male\n",
      "N·∫øu h√≥a ƒë∆°n ƒë√≥ mua h∆°n 1 nƒÉm r·ªìi th√¨ c√≥ t√¨m l·∫°i ƒë∆∞·ª£c kh√¥ng shop?\n",
      "User gender: male\n"
     ]
    }
   ],
   "source": [
    "tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    print(turn.input)\n",
    "    # turn list to str\n",
    "    turn_str = \"\"\n",
    "    for t in turn.context:\n",
    "        turn_str += t\n",
    "    print(turn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-23bb-7fe2-b9c9-7c4767e75b93\n",
      "2025-06-01 11:43:53 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 11:43:54 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 12\n",
      "faq id : 16\n",
      "faq id : 62\n",
      "faq id : 18\n",
      "2025-06-01 11:44:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: 594337d9-7381-4a39-a3b1-233965240458 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='D·∫° ch√†o anh. Anh c√≥ th·ªÉ tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i FPT Shop [t·∫°i ƒë√¢y](https://hddt.fptshop.com.vn/). N·∫øu anh c·∫ßn th√™m th√¥ng tin ho·∫∑c h·ªó tr·ª£ kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©.'\n",
      "D·∫° ch√†o anh. Anh c√≥ th·ªÉ tra c·ª©u h√≥a ƒë∆°n mua h√†ng t·∫°i FPT Shop [t·∫°i ƒë√¢y](https://hddt.fptshop.com.vn/). N·∫øu anh c·∫ßn th√™m th√¥ng tin ho·∫∑c h·ªó tr·ª£ kh√°c, ƒë·ª´ng ng·∫ßn ng·∫°i cho em bi·∫øt nh√©.\n",
      "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-4883-7120-ad90-0c8cad66e6a3\n",
      "2025-06-01 11:44:01 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 11:44:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 79\n",
      "2025-06-01 11:44:10 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: c8230f9e-ef8d-4764-8903-659fcb566532 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='D·∫° th∆∞a anh, theo quy ƒë·ªãnh c·ªßa FPT Shop, h√≥a ƒë∆°n mua h√†ng s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa c·ª≠a h√†ng trong v√≤ng 1 nƒÉm k·ªÉ t·ª´ ng√†y mua. Sau th·ªùi gian n√†y, vi·ªác truy xu·∫•t h√≥a ƒë∆°n s·∫Ω g·∫∑p kh√≥ khƒÉn v√† kh√¥ng ƒë·∫£m b·∫£o ch√≠nh x√°c. Tuy nhi√™n, anh c√≥ th·ªÉ th·ª≠ li√™n h·ªá t·ªïng ƒë√†i h·ªó tr·ª£ c·ªßa FPT Shop (1800.6601) ƒë·ªÉ ƒë∆∞·ª£c ki·ªÉm tra th√™m th√¥ng tin. Anh c√≥ c·∫ßn em h·ªó tr·ª£ t√¨m hi·ªÉu v·ªÅ c√°c s·∫£n ph·∫©m c√¥ng ngh·ªá hi·ªán c√≥ t·∫°i FPT Shop kh√¥ng ·∫°?'\n",
      "D·∫° th∆∞a anh, theo quy ƒë·ªãnh c·ªßa FPT Shop, h√≥a ƒë∆°n mua h√†ng s·∫Ω ƒë∆∞·ª£c l∆∞u tr·ªØ trong h·ªá th·ªëng c·ªßa c·ª≠a h√†ng trong v√≤ng 1 nƒÉm k·ªÉ t·ª´ ng√†y mua. Sau th·ªùi gian n√†y, vi·ªác truy xu·∫•t h√≥a ƒë∆°n s·∫Ω g·∫∑p kh√≥ khƒÉn v√† kh√¥ng ƒë·∫£m b·∫£o ch√≠nh x√°c. Tuy nhi√™n, anh c√≥ th·ªÉ th·ª≠ li√™n h·ªá t·ªïng ƒë√†i h·ªó tr·ª£ c·ªßa FPT Shop (1800.6601) ƒë·ªÉ ƒë∆∞·ª£c ki·ªÉm tra th√™m th√¥ng tin. Anh c√≥ c·∫ßn em h·ªó tr·ª£ t√¨m hi·ªÉu v·ªÅ c√°c s·∫£n ph·∫©m c√¥ng ngh·ªá hi·ªán c√≥ t·∫°i FPT Shop kh√¥ng ·∫°?\n"
     ]
    }
   ],
   "source": [
    "tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context))\n",
    "    print(turn.actual_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643917bcb1c443bbb807a432adff996c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-93c8-7562-814c-7645e051be0a\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-93c8-7562-814c-7645e051be0a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 11:44:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-a22c-7af2-b7ed-2c1477e1f6cf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üç© https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-a22c-7af2-b7ed-2c1477e1f6cf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 11:44:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998 The chatbot consistently uses 'em' for self-reference and 'anh' for the user, aligning with the user's male gender context. Pronoun usage is consistent and appropriate throughout the conversation.\n"
     ]
    }
   ],
   "source": [
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ConversationalTestCase' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpronoun_consistency_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/chatbot-tlcn/.venv/lib/python3.12/site-packages/deepeval/evaluate/evaluate.py:257\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(test_cases, metrics, hyperparameters, goldens, observed_callback, identifier, async_config, display_config, cache_config, error_config)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EvaluationResult(\n\u001b[1;32m    253\u001b[0m         test_results\u001b[38;5;241m=\u001b[39mtest_results, confident_link\u001b[38;5;241m=\u001b[39mconfident_link\n\u001b[1;32m    254\u001b[0m     )\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_cases \u001b[38;5;129;01mand\u001b[39;00m metrics:\n\u001b[0;32m--> 257\u001b[0m     \u001b[43mcheck_valid_test_cases_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     global_test_run_manager\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    260\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
      "File \u001b[0;32m~/chatbot-tlcn/.venv/lib/python3.12/site-packages/deepeval/test_case/utils.py:13\u001b[0m, in \u001b[0;36mcheck_valid_test_cases_type\u001b[0;34m(test_cases)\u001b[0m\n\u001b[1;32m     11\u001b[0m llm_test_case_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m conversational_test_case_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLLMTestCase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLLMTestCase\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_test_case_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ConversationalTestCase' object is not iterable"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    test_cases=tc,\n",
    "    metrics=[pronoun_consistency_metric],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define conversation starters\n",
    "CONVERSATION_STARTERS = [\n",
    "    \"Ch√†o shop, m√¨nh mu·ªën h·ªèi v·ªÅ {topic}\",\n",
    "    \"Shop ∆°i, cho m√¨nh h·ªèi v·ªÅ {topic}\",\n",
    "    \"M√¨nh ƒëang t√¨m hi·ªÉu v·ªÅ {topic}\",\n",
    "    \"B√™n shop c√≥ {topic} kh√¥ng?\",\n",
    "    \"M√¨nh mu·ªën h·ªèi v·ªÅ {topic}\"\n",
    "]\n",
    "\n",
    "# Define follow-up questions\n",
    "FOLLOW_UP_QUESTIONS = [\n",
    "    \"V·∫≠y {topic} c√≥ {detail} kh√¥ng?\",\n",
    "    \"C√≥ th·ªÉ cho m√¨nh bi·∫øt th√™m v·ªÅ {detail} kh√¥ng?\",\n",
    "    \"V·∫≠y {topic} th√¨ {detail} th·∫ø n√†o?\",\n",
    "    \"C√≥ th·ªÉ gi·∫£i th√≠ch r√µ h∆°n v·ªÅ {detail} kh√¥ng?\",\n",
    "    \"V·∫≠y {topic} c√≥ {detail} kh√¥ng shop?\"\n",
    "]\n",
    "def generate_bot_response(user_message: str, faqs: List[FAQModel], turn_number: int) -> str:\n",
    "    \"\"\"Generate a bot response based on user message and FAQs\"\"\"\n",
    "    if turn_number == 1:\n",
    "        # First turn - greeting and asking for more information\n",
    "        return f\"D·∫° ch√†o anh/ch·ªã, em c√≥ th·ªÉ gi√∫p g√¨ cho anh/ch·ªã ·∫°?\"\n",
    "    else:\n",
    "        # Follow-up turns - provide information based on FAQs\n",
    "        # Use OpenAI to generate a response based on the user message and FAQs\n",
    "        faq_context = \"\\n\".join([\n",
    "            f\"Q: {faq.question}\\nA: {faq.answer}\"\n",
    "            for faq in faqs\n",
    "        ])\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"\"\"You are a helpful customer service representative at FPT Shop. \n",
    "                Use the following FAQs to answer customer questions:\n",
    "                {faq_context}\n",
    "                \n",
    "                Guidelines:\n",
    "                - Be professional and friendly\n",
    "                - Use appropriate Vietnamese pronouns (em-anh/ch·ªã)\n",
    "                - Keep responses concise but informative\n",
    "                - If the question isn't covered in FAQs, ask for more details\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation_test_case(faqs: List[FAQModel], num_turns: int = 2) -> ConversationalTestCase:\n",
    "    \"\"\"Generate a multi-turn conversation test case\"\"\"\n",
    "    # Select random FAQ\n",
    "    faq = random.choice(faqs)\n",
    "    \n",
    "    # Generate conversation turns\n",
    "    turns = []\n",
    "    \n",
    "    # First turn\n",
    "    first_input = random.choice(CONVERSATION_STARTERS).format(topic=faq.title)\n",
    "    first_output = generate_bot_response(first_input, [faq], 1)\n",
    "    turns.append(LLMTestCase(\n",
    "        input=first_input,\n",
    "        actual_output=first_output,\n",
    "        context=[f\"FAQ Category: {faq.category}\"]\n",
    "    ))\n",
    "    \n",
    "    # Follow-up turns\n",
    "    for i in range(1, num_turns):\n",
    "        # Extract key details from FAQ answer for follow-up questions\n",
    "        follow_up = random.choice(FOLLOW_UP_QUESTIONS).format(\n",
    "            topic=faq.title,\n",
    "            detail=random.choice(faq.answer.split(\".\")[0].split())\n",
    "        )\n",
    "        bot_response = generate_bot_response(follow_up, [faq], i + 1)\n",
    "        turns.append(LLMTestCase(\n",
    "            input=follow_up,\n",
    "            actual_output=bot_response,\n",
    "            context=[f\"FAQ Category: {faq.category}\"]\n",
    "        ))\n",
    "    \n",
    "    return ConversationalTestCase(turns=turns)\n",
    "\n",
    "def generate_test_cases(num_cases: int = 10, min_turns: int = 2, max_turns: int = 4) -> List[ConversationalTestCase]:\n",
    "    \"\"\"Generate multiple test cases using FAQs\"\"\"\n",
    "    all_test_cases = []\n",
    "    faqs = get_all_faqs()\n",
    "    \n",
    "    for _ in range(num_cases):\n",
    "        num_turns = random.randint(min_turns, max_turns)\n",
    "        test_case = generate_conversation_test_case(faqs, num_turns)\n",
    "        all_test_cases.append(test_case)\n",
    "    \n",
    "    return all_test_cases\n",
    "\n",
    "def save_test_cases(test_cases: List[ConversationalTestCase], output_file: str):\n",
    "    \"\"\"Save test cases to a JSON file\"\"\"\n",
    "    serialized_cases = []\n",
    "    for case in test_cases:\n",
    "        serialized_turns = []\n",
    "        for turn in case.turns:\n",
    "            serialized_turns.append({\n",
    "                \"input\": turn.input,\n",
    "                \"actual_output\": turn.actual_output,\n",
    "                \"context\": turn.context\n",
    "            })\n",
    "        serialized_cases.append({\"turns\": serialized_turns})\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(serialized_cases, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
