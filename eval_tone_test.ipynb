{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case.llm_test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.test_case.conversational_test_case import ConversationalTestCase\n",
    "from deepeval.metrics.conversational_g_eval.conversational_g_eval import ConversationalGEval\n",
    "import deepeval.models.llms.openai_model as deepeval_models\n",
    "from deepeval import evaluate\n",
    "gpt_41_mini = deepeval_models.GPTModel(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    timeout=60,\n",
    ")\n",
    "json_file = 'conversation_tone.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deepeval.test_case.llm_test_case import LLMTestCase\n",
    "from deepeval.test_case.conversational_test_case import ConversationalTestCase\n",
    "from typing import List\n",
    "def load_testcase_from_json(json_file) -> List[ConversationalTestCase]:\n",
    "    try:\n",
    "        with open( json_file,\"r\") as f:\n",
    "            parsed_data = json.load(f)\n",
    "        deepeval_test_cases = []\n",
    "        for conv_data in parsed_data:\n",
    "            llm_turns = []\n",
    "            for turn_data in conv_data.get(\"turns\", []):\n",
    "                user_input = turn_data.get(\"user_input\")\n",
    "                gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  \n",
    "                current_context = []\n",
    "                if gender_context_val and gender_context_val != \"null\":  #Kiểm tra null dưới dạng chuỗi\n",
    "                    current_context.append(f\"User gender: {gender_context_val}\")\n",
    "            \n",
    "                if user_input:  #Chỉ thêm turn nếu có user_input\n",
    "                    llm_turns.append(\n",
    "                        LLMTestCase(\n",
    "                            input=user_input,\n",
    "                            actual_output=actual_output_placeholder, # Sẽ được điền sau\n",
    "                            context=current_context if current_context else None  # DeepEval có thể muốn None nếu context rỗng\n",
    "                        )\n",
    "                    )\n",
    "            if llm_turns:  #Chỉ thêm ConversationalTestCase nếu có turns hợp lệ\n",
    "                deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ dùng messages\n",
    "                                                                                    #(hoặc `turns=llm_turns` cho phiên bản cũ hơn)\n",
    "        print(f\"Đã load thành công {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "        return deepeval_test_cases\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Lỗi giải mã JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định khi xử lý: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer, ConfigModel\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "import service.openai as openai_service\n",
    "from openai.types.chat_model import ChatModel\n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str, response_model: str, use_fine_tune_tone: bool) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    config = ConfigModel(\n",
    "        response=response_model,\n",
    "        use_fine_tune_tone=use_fine_tune_tone,\n",
    "    )\n",
    "    history = [\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n",
    "\n",
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str\n",
    "\n",
    "\n",
    "def get_actual_answer_for_all_testcase_without_conversation_history(json_file:str,gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    #deepeval_test_cases = load_testcase_from_json(json_file) # load test case with actual_output werent generated\n",
    "    '''\n",
    "    get_actual_answer for all testcase\n",
    "    iter_checkpoint is the index of the checkpoint fine-tuned model\n",
    "    gen_answer_model is the fine-tuned model to use for generating responses\n",
    "    '''\n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    for conversational_test_case in conversations:\n",
    "        processed_turns = []\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "\n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conversational_test_case.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        '''write to json file'''\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n",
    "\n",
    "def get_actual_answer_with_conversation_history(json_file: str, gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    \n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "\n",
    "    for conv in conversations:\n",
    "        processed_turns = []\n",
    "        turns = conv.turns\n",
    "        user = create_user(\n",
    "            CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "        )\n",
    "        thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "        # Initialize conversation history with system message\n",
    "        history = [\n",
    "            {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + turns[0][\"user_gender_context\"]}\n",
    "        ]\n",
    "        \n",
    "        for turn in turns:\n",
    "            # Add user input to history\n",
    "            history.append({\"role\": \"user\", \"content\": turn[\"user_input\"]})\n",
    "            \n",
    "            # Set the model for this conversation\n",
    "            #openai_service._fine_tuning_model = gen_answer_model\n",
    "            \n",
    "            # Generate bot response using accumulated history\n",
    "            bot_response = gen_answer(\n",
    "                #thread_id=uuid4(),  # Generate new thread ID for each turn\n",
    "                thread_id=thread.id,\n",
    "                history=history,\n",
    "                #user_id=uuid4(),  # Generate new user ID for each turn\n",
    "                user_id=user.id,\n",
    "            )\n",
    "            turn.actual_output = bot_response\n",
    "            # Add bot response to history for next turn\n",
    "            history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "            \n",
    "            # Store processed turn\n",
    "            \n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "        \n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conv.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"{json_file}_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"Đánh giá khả năng của chatbot trong việc sử dụng đại từ nhân xưng tiếng Việt một cách chính xác và nhất quán trong suốt cuộc hội thoại. Cụ thể:\n",
    "    1. Chatbot (assistant) trong 'actual_output' phải LUÔN LUÔN tự xưng là 'em'.  Ví dụ: 'dạ em chào anh', 'em có thể giúp gì ạ'. KHÔNG được dùng 'tôi', 'mình'\n",
    "    2. Cách chatbot gọi người dùng (user) phải dựa trên thông tin được cung cấp hoặc cách người dùng tự xưng:\n",
    "        - Nếu 'User gender' được cung cấp là 'male' hoặc người dùng tự xưng là 'anh' như 'anh muốn hỏi...', chatbot phải gọi người dùng là 'anh'.\n",
    "        - Nếu 'User gender' được cung cấp là 'female' hoặc người dùng tự xưng là 'chị' như 'chị muốn hỏi...', chatbot phải gọi người dùng là 'chị'.\n",
    "        - Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'bác', chatbot phải gọi người dùng là 'bác' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'cô', chatbot phải gọi người dùng là 'cô' và tự xưng 'cháu'. \n",
    "        - Nếu 'User gender' được cung cấp là 'unknown' hoặc không được cung cấp, và người dùng không tự xưng theo một đại từ cụ thể nào ở trên, chatbot phải gọi người dùng là 'anh/chị'.\n",
    "\n",
    "    3. Tính nhất quán: Chatbot phải duy trì cách xưng hô đã được thiết lập với người dùng một cách nhất quán trong các lượt trả lời tiếp theo trong cùng một cuộc hội thoại, trừ khi có thông tin mới rõ ràng thay đổi cách xưng hô.\n",
    "    4. Không được sử dụng các cách xưng hô không phù hợp hoặc thiếu tôn trọng.\n",
    "      HƯỚNG DẪN CHẤM ĐIỂM:\n",
    "    - Điểm 1.0: Tuân thủ hoàn hảo tất cả các quy tắc trên trong mọi lượt của hội thoại.\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot tự xưng sai (ví dụ: xưng 'tôi' thay vì 'em').\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot gọi sai người dùng một cách rõ ràng (ví dụ: context là 'User gender: male' nhưng chatbot gọi là 'chị').\n",
    "    - Xem xét toàn bộ cuộc hội thoại để đánh giá tính nhất quán.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # Để phân tích input của user (ví dụ: \"anh muốn hỏi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # Để phân tích output của model\n",
    "        LLMTestCaseParams.CONTEXT,        # Nếu thông tin `User gender` được truyền qua context cho mỗi lượt\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"Chị muốn hỏi cách tra cứu điểm mua hàng đã tích được tại FPT Shop .\",\n",
    "            actual_output= \" Chị có thể thực hiện tra cứu điểm tích [tại đây](https://fptshop.com.vn/tai-khoan/lich-su-tich-diem) bằng cách đăng nhập số điện thoại mua hàng của chị.\",\n",
    "            # Không cần context nếu input đã đủ rõ, nhưng criteria cần xử lý được\n",
    "            # context=[\"User gender: female\"] # Có thể thêm nếu muốn rõ ràng hơn\n",
    "            context=[\"User gender: unknown\"]\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"Vậy còn tra cứu về thông tin trúng thưởng của FPT Shop khi tham gia các chương trình mini game?\",\n",
    "            actual_output=\"Chị có thể thực hiện tra cứu [tại đây](https://fptshop.com.vn/khuyen-mai/thong-tin-trao-thuong)\",\n",
    "            context=[\"User gender: unknown\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "pronoun_consistency_metric.measure(test_case)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_case1 = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"Chị muốn hỏi cách tra cứu điểm mua hàng đã tích được tại FPT Shop .\",\n",
    "            actual_output= \" Chị có thể thực hiện tra cứu điểm tích [tại đây](https://fptshop.com.vn/tai-khoan/lich-su-tich-diem) bằng cách đăng nhập số điện thoại mua hàng của chị.Chị cần em hỗ trợ gì nữa không ạ?\",\n",
    "            # Không cần context nếu input đã đủ rõ, nhưng criteria cần xử lý được\n",
    "            # context=[\"User gender: female\"] # Có thể thêm nếu muốn rõ ràng hơn\n",
    "            context=[\"User gender: unknown\"]\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"Vậy còn tra cứu về thông tin trúng thưởng của FPT Shop khi tham gia các chương trình mini game?\",\n",
    "            actual_output=\"Chị có thể thực hiện tra cứu [tại đây](https://fptshop.com.vn/khuyen-mai/thong-tin-trao-thuong). Chị cần em hỗ trợ gì nữa không ạ?\",\n",
    "            context=[\"User gender: unknown\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "pronoun_consistency_metric.measure(test_case1)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danh gia rieng le 1 testcase\n",
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "'''save the output of get_actual_answer for all testcase to json file for each model'''\n",
    "\n",
    "\n",
    "def eval_tc(_testcases,_metrics,iter_checkpoint):\n",
    "    evaluation_results = evaluate(\n",
    "        test_cases=_testcases,\n",
    "        metrics=_metrics,\n",
    "    )\n",
    "    # điểm số của metric được lưu trong mỗi đối tượng test case sau khi evaluate\n",
    "    score = 0\n",
    "    for result in evaluation_results: # evaluate() trả về list các test cases đã được cập nhật\n",
    "        print(f\"Test Case ID: {result.id if result.id else 'N/A'}\") # ConversationalTestCase có thể không có id trừ khi bạn set\n",
    "        for metric_result in result.metrics: # Mỗi test case có thể có nhiều metric\n",
    "            if metric_result.name == pronoun_consistency_metric.name:\n",
    "                print(f\"  Metric: {metric_result.name}\")\n",
    "                print(f\"  Score: {metric_result.score}\")\n",
    "                if metric_result.reason: \n",
    "                    print(f\"  Reason: {metric_result.reason[:300]}...\") # In một phần lý do\n",
    "                print(\"-\" * 20)\n",
    "                score += metric_result.score\n",
    "    mean_score = score/len(evaluation_results)\n",
    "    print(f\"Mean score: {mean_score}\")\n",
    "            \n",
    "    \n",
    "    # get the mean score of all testcase\n",
    "    \n",
    "    #mean_score = evaluation_results.score.mean()\n",
    "    # save result to file\n",
    "    with open(f\"evaluation_results_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(evaluation_results, f)\n",
    "        json.dump(mean_score, f)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_lst = [\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6dn4:ckpt-step-50\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6ShS:ckpt-step-100\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao7Wp2\"]\n",
    "\n",
    "def get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        model = checkpoint_model\n",
    "\n",
    "        # 1 trong 2 cach de luu actual_output vao json file moi\n",
    "        #get_actual_answer_for_all_testcase_without_conversation_history(json_file,model,iter_checkpoint)\n",
    "        get_actual_answer_with_conversation_history(json_file,model,iter_checkpoint)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thay vi chi dùng checkpoint cuoi của fine-tuned model , dùng toàn bộ checkpoint để đánh giá\"\"\"\n",
    "def eval_all_checkpoint(deepeval_test_cases,checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        load_testcase_from_json(f'{json_file}_{iter_checkpoint}.json')\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        # evaluate\n",
    "        eval_tc(deepeval_test_cases,[pronoun_consistency_metric],iter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
