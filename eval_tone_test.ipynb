{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.metrics import ConversationalGEval\n",
    "\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "import deepeval.models.llms.openai_model as deepeval_models\n",
    "from deepeval import evaluate\n",
    "gpt_41_mini = deepeval_models.GPTModel(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    timeout=60,\n",
    "    #_openai_api_key=\"sk-BJpqmcWfn3O9bvr2eryf6Uyf1m7VpSQpL7cNxGGlZccRrfA1\",\n",
    "    #base_url=\"https://open.keyai.shop/v1\"\n",
    ")\n",
    "json_file = 'conversation_tone.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tc = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"tui muốn hỏi cách tra cứu hóa đơn đã mua hàng\",\n",
    "            actual_output=\"Dạ anh có thể thực hiện tra cứu hóa đơn mua hàng tại [đây](https://hddt.fptshop.com.vn/).\",\n",
    "            # Không cần context nếu input đã đủ rõ, nhưng criteria cần xử lý được\n",
    "            context=[\"User gender: male\"] # Có thể thêm nếu muốn rõ ràng hơn\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"làm sao để tra cứu tình trạng sản phẩm gửi bảo hành tại FPT Shop?\",\n",
    "            actual_output=\"Dạ anh có thể tra cứu tình trạng máy gửi bảo hành bất cứ lúc nào [Tại đây](https://fptshop.com.vn/kiem-tra-bao-hanh?tab=thong-tin-bao-hanh)..\",\n",
    "            context=[\"User gender: male\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"Đánh giá khả năng của chatbot trong việc sử dụng đại từ nhân xưng tiếng Việt một cách chính xác và nhất quán trong suốt cuộc hội thoại. Cụ thể:\n",
    "    1. Chatbot (assistant) phải LUÔN LUÔN tự xưng là 'em'.\n",
    "    2. Cách chatbot gọi người dùng (user) phải dựa trên thông tin được cung cấp hoặc cách người dùng tự xưng:\n",
    "        - Nếu 'User gender' được cung cấp là 'male' hoặc người dùng tự xưng là 'anh', chatbot phải gọi người dùng là 'anh'.\n",
    "        - Nếu 'User gender' được cung cấp là 'female' hoặc người dùng tự xưng là 'chị', chatbot phải gọi người dùng là 'chị'.\n",
    "        - Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'cô', chatbot phải gọi người dùng là 'cô' và tự xưng 'cháu'. (Lưu ý: Cần điều chỉnh nếu model không được fine-tune để xưng 'cháu'. Nếu model luôn xưng 'em', thì tiêu chí này cần phản ánh điều đó, ví dụ: \"Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và vẫn tự xưng 'em'\").\n",
    "        - Nếu 'User gender' là 'unknown' hoặc không được cung cấp, và người dùng không tự xưng theo một đại từ cụ thể nào ở trên, chatbot phải gọi người dùng là 'anh/chị'.\n",
    "    3. Chatbot phải duy trì cách xưng hô đã thiết lập với người dùng một cách nhất quán trong các lượt trả lời tiếp theo, trừ khi có thông tin mới rõ ràng về giới tính hoặc cách xưng hô ưu tiên của người dùng.\n",
    "    4. Không được sử dụng các cách xưng hô không phù hợp hoặc thiếu tôn trọng.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # Để phân tích input của user (ví dụ: \"anh muốn hỏi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # Để phân tích output của model\n",
    "        # LLMTestCaseParams.CONTEXT,        # Nếu thông tin `User gender` được truyền qua context cho mỗi lượt\n",
    "    ]\n",
    "    \n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from deepeval.test_case import LLMTestCase, ConversationalTestCase\n",
    "from typing import List\n",
    "'''load testcase (with actual_output generated or not) from json file'''\n",
    "def load_testcase_from_json(json_file) -> List[ConversationalTestCase]:\n",
    "    try:\n",
    "            #parsed_data = json.loads(generated_json_string)\n",
    "            # load data from json file\n",
    "            with open( json_file,\"r\") as f:\n",
    "                parsed_data = json.load(f)\n",
    "            deepeval_test_cases = []\n",
    "            for conv_data in parsed_data:\n",
    "                llm_turns = []\n",
    "                for turn_data in conv_data.get(\"turns\", []):\n",
    "                    user_input = turn_data.get(\"user_input\")\n",
    "                    gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                    actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  \n",
    "\n",
    "                    current_context = []\n",
    "                    if gender_context_val and gender_context_val != \"null\":  #Kiểm tra null dưới dạng chuỗi\n",
    "                        current_context.append(f\"User gender: {gender_context_val}\")\n",
    "                \n",
    "                    if user_input:  #Chỉ thêm turn nếu có user_input\n",
    "                        llm_turns.append(\n",
    "                            LLMTestCase(\n",
    "                                input=user_input,\n",
    "                                actual_output=actual_output_placeholder, # Sẽ được điền sau\n",
    "                                context=current_context if current_context else None  # DeepEval có thể muốn None nếu context rỗng\n",
    "                            )\n",
    "                        )\n",
    "                if llm_turns:  #Chỉ thêm ConversationalTestCase nếu có turns hợp lệ\n",
    "                    deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ dùng messages\n",
    "                                                                                        #(hoặc `turns=llm_turns` cho phiên bản cũ hơn)\n",
    "\n",
    "            print(f\"Đã load thành công {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "            return deepeval_test_cases\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Lỗi giải mã JSON: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi không xác định khi xử lý: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "import service.openai as openai_service\n",
    "from openai.types.chat_model import ChatModel\n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str,gen_answer_model:ChatModel=None) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "    # Add gender context to the conversation\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + gender_context},\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n",
    "\n",
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str\n",
    "\n",
    "# ko luu conversation vao history\n",
    "def get_actual_answer_for_all_testcase_without_conversation_history(json_file:str,gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    #deepeval_test_cases = load_testcase_from_json(json_file) # load test case with actual_output werent generated\n",
    "    '''\n",
    "    get_actual_answer for all testcase\n",
    "    iter_checkpoint is the index of the checkpoint fine-tuned model\n",
    "    gen_answer_model is the fine-tuned model to use for generating responses\n",
    "    '''\n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    for conversational_test_case in conversations:\n",
    "        processed_turns = []\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "\n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conversational_test_case.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        '''write to json file'''\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n",
    "\n",
    "#luu conversation vao history\n",
    "def get_actual_answer_with_conversation_history(json_file: str, gen_answer_model:ChatModel=None,iter_checkpoint:int=0):\n",
    "    \n",
    "    conversations = load_testcase_from_json(json_file)\n",
    "    process_conversations = []\n",
    "    id = 0\n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat tung checkpoint model cho gen_answer\n",
    "\n",
    "    for conv in conversations:\n",
    "        processed_turns = []\n",
    "        turns = conv.turns\n",
    "        user = create_user(\n",
    "            CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "        )\n",
    "        thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "        # Initialize conversation history with system message\n",
    "        history = [\n",
    "            {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + turns[0][\"user_gender_context\"]}\n",
    "        ]\n",
    "        \n",
    "        for turn in turns:\n",
    "            # Add user input to history\n",
    "            history.append({\"role\": \"user\", \"content\": turn[\"user_input\"]})\n",
    "            \n",
    "            # Set the model for this conversation\n",
    "            #openai_service._fine_tuning_model = gen_answer_model\n",
    "            \n",
    "            # Generate bot response using accumulated history\n",
    "            bot_response = gen_answer(\n",
    "                #thread_id=uuid4(),  # Generate new thread ID for each turn\n",
    "                thread_id=thread.id,\n",
    "                history=history,\n",
    "                #user_id=uuid4(),  # Generate new user ID for each turn\n",
    "                user_id=user.id,\n",
    "            )\n",
    "            turn.actual_output = bot_response\n",
    "            # Add bot response to history for next turn\n",
    "            history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
    "            \n",
    "            # Store processed turn\n",
    "            \n",
    "            processed_turn = {\n",
    "                \"user_input\": turn.input,\n",
    "                \"user_gender_context\": turn.context,\n",
    "                \"bot_actual_output_placeholder\": turn.actual_output\n",
    "            }\n",
    "            processed_turns.append(processed_turn)\n",
    "        \n",
    "        process_conversations.append({\n",
    "            \"conversation_id\": conv.id,\n",
    "            \"turns\": processed_turns\n",
    "        })\n",
    "        id += 1\n",
    "        print(f\"Processed {id} conversations with actual answers.\")\n",
    "    with open(f\"{json_file}_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(process_conversations, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' function to get actual_output for all testcase and write to json file'''\n",
    "'''\n",
    "def get_actual_output_for_all_testcase(deepeval_test_cases,gen_answer_model,iter_checkpoint):\n",
    "    for conversational_test_case in deepeval_test_cases:\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "        with open(f\"conversation_tone_{iter_checkpoint}.json\", \"w\") as f:\n",
    "            json.dump(conversational_test_case, f)\n",
    "'''            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"Đánh giá khả năng của chatbot trong việc sử dụng đại từ nhân xưng tiếng Việt một cách chính xác và nhất quán trong suốt cuộc hội thoại. Cụ thể:\n",
    "    1. Chatbot (assistant) trong 'actual_output' **nên** tự xưng là 'em'. Việc này được ưu tiên, đặc biệt ở các lượt nói đầu hoặc khi cần làm rõ hành động của chatbot (ví dụ: 'Dạ em chào anh', 'Em có thể giúp gì ạ'). Việc không xưng 'em' trong một số câu trả lời ngắn và trực tiếp ở các lượt sau có thể được chấp nhận nếu văn phong tự nhiên và vai trò của chatbot đã rõ ràng từ trước. Chatbot **TUYỆT ĐỐI KHÔNG** được dùng 'tôi', 'mình' để tự xưng.\n",
    "    2. Cách chatbot gọi người dùng (user) phải dựa trên thông tin được cung cấp hoặc cách người dùng tự xưng:\n",
    "        - Nếu 'User gender' được cung cấp là 'male' hoặc người dùng tự xưng là 'anh' như 'anh muốn hỏi...', chatbot phải gọi người dùng là 'anh'.\n",
    "        - Nếu 'User gender' được cung cấp là 'female' hoặc người dùng tự xưng là 'chị' như 'chị muốn hỏi...', chatbot phải gọi người dùng là 'chị'.\n",
    "        - Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'bác', chatbot phải gọi người dùng là 'bác' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'cô', chatbot phải gọi người dùng là 'cô' và tự xưng 'cháu'.\n",
    "        - Nếu 'User gender' được cung cấp là 'unknown' hoặc không được cung cấp, và người dùng không tự xưng theo một đại từ cụ thể nào ở trên, chatbot phải gọi người dùng là 'anh/chị'.\n",
    "\n",
    "    3. Tính nhất quán: Chatbot phải duy trì cách xưng hô đã được thiết lập với người dùng một cách nhất quán trong các lượt trả lời tiếp theo trong cùng một cuộc hội thoại, trừ khi có thông tin mới rõ ràng thay đổi cách xưng hô.\n",
    "    4. Không được sử dụng các cách xưng hô không phù hợp hoặc thiếu tôn trọng.\n",
    "\n",
    "    HƯỚNG DẪN CHẤM ĐIỂM:\n",
    "    - Điểm 1.0: Tuân thủ hoàn hảo tất cả các quy tắc trên trong mọi lượt của hội thoại.\n",
    "    - **Phạt nặng (điểm gần 0): Nếu chatbot tự xưng sai hoàn toàn (ví dụ: dùng 'tôi', 'mình' thay vì 'em'; hoặc dùng sai giữa 'em' và 'cháu' khi ngữ cảnh yêu cầu rõ ràng).**\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot gọi sai người dùng một cách rõ ràng (ví dụ: context là 'User gender: male' nhưng chatbot gọi là 'chị').\n",
    "    - **Phạt nhẹ hoặc không phạt: Đối với trường hợp chatbot không tự xưng 'em' trong một số ít câu trả lời ngắn, trực tiếp ở các lượt sau, khi việc này không ảnh hưởng đáng kể đến sự rõ ràng, tính lịch sự của cuộc hội thoại và vai trò chatbot đã được thiết lập.**\n",
    "    - Xem xét toàn bộ cuộc hội thoại để đánh giá tính nhất quán.\n",
    "    \"\"\",\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.CONTEXT,\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"Đánh giá khả năng của chatbot trong việc sử dụng đại từ nhân xưng tiếng Việt một cách chính xác và nhất quán trong suốt cuộc hội thoại. \n",
    "\n",
    "    THÔNG TIN CẦN PHÂN TÍCH:\n",
    "    - 'input': Tin nhắn của người dùng - cần phân tích cách người dùng tự xưng và ngữ cảnh\n",
    "    - 'actual_output': Phản hồi của chatbot - cần đánh giá cách chatbot tự xưng và gọi người dùng\n",
    "    - 'context': Thông tin bổ sung về người dùng (ví dụ: User gender) và ngữ cảnh cuộc hội thoại\n",
    "\n",
    "    QUY TẮC ĐÁNH GIÁ:\n",
    "\n",
    "    1. **Cách chatbot tự xưng trong 'actual_output':**\n",
    "       - Chatbot **nên** tự xưng là 'em' (được ưu tiên, đặc biệt ở các lượt nói đầu hoặc khi cần làm rõ hành động)\n",
    "       - Chatbot **TUYỆT ĐỐI KHÔNG** được dùng 'tôi', 'mình' để tự xưng\n",
    "       - Ngoại lệ: Khi người dùng trong 'input' tự xưng là 'chú', 'bác', 'cô' thì chatbot phải tự xưng 'cháu'\n",
    "\n",
    "    2. **Cách chatbot gọi người dùng (dựa trên 'input' và 'context'):**\n",
    "       - Nếu trong 'context' có 'User gender: male' HOẶC người dùng trong 'input' tự xưng 'anh' → chatbot gọi 'anh'\n",
    "       - Nếu trong 'context' có 'User gender: female' HOẶC người dùng trong 'input' tự xưng 'chị' → chatbot gọi 'chị'\n",
    "       - Nếu người dùng trong 'input' tự xưng 'chú' → chatbot gọi 'chú' và tự xưng 'cháu'\n",
    "       - Nếu người dùng trong 'input' tự xưng 'bác' → chatbot gọi 'bác' và tự xưng 'cháu'\n",
    "       - Nếu người dùng trong 'input' tự xưng 'cô' → chatbot gọi 'cô' và tự xưng 'cháu'\n",
    "       - Nếu trong 'context' có 'User gender: unknown' hoặc không có thông tin gender, và người dùng trong 'input' không tự xưng rõ ràng → chatbot gọi 'anh/chị'\n",
    "\n",
    "    3. **Tính nhất quán:** \n",
    "       - Phân tích toàn bộ lịch sử hội thoại trong 'context' để đảm bảo chatbot duy trì cách xưng hô đã thiết lập\n",
    "       - Chỉ chấp nhận thay đổi cách xưng hô khi có thông tin mới rõ ràng trong 'input'\n",
    "\n",
    "    4. **Tính lịch sự và phù hợp:**\n",
    "       - Không sử dụng cách xưng hô thiếu tôn trọng hoặc không phù hợp với văn hóa Việt Nam\n",
    "\n",
    "    HƯỚNG DẪN CHẤM ĐIỂM:\n",
    "    - **Điểm 1.0:** Tuân thủ hoàn hảo tất cả các quy tắc trên, phù hợp với thông tin trong 'input', 'context' và thể hiện tính nhất quán trong 'actual_output'\n",
    "    \n",
    "    - **Phạt nặng (điểm 0.0-0.3):**\n",
    "      • Chatbot tự xưng sai hoàn toàn ('tôi', 'mình' thay vì 'em')\n",
    "      • Sử dụng sai giữa 'em' và 'cháu' khi 'input' hoặc 'context' yêu cầu rõ ràng\n",
    "      • Gọi sai người dùng rõ ràng (ví dụ: 'context' là 'User gender: male' nhưng gọi 'chị')\n",
    "      • Không nhất quán trong cùng cuộc hội thoại mà không có lý do chính đáng từ 'input' mới\n",
    "    \n",
    "    - **Phạt vừa (điểm 0.4-0.7):**\n",
    "      • Thiếu một số cách xưng hô cần thiết ở những vị trí quan trọng\n",
    "      • Không tận dụng đầy đủ thông tin từ 'context' để xác định cách xưng hô phù hợp\n",
    "    \n",
    "    - **Phạt nhẹ hoặc không phạt (điểm 0.8-1.0):**\n",
    "      • Chatbot không tự xưng 'em' trong một số ít câu trả lời ngắn, trực tiếp ở các lượt sau, khi vai trò đã được thiết lập và không ảnh hưởng đến tính lịch sự\n",
    "\n",
    "    CÁCH PHÂN TÍCH:\n",
    "    1. Đọc kỹ 'context' để hiểu thông tin về người dùng và lịch sử hội thoại\n",
    "    2. Phân tích 'input' để xác định cách người dùng tự xưng và mong đợi được gọi\n",
    "    3. Đánh giá 'actual_output' dựa trên các quy tắc trên\n",
    "    4. Xem xét tính nhất quán với các lượt hội thoại trước đó (nếu có trong context)\n",
    "    \"\"\",\n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "        LLMTestCaseParams.CONTEXT,\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713d2e504a174eccbffddadc453c6b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8029362452578461 The chatbot consistently uses 'Chị' to address the user, matching the user's self-reference in the input. Although the user's gender is unknown in context, the chatbot maintains politeness and cultural appropriateness without inconsistent shifts in pronouns.\n"
     ]
    }
   ],
   "source": [
    "test_case = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"Chị muốn hỏi cách tra cứu điểm mua hàng đã tích được tại FPT Shop .\",\n",
    "            actual_output= \" Chị có thể thực hiện tra cứu điểm tích [tại đây](https://fptshop.com.vn/tai-khoan/lich-su-tich-diem) bằng cách đăng nhập số điện thoại mua hàng của chị.\",\n",
    "            # Không cần context nếu input đã đủ rõ, nhưng criteria cần xử lý được\n",
    "            # context=[\"User gender: female\"] # Có thể thêm nếu muốn rõ ràng hơn\n",
    "            context=[\"User gender: unknown\"]\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"Vậy còn tra cứu về thông tin trúng thưởng của FPT Shop khi tham gia các chương trình mini game?\",\n",
    "            actual_output=\"Chị có thể thực hiện tra cứu [tại đây](https://fptshop.com.vn/khuyen-mai/thong-tin-trao-thuong)\",\n",
    "            context=[\"User gender: unknown\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "pronoun_consistency_metric.measure(test_case)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anh muốn hỏi cách tra cứu về hóa đơn đã mua hàng tại FPT Shop?\n",
      "User gender: male\n",
      "Nếu hóa đơn đó mua hơn 1 năm rồi thì có tìm lại được không shop?\n",
      "User gender: male\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    print(turn.input)\n",
    "    # turn list to str\n",
    "    turn_str = \"\"\n",
    "    for t in turn.context:\n",
    "        turn_str += t\n",
    "    print(turn_str)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-165e-7c72-bfd0-d513b251ee06\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 12\n",
      "faq id : 16\n",
      "faq id : 62\n",
      "faq id : 18\n",
      "2025-06-01 12:07:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: f6eb87ad-616a-4b58-a7e3-126f60c8f886 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='Dạ chào anh. Anh có thể tra cứu hóa đơn mua hàng tại FPT Shop [tại đây](https://hddt.fptshop.com.vn/). Nếu anh cần thêm thông tin hoặc hỗ trợ khác, đừng ngần ngại cho em biết nhé.'\n",
      "Dạ chào anh. Anh có thể tra cứu hóa đơn mua hàng tại FPT Shop [tại đây](https://hddt.fptshop.com.vn/). Nếu anh cần thêm thông tin hoặc hỗ trợ khác, đừng ngần ngại cho em biết nhé.\n",
      "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-3ff1-7050-806a-181e9b2ba4bb\n",
      "2025-06-01 12:08:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:08:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 79\n",
      "2025-06-01 12:08:08 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: a598641d-6bae-4686-bf42-a34df626c189 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='Dạ thưa anh, theo quy định của FPT Shop, hóa đơn mua hàng sẽ được lưu trữ trong hệ thống của cửa hàng trong vòng 1 năm kể từ ngày mua. Sau thời gian này, hóa đơn sẽ không còn khả năng truy xuất. Nếu anh cần hỗ trợ thêm thông tin về sản phẩm hoặc dịch vụ khác, đừng ngần ngại cho em biết nhé. FPT Shop hiện có nhiều loại sản phẩm công nghệ như điện thoại, laptop, máy tính bảng,... rất đa dạng ạ.'\n",
      "Dạ thưa anh, theo quy định của FPT Shop, hóa đơn mua hàng sẽ được lưu trữ trong hệ thống của cửa hàng trong vòng 1 năm kể từ ngày mua. Sau thời gian này, hóa đơn sẽ không còn khả năng truy xuất. Nếu anh cần hỗ trợ thêm thông tin về sản phẩm hoặc dịch vụ khác, đừng ngần ngại cho em biết nhé. FPT Shop hiện có nhiều loại sản phẩm công nghệ như điện thoại, laptop, máy tính bảng,... rất đa dạng ạ.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "for turn in tc.turns:\n",
    "    turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context))\n",
    "    print(turn.actual_output)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f6e08653f499e9f750202fd521a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The chatbot consistently uses 'em' for self-reference and addresses the male user as 'anh' in both turns, matching the user gender in context. The form of address remains consistent and respectful throughout the conversation.\n"
     ]
    }
   ],
   "source": [
    "# danh gia rieng le 1 testcase\n",
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "'''save the output of get_actual_answer for all testcase to json file for each model'''\n",
    "\n",
    "\n",
    "def eval_tc(_testcases,_metrics,iter_checkpoint):\n",
    "    evaluation_results = evaluate(\n",
    "        test_cases=_testcases,\n",
    "        metrics=_metrics,\n",
    "    )\n",
    "    # điểm số của metric được lưu trong mỗi đối tượng test case sau khi evaluate\n",
    "    score = 0\n",
    "    for result in evaluation_results: # evaluate() trả về list các test cases đã được cập nhật\n",
    "        print(f\"Test Case ID: {result.id if result.id else 'N/A'}\") # ConversationalTestCase có thể không có id trừ khi bạn set\n",
    "        for metric_result in result.metrics: # Mỗi test case có thể có nhiều metric\n",
    "            if metric_result.name == pronoun_consistency_metric.name:\n",
    "                print(f\"  Metric: {metric_result.name}\")\n",
    "                print(f\"  Score: {metric_result.score}\")\n",
    "                if metric_result.reason: \n",
    "                    print(f\"  Reason: {metric_result.reason[:300]}...\") # In một phần lý do\n",
    "                print(\"-\" * 20)\n",
    "                score += metric_result.score\n",
    "    mean_score = score/len(evaluation_results)\n",
    "    print(f\"Mean score: {mean_score}\")\n",
    "            \n",
    "    \n",
    "    # get the mean score of all testcase\n",
    "    \n",
    "    #mean_score = evaluation_results.score.mean()\n",
    "    # save result to file\n",
    "    with open(f\"evaluation_results_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(evaluation_results, f)\n",
    "        json.dump(mean_score, f)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_lst = [\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6dn4:ckpt-step-50\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6ShS:ckpt-step-100\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao7Wp2\"]\n",
    "\n",
    "def get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        model = checkpoint_model\n",
    "\n",
    "        # 1 trong 2 cach de luu actual_output vao json file moi\n",
    "        #get_actual_answer_for_all_testcase_without_conversation_history(json_file,model,iter_checkpoint)\n",
    "        get_actual_answer_with_conversation_history(json_file,model,iter_checkpoint)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_actual_answer_for_all_testcase_for_all_checkpoint(checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Thay vi chi dùng checkpoint cuoi của fine-tuned model , dùng toàn bộ checkpoint để đánh giá\"\"\"\n",
    "def eval_all_checkpoint(deepeval_test_cases,checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model in enumerate(checkpoint_lst):\n",
    "        load_testcase_from_json(f'{json_file}_{iter_checkpoint}.json')\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        # evaluate\n",
    "        eval_tc(deepeval_test_cases,[pronoun_consistency_metric],iter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danh gia toan bo testcase\n",
    "#eval_all_checkpoint(deepeval_test_cases,checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" +\"User gender: unknown\"}\n",
    "]\n",
    "turns = [\n",
    "    {\"user_input\": \"Chú muốn hỏi Shop có hỗ trợ trả góp qua Home PayLater không?\"},\n",
    "    {\"user_input\": \"Vậy cửa hàng có hỗ trợ trả góp qua Kredivo không?\"}\n",
    "]\n",
    "user = create_user(\n",
    "            CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "        )\n",
    "thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "for turn in turns:\n",
    "    # Add user input to history\n",
    "    history.append({\"role\": \"user\", \"content\": turn[\"user_input\"]})\n",
    "    \n",
    "    # Set the model for this conversation\n",
    "    #openai_service._fine_tuning_model = gen_answer_model\n",
    "    \n",
    "    # Generate bot response using accumulated history\n",
    "    bot_response = gen_answer(\n",
    "        #thread_id=uuid4(),  # Generate new thread ID for each turn\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        #user_id=uuid4(),  # Generate new user ID for each turn\n",
    "        user_id=user.id,\n",
    "    )\n",
    "    turn.actual_output = bot_response\n",
    "    # Add bot response to history for next turn\n",
    "    history.append({\"role\": \"assistant\", \"content\": bot_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
