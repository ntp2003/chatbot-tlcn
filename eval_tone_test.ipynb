{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.metrics import ConversationalGEval\n",
    "\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "import deepeval.models.llms.openai_model as deepeval_models\n",
    "from deepeval import evaluate\n",
    "gpt_41_mini = deepeval_models.GPTModel(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    timeout=60,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tc = ConversationalTestCase(\n",
    "    turns=[\n",
    "        LLMTestCase(\n",
    "            input=\"tui muốn hỏi cách tra cứu hóa đơn đã mua hàng\",\n",
    "            actual_output=\"Dạ anh có thể thực hiện tra cứu hóa đơn mua hàng tại [đây](https://hddt.fptshop.com.vn/).\",\n",
    "            # Không cần context nếu input đã đủ rõ, nhưng criteria cần xử lý được\n",
    "            context=[\"User gender: male\"] # Có thể thêm nếu muốn rõ ràng hơn\n",
    "        ),\n",
    "        LLMTestCase(\n",
    "            input=\"làm sao để tra cứu tình trạng sản phẩm gửi bảo hành tại FPT Shop?\",\n",
    "            actual_output=\"Dạ anh có thể tra cứu tình trạng máy gửi bảo hành bất cứ lúc nào [Tại đây](https://fptshop.com.vn/kiem-tra-bao-hanh?tab=thong-tin-bao-hanh)..\",\n",
    "            context=[\"User gender: male\"]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"Đánh giá khả năng của chatbot trong việc sử dụng đại từ nhân xưng tiếng Việt một cách chính xác và nhất quán trong suốt cuộc hội thoại. Cụ thể:\n",
    "    1. Chatbot (assistant) phải LUÔN LUÔN tự xưng là 'em'.\n",
    "    2. Cách chatbot gọi người dùng (user) phải dựa trên thông tin được cung cấp hoặc cách người dùng tự xưng:\n",
    "        - Nếu 'User gender' được cung cấp là 'male' hoặc người dùng tự xưng là 'anh', chatbot phải gọi người dùng là 'anh'.\n",
    "        - Nếu 'User gender' được cung cấp là 'female' hoặc người dùng tự xưng là 'chị', chatbot phải gọi người dùng là 'chị'.\n",
    "        - Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'cô', chatbot phải gọi người dùng là 'cô' và tự xưng 'cháu'. (Lưu ý: Cần điều chỉnh nếu model không được fine-tune để xưng 'cháu'. Nếu model luôn xưng 'em', thì tiêu chí này cần phản ánh điều đó, ví dụ: \"Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và vẫn tự xưng 'em'\").\n",
    "        - Nếu 'User gender' là 'unknown' hoặc không được cung cấp, và người dùng không tự xưng theo một đại từ cụ thể nào ở trên, chatbot phải gọi người dùng là 'anh/chị'.\n",
    "    3. Chatbot phải duy trì cách xưng hô đã thiết lập với người dùng một cách nhất quán trong các lượt trả lời tiếp theo, trừ khi có thông tin mới rõ ràng về giới tính hoặc cách xưng hô ưu tiên của người dùng.\n",
    "    4. Không được sử dụng các cách xưng hô không phù hợp hoặc thiếu tôn trọng.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # Để phân tích input của user (ví dụ: \"anh muốn hỏi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # Để phân tích output của model\n",
    "        # LLMTestCaseParams.CONTEXT,        # Nếu thông tin `User gender` được truyền qua context cho mỗi lượt\n",
    "    ]\n",
    "    \n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo thành công 30 ConversationalTestCase objects.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from deepeval.test_case import LLMTestCase, ConversationalTestCase\n",
    "\n",
    "\n",
    "try:\n",
    "        #parsed_data = json.loads(generated_json_string)\n",
    "        # load data from json file\n",
    "        with open(\"conversation_tone.json\", \"r\") as f:\n",
    "            parsed_data = json.load(f)\n",
    "        deepeval_test_cases = []\n",
    "        for conv_data in parsed_data:\n",
    "            llm_turns = []\n",
    "            for turn_data in conv_data.get(\"turns\", []):\n",
    "                user_input = turn_data.get(\"user_input\")\n",
    "                gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  #Nên là \"\"\n",
    "\n",
    "                current_context = []\n",
    "                if gender_context_val and gender_context_val != \"null\":  #Kiểm tra null dưới dạng chuỗi\n",
    "                    current_context.append(f\"User gender: {gender_context_val}\")\n",
    "            \n",
    "                if user_input:  #Chỉ thêm turn nếu có user_input\n",
    "                    llm_turns.append(\n",
    "                        LLMTestCase(\n",
    "                            input=user_input,\n",
    "                            actual_output=actual_output_placeholder, # Sẽ được điền sau\n",
    "                            context=current_context if current_context else None  # DeepEval có thể muốn None nếu context rỗng\n",
    "                        )\n",
    "                    )\n",
    "            if llm_turns:  #Chỉ thêm ConversationalTestCase nếu có turns hợp lệ\n",
    "                deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ dùng messages\n",
    "                                                                                    #(hoặc `turns=llm_turns` cho phiên bản cũ hơn)\n",
    "\n",
    "        print(f\"Đã tạo thành công {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "        #có thể dùng deepeval_test_cases để chạy đánh giá sau khi điền actual_output\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Lỗi giải mã JSON: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi không xác định khi xử lý: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:39:56 - Loaded .env file\n",
      "2025-06-01 12:40:00 - >>> {\"query\": \"query DefaultEntity {\\n  viewer {\\n    username\\n    defaultEntity {\\n      name\\n    }\\n  }\\n}\"}\n",
      "2025-06-01 12:40:01 - <<< {\"data\":{\"viewer\":{\"username\":\"phatnguyen-041203\",\"defaultEntity\":{\"name\":\"tlcn\"}}}}\n",
      "weave version 0.51.49 is available!  To upgrade, please run:\n",
      " $ pip install weave --upgrade\n",
      "Logged in as Weights & Biases user: phatnguyen-041203.\n",
      "View Weave data at https://wandb.ai/tlcn/CHATBOT-TLCN/weave\n",
      "2025-06-01 12:40:02 - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "import service.openai as openai_service\n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str,gen_answer_model=None) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "    \n",
    "    openai_service._fine_tuning_model = gen_answer_model # cap nhat model cho gen_answer\n",
    "    # Add gender context to the conversation\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + gender_context},\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"Đánh giá khả năng của chatbot trong việc sử dụng đại từ nhân xưng tiếng Việt một cách chính xác và nhất quán trong suốt cuộc hội thoại. Cụ thể:\n",
    "    1. Chatbot (assistant) trong 'actual_output' phải LUÔN LUÔN tự xưng là 'em'.  Ví dụ: 'dạ em chào anh', 'em có thể giúp gì ạ'. KHÔNG được dùng 'tôi', 'mình'\n",
    "    2. Cách chatbot gọi người dùng (user) phải dựa trên thông tin được cung cấp hoặc cách người dùng tự xưng:\n",
    "        - Nếu 'User gender được cung cấp là 'male' hoặc người dùng tự xưng là 'anh', chatbot phải gọi người dùng là 'anh'.\n",
    "        - Nếu 'User gend'er' được cung cấp là 'female' hoặc người dùng tự xưng là 'chị', chatbot phải gọi người dùng là 'chị'.\n",
    "        - Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'cô', chatbot phải gọi người dùng là 'cô' và tự xưng 'cháu'. \n",
    "        - Nếu 'User gender' là 'unknown' hoặc không được cung cấp, và người dùng không tự xưng theo một đại từ cụ thể nào ở trên, chatbot phải gọi người dùng là 'anh/chị'.\n",
    "    3. Tính nhất quán: Chatbot phải duy trì cách xưng hô đã được thiết lập với người dùng một cách nhất quán trong các lượt trả lời tiếp theo trong cùng một cuộc hội thoại, trừ khi có thông tin mới rõ ràng thay đổi cách xưng hô.\n",
    "    4. Không được sử dụng các cách xưng hô không phù hợp hoặc thiếu tôn trọng.\n",
    "      HƯỚNG DẪN CHẤM ĐIỂM:\n",
    "    - Điểm 1.0: Tuân thủ hoàn hảo tất cả các quy tắc trên trong mọi lượt của hội thoại.\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot tự xưng sai (ví dụ: xưng 'tôi' thay vì 'em').\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot gọi sai người dùng một cách rõ ràng (ví dụ: context là 'User gender: male' nhưng chatbot gọi là 'chị').\n",
    "    - Phạt nhẹ hơn: Nếu chatbot dùng 'anh/chị' trong trường hợp có thể suy luận giới tính từ input nhưng không rõ ràng 100%.\n",
    "    - Xem xét toàn bộ cuộc hội thoại để đánh giá tính nhất quán.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # Để phân tích input của user (ví dụ: \"anh muốn hỏi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # Để phân tích output của model\n",
    "        LLMTestCaseParams.CONTEXT,        # Nếu thông tin `User gender` được truyền qua context cho mỗi lượt\n",
    "    ],\n",
    "    model=gpt_41_mini,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anh muốn hỏi cách tra cứu về hóa đơn đã mua hàng tại FPT Shop?\n",
      "User gender: male\n",
      "Nếu hóa đơn đó mua hơn 1 năm rồi thì có tìm lại được không shop?\n",
      "User gender: male\n"
     ]
    }
   ],
   "source": [
    "tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    print(turn.input)\n",
    "    # turn list to str\n",
    "    turn_str = \"\"\n",
    "    for t in turn.context:\n",
    "        turn_str += t\n",
    "    print(turn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-165e-7c72-bfd0-d513b251ee06\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:07:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 12\n",
      "faq id : 16\n",
      "faq id : 62\n",
      "faq id : 18\n",
      "2025-06-01 12:07:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: f6eb87ad-616a-4b58-a7e3-126f60c8f886 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='Dạ chào anh. Anh có thể tra cứu hóa đơn mua hàng tại FPT Shop [tại đây](https://hddt.fptshop.com.vn/). Nếu anh cần thêm thông tin hoặc hỗ trợ khác, đừng ngần ngại cho em biết nhé.'\n",
      "Dạ chào anh. Anh có thể tra cứu hóa đơn mua hàng tại FPT Shop [tại đây](https://hddt.fptshop.com.vn/). Nếu anh cần thêm thông tin hoặc hỗ trợ khác, đừng ngần ngại cho em biết nhé.\n",
      "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-3ff1-7050-806a-181e9b2ba4bb\n",
      "2025-06-01 12:08:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 12:08:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 79\n",
      "2025-06-01 12:08:08 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: a598641d-6bae-4686-bf42-a34df626c189 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='Dạ thưa anh, theo quy định của FPT Shop, hóa đơn mua hàng sẽ được lưu trữ trong hệ thống của cửa hàng trong vòng 1 năm kể từ ngày mua. Sau thời gian này, hóa đơn sẽ không còn khả năng truy xuất. Nếu anh cần hỗ trợ thêm thông tin về sản phẩm hoặc dịch vụ khác, đừng ngần ngại cho em biết nhé. FPT Shop hiện có nhiều loại sản phẩm công nghệ như điện thoại, laptop, máy tính bảng,... rất đa dạng ạ.'\n",
      "Dạ thưa anh, theo quy định của FPT Shop, hóa đơn mua hàng sẽ được lưu trữ trong hệ thống của cửa hàng trong vòng 1 năm kể từ ngày mua. Sau thời gian này, hóa đơn sẽ không còn khả năng truy xuất. Nếu anh cần hỗ trợ thêm thông tin về sản phẩm hoặc dịch vụ khác, đừng ngần ngại cho em biết nhé. FPT Shop hiện có nhiều loại sản phẩm công nghệ như điện thoại, laptop, máy tính bảng,... rất đa dạng ạ.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for turn in tc.turns:\n",
    "    turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context))\n",
    "    print(turn.actual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641f6e08653f499e9f750202fd521a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b64-f9fa-7eb3-9844-365579882529\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b65-1a1a-7400-b29b-61768612942a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 12:08:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 The chatbot consistently uses 'em' for self-reference and addresses the male user as 'anh' in both turns, matching the user gender in context. The form of address remains consistent and respectful throughout the conversation.\n"
     ]
    }
   ],
   "source": [
    "# danh gia rieng le 1 testcase\n",
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''function to get_actual_answer for all testcase'''\n",
    "def get_actual_answer_for_all_testcase(deepeval_test_cases,gen_answer_model):\n",
    "    for conversational_test_case in deepeval_test_cases:\n",
    "        for turn in conversational_test_case.turns:\n",
    "            turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context),gen_answer_model)\n",
    "            print(turn.input,turn.actual_output)\n",
    "\n",
    "def eval_tc(_testcases,_metrics,iter_checkpoint):\n",
    "    evaluation_results = evaluate(\n",
    "        test_cases=_testcases,\n",
    "        metrics=_metrics,\n",
    "    )\n",
    "    # điểm số của metric được lưu trong mỗi đối tượng test case sau khi evaluate\n",
    "    score = 0\n",
    "    for result in evaluation_results: # evaluate() trả về list các test cases đã được cập nhật\n",
    "        print(f\"Test Case ID: {result.id if result.id else 'N/A'}\") # ConversationalTestCase có thể không có id trừ khi bạn set\n",
    "        for metric_result in result.metrics: # Mỗi test case có thể có nhiều metric\n",
    "            if metric_result.name == pronoun_consistency_metric.name:\n",
    "                print(f\"  Metric: {metric_result.name}\")\n",
    "                print(f\"  Score: {metric_result.score}\")\n",
    "                if metric_result.reason: \n",
    "                    print(f\"  Reason: {metric_result.reason[:300]}...\") # In một phần lý do\n",
    "                print(\"-\" * 20)\n",
    "                score += metric_result.score\n",
    "    mean_score = score/len(evaluation_results)\n",
    "    print(f\"Mean score: {mean_score}\")\n",
    "            \n",
    "    # get the mean score of all testcase\n",
    "    \n",
    "    #mean_score = evaluation_results.score.mean()\n",
    "    # save result to file\n",
    "    with open(f\"evaluation_results_{iter_checkpoint}.json\", \"w\") as f:\n",
    "        json.dump(evaluation_results, f)\n",
    "        json.dump(mean_score, f)\n",
    "\n",
    "\n",
    "\"\"\"Thay vi chi dùng checkpoint cuoi của fine-tuned model , dùng toàn bộ checkpoint để đánh giá\"\"\"\n",
    "checkpoint_lst = [\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6dn4:ckpt-step-50\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao6ShS:ckpt-step-100\",\"ft:gpt-4o-mini-2024-07-18:personal::Bdao7Wp2\"]\n",
    "def eval_all_checkpoint(deepeval_test_cases,checkpoint_lst):\n",
    "    for iter_checkpoint,checkpoint_model  in enumerate(checkpoint_lst):\n",
    "        print(checkpoint_model)\n",
    "        # load checkpoint\n",
    "        model = checkpoint_model\n",
    "        get_actual_answer_for_all_testcase(deepeval_test_cases,model)\n",
    "        # evaluate\n",
    "        eval_tc(deepeval_test_cases,[pronoun_consistency_metric],iter_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# danh gia toan bo testcase\n",
    "eval_all_checkpoint(deepeval_test_cases,checkpoint_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
