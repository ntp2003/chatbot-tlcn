{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from service.embedding import _model as model\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tasks.import_faq_data import file_path, _preprocessing_data_in_batch\n",
    "import pandas as pd\n",
    "import time\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def gen_langchain_docs(\n",
    "    file_path: str = file_path,\n",
    "):\n",
    "    start_time = time.time()\n",
    "    docs = []\n",
    "    print(\"Import is running...\")\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = _preprocessing_data_in_batch(df)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        content = (\n",
    "                    \"Câu hỏi: \" + row[\"question\"] + \"\\nCâu trả lời: \" + row[\"answer\"]\n",
    "                )\n",
    "        doc = Document(page_content=content)\n",
    "        docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import is running...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:30 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:   4%|▎         | 1/28 [00:01<00:37,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:30 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  11%|█         | 3/28 [00:01<00:11,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  18%|█▊        | 5/28 [00:01<00:05,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  25%|██▌       | 7/28 [00:01<00:03,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  32%|███▏      | 9/28 [00:01<00:02,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  39%|███▉      | 11/28 [00:02<00:01,  9.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  46%|████▋     | 13/28 [00:02<00:01,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:31 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  54%|█████▎    | 15/28 [00:02<00:01, 10.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  61%|██████    | 17/28 [00:02<00:00, 11.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  68%|██████▊   | 19/28 [00:02<00:01,  8.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  75%|███████▌  | 21/28 [00:03<00:00,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:32 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  82%|████████▏ | 23/28 [00:03<00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:33 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:33 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  89%|████████▉ | 25/28 [00:03<00:00,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:33 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:33 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying SummaryExtractor:  96%|█████████▋| 27/28 [00:03<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:34 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:   0%|          | 0/34 [00:00<?, ?it/s]         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:34 - Node 30f874b1-95a9-4a5c-a61a-e836b0aab46e does not have a summary. Skipping filtering.\n",
      "2024-12-06 01:16:34 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:   6%|▌         | 2/34 [00:00<00:11,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - Node 839b33c0-8999-4749-8a4a-d777232ed179 does not have a summary. Skipping filtering.\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:  12%|█▏        | 4/34 [00:00<00:05,  5.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:35 - Node 905d474b-b2a6-4077-8460-7eb10eed126a does not have a summary. Skipping filtering.\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - Node 44ccbde3-0a35-4cee-a46a-277605c1d555 does not have a summary. Skipping filtering.\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - Node c93df0db-c7bc-4966-97bd-282e507c22d9 does not have a summary. Skipping filtering.\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:  41%|████      | 14/34 [00:00<00:00, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:35 - Node 8fac342d-8693-49ff-b05c-4bda7a93affa does not have a summary. Skipping filtering.\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:  65%|██████▍   | 22/34 [00:01<00:00, 19.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:  76%|███████▋  | 26/34 [00:01<00:00, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying CustomNodeFilter:  88%|████████▊ | 30/34 [00:01<00:00, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:35 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:36 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:37 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:38 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:38 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:40 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:41 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:41 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:42 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:42 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:43 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:44 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:44 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:45 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:46 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:46 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:47 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:47 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:47 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:48 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:49 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:49 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:49 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:50 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:51 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:51 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:52 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:52 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:52 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:53 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   1%|          | 1/96 [00:17<27:27, 17.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:54 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  30%|███       | 29/96 [00:18<00:31,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:54 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:54 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  33%|███▎      | 32/96 [00:19<00:27,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  35%|███▌      | 34/96 [00:19<00:24,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  44%|████▍     | 42/96 [00:19<00:13,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:55 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  48%|████▊     | 46/96 [00:20<00:11,  4.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  51%|█████     | 49/96 [00:20<00:09,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  55%|█████▌    | 53/96 [00:20<00:06,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  59%|█████▉    | 57/96 [00:20<00:04,  7.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:56 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  62%|██████▎   | 60/96 [00:21<00:04,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  66%|██████▌   | 63/96 [00:21<00:03,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  68%|██████▊   | 65/96 [00:21<00:03,  9.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  71%|███████   | 68/96 [00:21<00:02, 10.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  75%|███████▌  | 72/96 [00:21<00:01, 14.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:57 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  78%|███████▊  | 75/96 [00:22<00:01, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  80%|████████  | 77/96 [00:22<00:01, 11.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  82%|████████▏ | 79/96 [00:22<00:01, 12.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  89%|████████▊ | 85/96 [00:22<00:00, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:58 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  92%|█████████▏| 88/96 [00:22<00:00, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  94%|█████████▍| 90/96 [00:23<00:00, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  96%|█████████▌| 92/96 [00:23<00:00, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:16:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:  99%|█████████▉| 95/96 [00:23<00:00, 15.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:59 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:16:59 - found 0 clusters\n",
      "2024-12-06 01:16:59 - found 8 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas:  33%|███▎      | 1/3 [00:00<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  2.82it/s]\n",
      "Generating Scenarios:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:00 - found 8 clusters\n",
      "2024-12-06 01:17:01 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:01 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:02 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:02 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:03 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:03 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:04 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:05 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:05 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:06 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:06 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:07 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:07 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Scenarios:  50%|█████     | 1/2 [00:07<00:07,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:09 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:10 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:11 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:12 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:13 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:14 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:16 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:17 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:18 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:20 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:21 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Scenarios: 100%|██████████| 2/2 [00:21<00:00, 10.59s/it]\n",
      "Generating Samples:   0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:   4%|▍         | 1/24 [00:01<00:38,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:   8%|▊         | 2/24 [00:02<00:20,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:  29%|██▉       | 7/24 [00:02<00:03,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:24 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:24 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:  42%|████▏     | 10/24 [00:02<00:01,  7.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:24 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:24 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:24 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:  54%|█████▍    | 13/24 [00:02<00:01,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:24 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:  62%|██████▎   | 15/24 [00:03<00:01,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:  71%|███████   | 17/24 [00:03<00:01,  5.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:  79%|███████▉  | 19/24 [00:03<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:26 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:26 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:  88%|████████▊ | 21/24 [00:04<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:26 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-12-06 01:17:26 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples:  96%|█████████▌| 23/24 [00:04<00:00,  5.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-06 01:17:28 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Samples: 100%|██████████| 24/24 [00:06<00:00,  3.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "docs = gen_langchain_docs()\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01muuid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m uuid4, UUID\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Message\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response_series_from_test_set\u001b[39m(test_df: \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[pd\u001b[38;5;241m.\u001b[39mSeries, pd\u001b[38;5;241m.\u001b[39mSeries]:\n\u001b[1;32m      6\u001b[0m     responses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m     retrieved_contexts \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "from service.store_chatbot import gen_answer\n",
    "from uuid import uuid4, UUID\n",
    "from models.message import Message\n",
    "\n",
    "def generate_response_series_from_test_set(test_df: pd.DataFrame) -> tuple[pd.Series, pd.Series]:\n",
    "    responses = []\n",
    "    retrieved_contexts = []\n",
    "    for index, row in test_df.iterrows():\n",
    "        question = row[\"user_input\"]\n",
    "        answer = gen_answer(\n",
    "            UUID(\"f6f200d4-e309-47fc-8cc2-ffac77cdb8ad\"),\n",
    "            uuid4(),\n",
    "            [Message(content=question, author=\"user\")],\n",
    "        )\n",
    "\n",
    "        for key, value in answer.metadata.items():\n",
    "            if key == \"search_faq_database_tool\":\n",
    "                retrieved_contexts.append(value)\n",
    "            else:\n",
    "                retrieved_contexts.append(\"\")\n",
    "        responses.append(answer.content)\n",
    "    return (\n",
    "        pd.Series(responses, dtype=str, name=\"response\"),\n",
    "        pd.Series(retrieved_contexts, dtype=str, name=\"retrieved_contexts\"),\n",
    "    )\n",
    "\n",
    "response_series, retrieved_context_series = generate_response_series_from_test_set(test_df)\n",
    "\n",
    "test_df[\"response\"] = response_series\n",
    "test_df[\"retrieved_contexts\"] = retrieved_context_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "      <th>response</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FPTshop.com.vn thu thập thông tin cá nhân của ...</td>\n",
       "      <td>[1143f59b-29ff-4b7a-909c-b1c146baf092\\n\\nCâu h...</td>\n",
       "      <td>FPTshop.com.vn thu thập thông tin cá nhân của ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the scope of personal information usag...</td>\n",
       "      <td>[66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...</td>\n",
       "      <td>FPTshop.com.vn chỉ sử dụng thông tin cá nhân c...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tôi muốn biết là thông tin cá nhân của khách h...</td>\n",
       "      <td>[af5fea67-0372-4b65-9961-6b52e0f247a1\\n\\nCâu h...</td>\n",
       "      <td>Dữ liệu cá nhân sẽ được lưu trữ đến khi có yêu...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FPT Shop nói là bảo mật thông tin khách hàng r...</td>\n",
       "      <td>[f656f658-4e85-4cc6-a295-a6b8027b2153\\n\\nCâu h...</td>\n",
       "      <td>FPTshop.com.vn cam kết bảo mật thông tin cá nh...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How does FPT Shop comply with PCI DSS for paym...</td>\n",
       "      <td>[b0244ec7-120c-493c-bd0f-c5de100d17ef\\n\\nCâu h...</td>\n",
       "      <td>FPTShop ensures that customer payment card inf...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Làm sao tôi có thể yêu cầu xóa dữ liệu cá nhân...</td>\n",
       "      <td>[57330c48-5708-4505-bbee-2bfd35ab8f1e\\n\\nCâu h...</td>\n",
       "      <td>Khách hàng có thể gửi yêu cầu xóa dữ liệu qua ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FPT Shop co chinh sach giao hang tai nha nhu t...</td>\n",
       "      <td>[7a523fad-e48f-4f31-a5bf-8ebc6f391d7a\\n\\nCâu h...</td>\n",
       "      <td>FPT Shop hỗ trợ giao hàng tại nhà trên toàn qu...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Khi mua hàng trực tuyến tại FPT Shop, nếu đơn ...</td>\n",
       "      <td>[1753ba0e-9093-4d75-863f-a4a493d848cd\\n\\nCâu h...</td>\n",
       "      <td>Đơn hàng có giá trị dưới 50 triệu: Quý khách c...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As a Data Privacy Officer, I am particularly i...</td>\n",
       "      <td>[30f874b1-95a9-4a5c-a61a-e836b0aab46e\\n\\nCâu h...</td>\n",
       "      <td>FPT Shop hỗ trợ lắp đặt miễn phí cho các sản p...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FPT Shop đổi trả sản phẩm ra sao?</td>\n",
       "      <td>[15d705c6-9e7e-4f94-973b-27e87b7e2963\\n\\nCâu h...</td>\n",
       "      <td>Khách hàng có thể đổi sản phẩm nếu phát hiện l...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FPT Shop bảo hành máy đổi trả ra sao?</td>\n",
       "      <td>[3db286df-8b16-4483-be09-2e7d95a02836\\n\\nCâu h...</td>\n",
       "      <td>Máy đổi trả tại FPT Shop được bảo hành 1 đổi 1...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FPT Shop có phải là đại lý ủy quyền của Apple ...</td>\n",
       "      <td>[3940d764-00b4-411c-8cc1-74021db8c2a8\\n\\nCâu h...</td>\n",
       "      <td>FPT Shop là đại lý ủy quyền toàn cầu của Apple...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tôi muốn biết về chính sách bảo hành của FPT S...</td>\n",
       "      <td>[9624cefa-b6a3-4a83-bbc2-6d65a2035a7f\\n\\nCâu h...</td>\n",
       "      <td>Sản phẩm trong tình trạng bị khóa tài khoản cá...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is the process for creating an Apple ID a...</td>\n",
       "      <td>[40106967-e8c2-4a27-8e1a-28f8aafc05d5\\n\\nCâu h...</td>\n",
       "      <td>If you do not have an Apple ID, you can contac...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sản phẩm tại FPT Shop được bảo hành như thế nào?</td>\n",
       "      <td>[2eb94cfd-e3f4-431a-8a5c-dae1add8a658\\n\\nCâu h...</td>\n",
       "      <td>Để đảm bảo quyền lợi của Quý khách hàng khi mu...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Khi mua sản phẩm ĐTDĐ tại FPT Shop, liệu có th...</td>\n",
       "      <td>[32dcae0e-ea6f-4723-bf19-3a6ac0b7f586\\n\\nCâu h...</td>\n",
       "      <td>Đối với các sản phẩm ĐTDĐ, MTB, MTXT, SMARTWAT...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FPT Shop's delivery policy before 20h00?</td>\n",
       "      <td>[682af76f-e365-4e48-afb7-e4d14efec7dc\\n\\nCâu h...</td>\n",
       "      <td>FPT Shop cam kết giao hàng toàn bộ 63 tỉnh thà...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What measures does FPTShop take to ensure the ...</td>\n",
       "      <td>[66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...</td>\n",
       "      <td>FPTShop ensures that customer payment card inf...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are the procedures for customers to manag...</td>\n",
       "      <td>[66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...</td>\n",
       "      <td>FPTshop.com.vn only uses customer personal inf...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FPTshop.com.vn bảo vệ thông tin khách hàng ra ...</td>\n",
       "      <td>[66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...</td>\n",
       "      <td>FPTshop.com.vn cam kết bảo mật thông tin cá nh...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What measures does FPTshop.com.vn take to ensu...</td>\n",
       "      <td>[66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...</td>\n",
       "      <td>FPTshop.com.vn only uses customer personal inf...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Quý khách hàng có thể bảo hành sản phẩm FPT Sh...</td>\n",
       "      <td>[2eb94cfd-e3f4-431a-8a5c-dae1add8a658\\n\\nCâu h...</td>\n",
       "      <td>Để đảm bảo quyền lợi của Quý khách hàng khi mu...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Làm sao mà tôi có thể mua hàng online và thanh...</td>\n",
       "      <td>[ff9c322b-4097-49c7-a2a0-7d9e2a86642c\\n\\nCâu h...</td>\n",
       "      <td>Để mua hàng online tại FPT Shop, trước tiên bạ...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Nếu mà tôi muốn biết cách để cập nhật thông ti...</td>\n",
       "      <td>[4eae7527-8882-4784-a3e0-8621da8c6de2\\n\\nCâu h...</td>\n",
       "      <td>Quý khách vui lòng chờ thêm và kiểm tra lại th...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "      <td>An error occurred: Chainlit context not found</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   FPTshop.com.vn thu thập thông tin cá nhân của ...   \n",
       "1   What is the scope of personal information usag...   \n",
       "2   Tôi muốn biết là thông tin cá nhân của khách h...   \n",
       "3   FPT Shop nói là bảo mật thông tin khách hàng r...   \n",
       "4   How does FPT Shop comply with PCI DSS for paym...   \n",
       "5   Làm sao tôi có thể yêu cầu xóa dữ liệu cá nhân...   \n",
       "6   FPT Shop co chinh sach giao hang tai nha nhu t...   \n",
       "7   Khi mua hàng trực tuyến tại FPT Shop, nếu đơn ...   \n",
       "8   As a Data Privacy Officer, I am particularly i...   \n",
       "9                   FPT Shop đổi trả sản phẩm ra sao?   \n",
       "10              FPT Shop bảo hành máy đổi trả ra sao?   \n",
       "11  FPT Shop có phải là đại lý ủy quyền của Apple ...   \n",
       "12  Tôi muốn biết về chính sách bảo hành của FPT S...   \n",
       "13  What is the process for creating an Apple ID a...   \n",
       "14   Sản phẩm tại FPT Shop được bảo hành như thế nào?   \n",
       "15  Khi mua sản phẩm ĐTDĐ tại FPT Shop, liệu có th...   \n",
       "16           FPT Shop's delivery policy before 20h00?   \n",
       "17  What measures does FPTShop take to ensure the ...   \n",
       "18  What are the procedures for customers to manag...   \n",
       "19  FPTshop.com.vn bảo vệ thông tin khách hàng ra ...   \n",
       "20  What measures does FPTshop.com.vn take to ensu...   \n",
       "21  Quý khách hàng có thể bảo hành sản phẩm FPT Sh...   \n",
       "22  Làm sao mà tôi có thể mua hàng online và thanh...   \n",
       "23  Nếu mà tôi muốn biết cách để cập nhật thông ti...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [1143f59b-29ff-4b7a-909c-b1c146baf092\\n\\nCâu h...   \n",
       "1   [66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...   \n",
       "2   [af5fea67-0372-4b65-9961-6b52e0f247a1\\n\\nCâu h...   \n",
       "3   [f656f658-4e85-4cc6-a295-a6b8027b2153\\n\\nCâu h...   \n",
       "4   [b0244ec7-120c-493c-bd0f-c5de100d17ef\\n\\nCâu h...   \n",
       "5   [57330c48-5708-4505-bbee-2bfd35ab8f1e\\n\\nCâu h...   \n",
       "6   [7a523fad-e48f-4f31-a5bf-8ebc6f391d7a\\n\\nCâu h...   \n",
       "7   [1753ba0e-9093-4d75-863f-a4a493d848cd\\n\\nCâu h...   \n",
       "8   [30f874b1-95a9-4a5c-a61a-e836b0aab46e\\n\\nCâu h...   \n",
       "9   [15d705c6-9e7e-4f94-973b-27e87b7e2963\\n\\nCâu h...   \n",
       "10  [3db286df-8b16-4483-be09-2e7d95a02836\\n\\nCâu h...   \n",
       "11  [3940d764-00b4-411c-8cc1-74021db8c2a8\\n\\nCâu h...   \n",
       "12  [9624cefa-b6a3-4a83-bbc2-6d65a2035a7f\\n\\nCâu h...   \n",
       "13  [40106967-e8c2-4a27-8e1a-28f8aafc05d5\\n\\nCâu h...   \n",
       "14  [2eb94cfd-e3f4-431a-8a5c-dae1add8a658\\n\\nCâu h...   \n",
       "15  [32dcae0e-ea6f-4723-bf19-3a6ac0b7f586\\n\\nCâu h...   \n",
       "16  [682af76f-e365-4e48-afb7-e4d14efec7dc\\n\\nCâu h...   \n",
       "17  [66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...   \n",
       "18  [66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...   \n",
       "19  [66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...   \n",
       "20  [66d17c2a-af11-4ac8-b154-68fb1ee86281\\n\\nCâu h...   \n",
       "21  [2eb94cfd-e3f4-431a-8a5c-dae1add8a658\\n\\nCâu h...   \n",
       "22  [ff9c322b-4097-49c7-a2a0-7d9e2a86642c\\n\\nCâu h...   \n",
       "23  [4eae7527-8882-4784-a3e0-8621da8c6de2\\n\\nCâu h...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   FPTshop.com.vn thu thập thông tin cá nhân của ...   \n",
       "1   FPTshop.com.vn chỉ sử dụng thông tin cá nhân c...   \n",
       "2   Dữ liệu cá nhân sẽ được lưu trữ đến khi có yêu...   \n",
       "3   FPTshop.com.vn cam kết bảo mật thông tin cá nh...   \n",
       "4   FPTShop ensures that customer payment card inf...   \n",
       "5   Khách hàng có thể gửi yêu cầu xóa dữ liệu qua ...   \n",
       "6   FPT Shop hỗ trợ giao hàng tại nhà trên toàn qu...   \n",
       "7   Đơn hàng có giá trị dưới 50 triệu: Quý khách c...   \n",
       "8   FPT Shop hỗ trợ lắp đặt miễn phí cho các sản p...   \n",
       "9   Khách hàng có thể đổi sản phẩm nếu phát hiện l...   \n",
       "10  Máy đổi trả tại FPT Shop được bảo hành 1 đổi 1...   \n",
       "11  FPT Shop là đại lý ủy quyền toàn cầu của Apple...   \n",
       "12  Sản phẩm trong tình trạng bị khóa tài khoản cá...   \n",
       "13  If you do not have an Apple ID, you can contac...   \n",
       "14  Để đảm bảo quyền lợi của Quý khách hàng khi mu...   \n",
       "15  Đối với các sản phẩm ĐTDĐ, MTB, MTXT, SMARTWAT...   \n",
       "16  FPT Shop cam kết giao hàng toàn bộ 63 tỉnh thà...   \n",
       "17  FPTShop ensures that customer payment card inf...   \n",
       "18  FPTshop.com.vn only uses customer personal inf...   \n",
       "19  FPTshop.com.vn cam kết bảo mật thông tin cá nh...   \n",
       "20  FPTshop.com.vn only uses customer personal inf...   \n",
       "21  Để đảm bảo quyền lợi của Quý khách hàng khi mu...   \n",
       "22  Để mua hàng online tại FPT Shop, trước tiên bạ...   \n",
       "23  Quý khách vui lòng chờ thêm và kiểm tra lại th...   \n",
       "\n",
       "                        synthesizer_name  \\\n",
       "0   single_hop_specifc_query_synthesizer   \n",
       "1   single_hop_specifc_query_synthesizer   \n",
       "2   single_hop_specifc_query_synthesizer   \n",
       "3   single_hop_specifc_query_synthesizer   \n",
       "4   single_hop_specifc_query_synthesizer   \n",
       "5   single_hop_specifc_query_synthesizer   \n",
       "6   single_hop_specifc_query_synthesizer   \n",
       "7   single_hop_specifc_query_synthesizer   \n",
       "8   single_hop_specifc_query_synthesizer   \n",
       "9   single_hop_specifc_query_synthesizer   \n",
       "10  single_hop_specifc_query_synthesizer   \n",
       "11  single_hop_specifc_query_synthesizer   \n",
       "12  single_hop_specifc_query_synthesizer   \n",
       "13  single_hop_specifc_query_synthesizer   \n",
       "14  single_hop_specifc_query_synthesizer   \n",
       "15  single_hop_specifc_query_synthesizer   \n",
       "16  single_hop_specifc_query_synthesizer   \n",
       "17  multi_hop_specific_query_synthesizer   \n",
       "18  multi_hop_specific_query_synthesizer   \n",
       "19  multi_hop_specific_query_synthesizer   \n",
       "20  multi_hop_specific_query_synthesizer   \n",
       "21  multi_hop_specific_query_synthesizer   \n",
       "22  multi_hop_specific_query_synthesizer   \n",
       "23  multi_hop_specific_query_synthesizer   \n",
       "\n",
       "                                         response retrieved_contexts  \n",
       "0   An error occurred: Chainlit context not found                NaN  \n",
       "1   An error occurred: Chainlit context not found                NaN  \n",
       "2   An error occurred: Chainlit context not found                NaN  \n",
       "3   An error occurred: Chainlit context not found                NaN  \n",
       "4   An error occurred: Chainlit context not found                NaN  \n",
       "5   An error occurred: Chainlit context not found                NaN  \n",
       "6   An error occurred: Chainlit context not found                NaN  \n",
       "7   An error occurred: Chainlit context not found                NaN  \n",
       "8   An error occurred: Chainlit context not found                NaN  \n",
       "9   An error occurred: Chainlit context not found                NaN  \n",
       "10  An error occurred: Chainlit context not found                NaN  \n",
       "11  An error occurred: Chainlit context not found                NaN  \n",
       "12  An error occurred: Chainlit context not found                NaN  \n",
       "13  An error occurred: Chainlit context not found                NaN  \n",
       "14  An error occurred: Chainlit context not found                NaN  \n",
       "15  An error occurred: Chainlit context not found                NaN  \n",
       "16  An error occurred: Chainlit context not found                NaN  \n",
       "17  An error occurred: Chainlit context not found                NaN  \n",
       "18  An error occurred: Chainlit context not found                NaN  \n",
       "19  An error occurred: Chainlit context not found                NaN  \n",
       "20  An error occurred: Chainlit context not found                NaN  \n",
       "21  An error occurred: Chainlit context not found                NaN  \n",
       "22  An error occurred: Chainlit context not found                NaN  \n",
       "23  An error occurred: Chainlit context not found                NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for SingleTurnSample\nretrieved_contexts\n  Input should be a valid list [type=list_type, input_value=nan, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/list_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationDataset\n\u001b[0;32m----> 3\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mEvaluationDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/chatbot-tlcn-L8ehHy6a-py3.10/lib/python3.10/site-packages/ragas/dataset_schema.py:209\u001b[0m, in \u001b[0;36mRagasDataset.from_pandas\u001b[0;34m(cls, dataframe)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pandas\u001b[39m(\u001b[38;5;28mcls\u001b[39m, dataframe: PandasDataframe):\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates an EvaluationDataset from a pandas DataFrame.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/chatbot-tlcn-L8ehHy6a-py3.10/lib/python3.10/site-packages/ragas/dataset_schema.py:348\u001b[0m, in \u001b[0;36mEvaluationDataset.from_list\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    346\u001b[0m     samples\u001b[38;5;241m.\u001b[39mextend(MultiTurnSample(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msample) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m     \u001b[43msamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSingleTurnSample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(samples\u001b[38;5;241m=\u001b[39msamples)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/chatbot-tlcn-L8ehHy6a-py3.10/lib/python3.10/site-packages/ragas/dataset_schema.py:348\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    346\u001b[0m     samples\u001b[38;5;241m.\u001b[39mextend(MultiTurnSample(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msample) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 348\u001b[0m     samples\u001b[38;5;241m.\u001b[39mextend(\u001b[43mSingleTurnSample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(samples\u001b[38;5;241m=\u001b[39msamples)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/chatbot-tlcn-L8ehHy6a-py3.10/lib/python3.10/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for SingleTurnSample\nretrieved_contexts\n  Input should be a valid list [type=list_type, input_value=nan, input_type=float]\n    For further information visit https://errors.pydantic.dev/2.10/v/list_type"
     ]
    }
   ],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "eval_dataset = EvaluationDataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluationDataset.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o-mini\"))\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings(model=model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The metric [context_recall] that is used requires the following additional columns ['retrieved_contexts'] to be present in the dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[1;32m      4\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     LLMContextRecall(llm\u001b[38;5;241m=\u001b[39mevaluator_llm),\n\u001b[1;32m      6\u001b[0m     FactualCorrectness(llm\u001b[38;5;241m=\u001b[39mevaluator_llm),\n\u001b[1;32m      7\u001b[0m     Faithfulness(llm\u001b[38;5;241m=\u001b[39mevaluator_llm),\n\u001b[1;32m      8\u001b[0m     SemanticSimilarity(embeddings\u001b[38;5;241m=\u001b[39mevaluator_embeddings),\n\u001b[1;32m      9\u001b[0m ]\n\u001b[0;32m---> 10\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/chatbot-tlcn-L8ehHy6a-py3.10/lib/python3.10/site-packages/ragas/_analytics.py:130\u001b[0m, in \u001b[0;36mtrack_was_completed.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[1;32m    129\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m--> 130\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     track(IsCompleteEvent(event_type\u001b[38;5;241m=\u001b[39mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_completed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/chatbot-tlcn-L8ehHy6a-py3.10/lib/python3.10/site-packages/ragas/evaluation.py:179\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, llm, embeddings, callbacks, in_ci, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size)\u001b[0m\n\u001b[1;32m    176\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m EvaluationDataset\u001b[38;5;241m.\u001b[39mfrom_list(dataset\u001b[38;5;241m.\u001b[39mto_list())\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, EvaluationDataset):\n\u001b[0;32m--> 179\u001b[0m     \u001b[43mvalidate_required_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     validate_supported_metrics(dataset, metrics)\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# set the llm and embeddings\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/chatbot-tlcn-L8ehHy6a-py3.10/lib/python3.10/site-packages/ragas/validation.py:63\u001b[0m, in \u001b[0;36mvalidate_required_columns\u001b[0;34m(ds, metrics)\u001b[0m\n\u001b[1;32m     61\u001b[0m available_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(ds\u001b[38;5;241m.\u001b[39mfeatures())\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m required_columns\u001b[38;5;241m.\u001b[39missubset(available_columns):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe metric [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] that is used requires the following \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madditional columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(required_columns\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mavailable_columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto be present in the dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The metric [context_recall] that is used requires the following additional columns ['retrieved_contexts'] to be present in the dataset."
     ]
    }
   ],
   "source": [
    "from ragas.metrics import LLMContextRecall, FactualCorrectness, Faithfulness, SemanticSimilarity\n",
    "from ragas import evaluate\n",
    "\n",
    "metrics = [\n",
    "    LLMContextRecall(llm=evaluator_llm),\n",
    "    FactualCorrectness(llm=evaluator_llm),\n",
    "    Faithfulness(llm=evaluator_llm),\n",
    "    SemanticSimilarity(embeddings=evaluator_embeddings),\n",
    "]\n",
    "results = evaluate(dataset=eval_dataset, metrics=metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-tlcn-L8ehHy6a-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
