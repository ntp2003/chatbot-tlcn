{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import LLMTestCase, ConversationalTestCase\n",
    "from deepeval.synthesizer import Synthesizer\n",
    "from deepeval.dataset import Golden\n",
    "from deepeval.synthesizer.config import StylingConfig\n",
    "from repositories.faq import get_all as get_all_faqs\n",
    "from models.faq import FAQModel\n",
    "import json\n",
    "from typing import List, Dict\n",
    "import random\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI(api_key=\"sk-BJpqmcWfn3O9bvr2eryf6Uyf1m7VpSQpL7cNxGGlZccRrfA1\",base_url=\"https://open.keyai.shop/v1\")\n",
    "faqs = get_all_faqs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs_questions = [faq.question for faq in faqs]\n",
    "faq_questions_string = \"\\\\n-\".join([f\"- {question}\" for question in faqs_questions])\n",
    "prompt_template = \"\"\"\n",
    "Bạn là một Chuyên gia Thiết kế Test Case AI, chuyên tạo ra các kịch bản hội thoại đa dạng và thực tế để đánh giá chatbot tiếng Việt.\n",
    "\n",
    "NHIỆM VỤ:\n",
    "Mục tiêu của bạn là tạo ra một bộ dữ liệu gồm chính xác 30 kịch bản `ConversationalTestCase` . Mỗi kịch bản sẽ được sử dụng để kiểm tra khả năng của chatbot trong việc xử lý các truy vấn khác nhau từ người dùng và cách sử dụng đại từ nhân xưng đúng đắn dựa trên user_gender hoặc pronoun trong user_input.\n",
    "\n",
    "DANH SÁCH CÂU HỎI FAQ THAM KHẢO (Sử dụng để simulate các câu hỏi của người dùng):\n",
    "{faq_questions_string}\n",
    "\n",
    "YÊU CẦU CHI TIẾT CHO MỖI `ConversationalTestCase`:\n",
    "Mỗi `ConversationalTestCase` phải là một đối tượng JSON và có các đặc điểm sau:\n",
    "1.  Một trường `conversation_id` (chuỗi, ví dụ: \"conv_01\", \"conv_02\", ... , \"conv_30\").\n",
    "2.  Một trường `turns` (danh sách). Danh sách này phải chứa từ 1 đến 4 đối tượng, mỗi đối tượng đại diện cho một lượt của người dùng và sẽ được dùng để tạo một `LLMTestCase` sau này.\n",
    "3.  Đối với mỗi đối tượng \"turn\" trong danh sách `turns`:\n",
    "    a.  `user_input` (chuỗi): Tạo một câu hỏi tự nhiên từ phía người dùng. Câu hỏi này NÊN được lấy cảm hứng từ hoặc dẫn dắt đến một trong các câu hỏi trong \"DANH SÁCH CÂU HỎI FAQ THAM KHẢO\" ở trên.\n",
    "        -   **Quan trọng:** Câu hỏi của người dùng PHẢI sử dụng đa dạng các đại từ nhân xưng tiếng Việt để tự xưng, ví dụ: \"anh\", \"chị\", \"cô\", \"chú\", \"bác\", \"em\", \"tui\", \"tôi\", \"mình\".\n",
    "        -   Cũng bao gồm các trường hợp người dùng KHÔNG sử dụng đại từ nhân xưng rõ ràng (ví dụ: \"Làm thế nào để...\", \"Cho hỏi về...\", \"Sản phẩm này còn không?\").\n",
    "        -   Đảm bảo sự đa dạng và phân bổ hợp lý các loại đại từ này trong toàn bộ 30 kịch bản.\n",
    "        -   Ví dụ: \"Anh muốn hỏi cách tra cứu về hóa đơn đã mua hàng tại FPT Shop?\", \"Làm thế nào để kiểm tra được tình trạng máy đã gửi đi bảo hành tại FPT Shop?\", \"Em ơi, chị cần hỗ trợ về vấn đề tài khoản.\", \"Chú hỏi chút, cửa hàng mình có chính sách cho khách hàng thân thiết không?\"\n",
    "    b.  `user_gender_context` (chuỗi hoặc null): Chỉ định ngữ cảnh giới tính của người dùng cho lượt đó. Giá trị có thể là một trong các chuỗi: \"male\", \"female\", \"unknown\". Trong một số trường hợp, giá trị này có thể là `null` (hoặc trường này có thể không xuất hiện), cho biết không có thông tin giới tính cụ thể nào được cung cấp cho lượt đó. Phân bổ các tùy chọn này một cách thực tế và đa dạng.\n",
    "    c.  `bot_actual_output_placeholder` (chuỗi): Trường này PHẢI LUÔN LUÔN là một chuỗi rỗng (`\"\"`). Nó sẽ được điền vào sau bởi phản hồi thực tế của chatbot.\n",
    "\n",
    "YÊU CẦU CHO TOÀN BỘ BỘ DỮ LIỆU (30 `ConversationalTestCase`):\n",
    "1.  Tạo ra CHÍNH XÁC 30 kịch bản `ConversationalTestCase`.\n",
    "2.  Đảm bảo sự đa dạng cao trong toàn bộ 30 kịch bản về các mặt sau:\n",
    "    * Bắt buộc dựa trên DANH SÁCH CÂU HỎI FAQ THAM KHẢO gốc ở trên.\n",
    "    * Số lượng \"turns\" trong mỗi hội thoại (từ 1 đến 4).\n",
    "    * Đại từ nhân xưng được sử dụng trong `user_input`.\n",
    "    * Giá trị `user_gender_context` được cung cấp cho mỗi lượt.\n",
    "    * Phong cách hỏi của người dùng (trang trọng, thân mật, trực tiếp, v.v.).\n",
    "\n",
    "ĐỊNH DẠNG ĐẦU RA:\n",
    "Trả về TOÀN BỘ bộ dữ liệu dưới dạng MỘT MẢNG JSON DUY NHẤT (a single JSON array). Mỗi phần tử của mảng là một đối tượng JSON đại diện cho một `ConversationalTestCase`, tuân thủ cấu trúc đã mô tả ở trên (với các khóa `conversation_id`, `turns`; và trong mỗi turn là `user_input`, `user_gender_context`, `bot_actual_output_placeholder`).\n",
    "\n",
    "VÍ DỤ VỀ CẤU TRÚC CHO MỘT `ConversationalTestCase` TRONG MẢNG JSON:\n",
    "```json\n",
    "{\n",
    "  \"conversation_id\": \"conv_01\",\n",
    "  \"turns\": [\n",
    "    {\n",
    "      \"user_input\": \"Anh muốn hỏi cách tra cứu về hóa đơn đã mua hàng tại FPT Shop?\",\n",
    "      \"user_gender_context\": \"male\",\n",
    "      \"bot_actual_output_placeholder\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"user_input\": \"Nếu hóa đơn đó mua hơn 1 năm rồi thì có tìm lại được không shop?\",\n",
    "      \"user_gender_context\": \"male\",\n",
    "      \"bot_actual_output_placeholder\": \"\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#final_prompt = prompt_template.format(faq_questions_string=faq_questions_string)\n",
    "final_prompt = prompt_template.replace(\"{faq_questions_string}\", faq_questions_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\", \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Bạn là một AI hỗ trợ tạo dữ liệu test case cho deepeval đánh giá chatbot tiếng việt.\"},\n",
    "            {\"role\": \"user\", \"content\": final_prompt}\n",
    "        ],\n",
    "         # response_format={\"type\": \"json_object\"}, # Nếu model hỗ trợ và bạn muốn JSON object chứa array\n",
    "        temperature=0. # Điều chỉnh để có sự đa dạng\n",
    "    )\n",
    "generated_json_string = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the generated JSON string to a file\n",
    "with open(\"conversation_tone.json\", \"w\") as f:\n",
    "    f.write(generated_json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lỗi không xác định khi xử lý: ConversationalTestCase.__init__() got an unexpected keyword argument 'messages'\n"
     ]
    }
   ],
   "source": [
    "cleaned_json_string = generated_json_string\n",
    "\n",
    "# Remove the Markdown code block delimiters\n",
    "# Common patterns are \"```json\\n\" at the start and \"\\n```\" at the end\n",
    "# Or just \"```json\" and \"```\" if there are no newlines separating them from the content\n",
    "\n",
    "# More robust cleaning:\n",
    "# 1. Remove \"```json\" from the start.\n",
    "# 2. Remove \"```\" from the end.\n",
    "# 3. Strip any surrounding whitespace (including newlines) that might be left.\n",
    "\n",
    "if cleaned_json_string.startswith(\"```json\"):\n",
    "    cleaned_json_string = cleaned_json_string[len(\"```json\"):]\n",
    "elif cleaned_json_string.startswith(\"```\"): # If it's just ``` without 'json'\n",
    "    cleaned_json_string = cleaned_json_string[len(\"```\"):]\n",
    "\n",
    "if cleaned_json_string.endswith(\"```\"):\n",
    "    cleaned_json_string = cleaned_json_string[:-len(\"```\")]\n",
    "\n",
    "# Strip whitespace (like newlines or spaces) from the beginning and end\n",
    "cleaned_json_string = cleaned_json_string.strip()\n",
    "# --- End of fix ---\n",
    "\n",
    "try:\n",
    "    parsed_data = json.loads(cleaned_json_string) # Use the cleaned string\n",
    "    deepeval_test_cases = []\n",
    "    for conv_data in parsed_data:\n",
    "        llm_turns = []\n",
    "        for turn_data in conv_data.get(\"turns\", []):\n",
    "            user_input = turn_data.get(\"user_input\")\n",
    "            gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "            actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")\n",
    "\n",
    "            current_context = []\n",
    "            if gender_context_val and gender_context_val != \"null\": #Check for string \"null\"\n",
    "                current_context.append(f\"User gender: {gender_context_val}\")\n",
    "            \n",
    "            if user_input: #Only add turn if user_input exists\n",
    "                llm_turns.append(\n",
    "                    LLMTestCase(\n",
    "                        input=user_input,\n",
    "                        actual_output=actual_output_placeholder, # Will be filled later\n",
    "                        context=current_context if current_context else None\n",
    "                    )\n",
    "                )\n",
    "        if llm_turns: #Only add ConversationalTestCase if there are valid turns\n",
    "            deepeval_test_cases.append(ConversationalTestCase(messages=llm_turns))\n",
    "\n",
    "    print(f\"Đã tạo thành công {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "    # Now you can use deepeval_test_cases to run evaluations after filling actual_output\n",
    "\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Lỗi giải mã JSON: {e}\")\n",
    "    # Print the cleaned string for better debugging if error persists\n",
    "    print(f\"Dữ liệu đã được làm sạch (một phần): {cleaned_json_string[:500]}...\")\n",
    "    print(f\"Dữ liệu gốc (một phần): {generated_json_string[:500]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi không xác định khi xử lý: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã tạo thành công 30 ConversationalTestCase objects.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from deepeval.test_case import LLMTestCase, ConversationalTestCase\n",
    "\n",
    "\n",
    "try:\n",
    "        #parsed_data = json.loads(generated_json_string)\n",
    "        # load data from json file\n",
    "        with open(\"conversation_tone.json\", \"r\") as f:\n",
    "            parsed_data = json.load(f)\n",
    "        deepeval_test_cases = []\n",
    "        for conv_data in parsed_data:\n",
    "            llm_turns = []\n",
    "            for turn_data in conv_data.get(\"turns\", []):\n",
    "                user_input = turn_data.get(\"user_input\")\n",
    "                gender_context_val = turn_data.get(\"user_gender_context\")\n",
    "                actual_output_placeholder = turn_data.get(\"bot_actual_output_placeholder\", \"\")  #Nên là \"\"\n",
    "\n",
    "                current_context = []\n",
    "                if gender_context_val and gender_context_val != \"null\":  #Kiểm tra null dưới dạng chuỗi\n",
    "                    current_context.append(f\"User gender: {gender_context_val}\")\n",
    "            \n",
    "                if user_input:  #Chỉ thêm turn nếu có user_input\n",
    "                    llm_turns.append(\n",
    "                        LLMTestCase(\n",
    "                            input=user_input,\n",
    "                            actual_output=actual_output_placeholder, # Sẽ được điền sau\n",
    "                            context=current_context if current_context else None  # DeepEval có thể muốn None nếu context rỗng\n",
    "                        )\n",
    "                    )\n",
    "            if llm_turns:  #Chỉ thêm ConversationalTestCase nếu có turns hợp lệ\n",
    "                deepeval_test_cases.append(ConversationalTestCase(turns=llm_turns))  #DeepEval v0.20+ dùng messages\n",
    "                                                                                    #(hoặc `turns=llm_turns` cho phiên bản cũ hơn)\n",
    "\n",
    "        print(f\"Đã tạo thành công {len(deepeval_test_cases)} ConversationalTestCase objects.\")\n",
    "        #Bây giờ bạn có thể dùng deepeval_test_cases để chạy đánh giá sau khi điền actual_output\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Lỗi giải mã JSON: {e}\")\n",
    "    print(f\"Dữ liệu nhận được: {generated_json_string[:500]}...\")  #In một phần dữ liệu lỗi\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi không xác định khi xử lý: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.test_case import ConversationalTestCase, LLMTestCase\n",
    "from deepeval.metrics import ConversationalGEval\n",
    "\n",
    "from deepeval.test_case import LLMTestCaseParams\n",
    "from deepeval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 11:43:25 - Loaded .env file\n",
      "2025-06-01 11:43:29 - >>> {\"query\": \"query DefaultEntity {\\n  viewer {\\n    username\\n    defaultEntity {\\n      name\\n    }\\n  }\\n}\"}\n",
      "2025-06-01 11:43:30 - <<< {\"data\":{\"viewer\":{\"username\":\"phatnguyen-041203\",\"defaultEntity\":{\"name\":\"tlcn\"}}}}\n",
      "weave version 0.51.49 is available!  To upgrade, please run:\n",
      " $ pip install weave --upgrade\n",
      "Logged in as Weights & Biases user: phatnguyen-041203.\n",
      "View Weave data at https://wandb.ai/tlcn/CHATBOT-TLCN/weave\n",
      "2025-06-01 11:43:31 - file_cache is only supported with oauth2client<4.0.0\n"
     ]
    }
   ],
   "source": [
    "from repositories.user import create as create_user, CreateUserModel\n",
    "from repositories.thread import create as create_thread, CreateThreadModel\n",
    "from service.store_chatbot_v2 import gen_answer\n",
    "from uuid import uuid4\n",
    "from models.user import UserRole    \n",
    "\n",
    "def get_actual_answer(input: str, gender_context: str) -> str:\n",
    "    user = create_user(\n",
    "        CreateUserModel(user_name=str(uuid4()), role=UserRole.chainlit_user)\n",
    "    )\n",
    "    thread = create_thread(CreateThreadModel(user_id=user.id, name=user.user_name))\n",
    "\n",
    "    # Add gender context to the conversation\n",
    "    history = [\n",
    "        {\"role\": \"system\", \"content\": \"##BASE KNOWLEDGE:\\n\" + gender_context},\n",
    "        {\"role\": \"user\", \"content\": str(input)}\n",
    "    ]\n",
    "\n",
    "    return gen_answer(\n",
    "        thread_id=thread.id,\n",
    "        history=history,\n",
    "        user_id=user.id,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pronoun_consistency_metric = ConversationalGEval(\n",
    "    name=\"Vietnamese Pronoun Consistency\",\n",
    "    criteria=\"\"\"Đánh giá khả năng của chatbot trong việc sử dụng đại từ nhân xưng tiếng Việt một cách chính xác và nhất quán trong suốt cuộc hội thoại. Cụ thể:\n",
    "    1. Chatbot (assistant) trong 'actual_output' phải LUÔN LUÔN tự xưng là 'em'.  Ví dụ: 'dạ em chào anh', 'em có thể giúp gì ạ'. KHÔNG được dùng 'tôi', 'mình'\n",
    "    2. Cách chatbot gọi người dùng (user) phải dựa trên thông tin được cung cấp hoặc cách người dùng tự xưng:\n",
    "        - Nếu 'User gender' được cung cấp là 'male' hoặc người dùng tự xưng là 'anh', chatbot phải gọi người dùng là 'anh'.\n",
    "        - Nếu 'User gender' được cung cấp là 'female' hoặc người dùng tự xưng là 'chị', chatbot phải gọi người dùng là 'chị'.\n",
    "        - Nếu người dùng tự xưng là 'chú', chatbot phải gọi người dùng là 'chú' và tự xưng 'cháu'.\n",
    "        - Nếu người dùng tự xưng là 'cô', chatbot phải gọi người dùng là 'cô' và tự xưng 'cháu'. \n",
    "        - Nếu 'User gender' là 'unknown' hoặc không được cung cấp, và người dùng không tự xưng theo một đại từ cụ thể nào ở trên, chatbot phải gọi người dùng là 'anh/chị'.\n",
    "    3. Tính nhất quán: Chatbot phải duy trì cách xưng hô đã được thiết lập với người dùng một cách nhất quán trong các lượt trả lời tiếp theo trong cùng một cuộc hội thoại, trừ khi có thông tin mới rõ ràng thay đổi cách xưng hô.\n",
    "    4. Không được sử dụng các cách xưng hô không phù hợp hoặc thiếu tôn trọng.\n",
    "      HƯỚNG DẪN CHẤM ĐIỂM:\n",
    "    - Điểm 1.0: Tuân thủ hoàn hảo tất cả các quy tắc trên trong mọi lượt của hội thoại.\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot tự xưng sai (ví dụ: xưng 'tôi' thay vì 'em').\n",
    "    - Phạt nặng (điểm gần 0): Nếu chatbot gọi sai người dùng một cách rõ ràng (ví dụ: context là 'User gender: male' nhưng chatbot gọi là 'chị').\n",
    "    - Phạt nhẹ hơn: Nếu chatbot dùng 'anh/chị' trong trường hợp có thể suy luận giới tính từ input nhưng không rõ ràng 100%.\n",
    "    - Xem xét toàn bộ cuộc hội thoại để đánh giá tính nhất quán.\n",
    "    \"\"\",\n",
    "    \n",
    "    evaluation_params=[\n",
    "        LLMTestCaseParams.INPUT,            # Để phân tích input của user (ví dụ: \"anh muốn hỏi...\")\n",
    "        LLMTestCaseParams.ACTUAL_OUTPUT,    # Để phân tích output của model\n",
    "        LLMTestCaseParams.CONTEXT,        # Nếu thông tin `User gender` được truyền qua context cho mỗi lượt\n",
    "    ]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anh muốn hỏi cách tra cứu về hóa đơn đã mua hàng tại FPT Shop?\n",
      "User gender: male\n",
      "Nếu hóa đơn đó mua hơn 1 năm rồi thì có tìm lại được không shop?\n",
      "User gender: male\n"
     ]
    }
   ],
   "source": [
    "tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    print(turn.input)\n",
    "    # turn list to str\n",
    "    turn_str = \"\"\n",
    "    for t in turn.context:\n",
    "        turn_str += t\n",
    "    print(turn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_context_to_str(lst: list) -> str:\n",
    "    turn_str = \"\"\n",
    "    for t in lst:\n",
    "        turn_str += t\n",
    "    return turn_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-23bb-7fe2-b9c9-7c4767e75b93\n",
      "2025-06-01 11:43:53 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 11:43:54 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 12\n",
      "faq id : 16\n",
      "faq id : 62\n",
      "faq id : 18\n",
      "2025-06-01 11:44:00 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: 594337d9-7381-4a39-a3b1-233965240458 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='Dạ chào anh. Anh có thể tra cứu hóa đơn mua hàng tại FPT Shop [tại đây](https://hddt.fptshop.com.vn/). Nếu anh cần thêm thông tin hoặc hỗ trợ khác, đừng ngần ngại cho em biết nhé.'\n",
      "Dạ chào anh. Anh có thể tra cứu hóa đơn mua hàng tại FPT Shop [tại đây](https://hddt.fptshop.com.vn/). Nếu anh cần thêm thông tin hoặc hỗ trợ khác, đừng ngần ngại cho em biết nhé.\n",
      "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-4883-7120-ad90-0c8cad66e6a3\n",
      "2025-06-01 11:44:01 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "User request: {'user_demand': <ProductType.UNDETERMINED: 'undetermined'>, 'user_info': {'phone_number': None, 'email': None}}\n",
      "Detect demand response: type='finished' content='The user request has been successfully processed.' instructions=[] UserIntent(is_user_needs_other_suggestions=False, product_type=None)\n",
      "2025-06-01 11:44:01 - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "faq id : 79\n",
      "2025-06-01 11:44:10 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Updating user memory with id: c8230f9e-ef8d-4764-8903-659fcb566532 and data: {'user_demand': None, 'product_name': None, 'brand_code': None, 'brand_name': None, 'min_price': None, 'max_price': None, 'phone_number': None, 'email': None, 'intent': {'is_user_needs_other_suggestions': False, 'product_type': None}, 'current_filter': {'product_name': None}, 'consultation_status': {'is_recommending': False}}\n",
      "Undetermined generate response: type='finished' content='Dạ thưa anh, theo quy định của FPT Shop, hóa đơn mua hàng sẽ được lưu trữ trong hệ thống của cửa hàng trong vòng 1 năm kể từ ngày mua. Sau thời gian này, việc truy xuất hóa đơn sẽ gặp khó khăn và không đảm bảo chính xác. Tuy nhiên, anh có thể thử liên hệ tổng đài hỗ trợ của FPT Shop (1800.6601) để được kiểm tra thêm thông tin. Anh có cần em hỗ trợ tìm hiểu về các sản phẩm công nghệ hiện có tại FPT Shop không ạ?'\n",
      "Dạ thưa anh, theo quy định của FPT Shop, hóa đơn mua hàng sẽ được lưu trữ trong hệ thống của cửa hàng trong vòng 1 năm kể từ ngày mua. Sau thời gian này, việc truy xuất hóa đơn sẽ gặp khó khăn và không đảm bảo chính xác. Tuy nhiên, anh có thể thử liên hệ tổng đài hỗ trợ của FPT Shop (1800.6601) để được kiểm tra thêm thông tin. Anh có cần em hỗ trợ tìm hiểu về các sản phẩm công nghệ hiện có tại FPT Shop không ạ?\n"
     ]
    }
   ],
   "source": [
    "tc = deepeval_test_cases[0]\n",
    "for turn in tc.turns:\n",
    "    turn.actual_output = get_actual_answer(turn.input, lst_context_to_str(turn.context))\n",
    "    print(turn.actual_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643917bcb1c443bbb807a432adff996c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-93c8-7562-814c-7645e051be0a\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-93c8-7562-814c-7645e051be0a\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 11:44:23 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-a22c-7af2-b7ed-2c1477e1f6cf\n",
       "</pre>\n"
      ],
      "text/plain": [
       "🍩 https://wandb.ai/tlcn/CHATBOT-TLCN/r/call/01972b4e-a22c-7af2-b7ed-2c1477e1f6cf\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 11:44:25 - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999998 The chatbot consistently uses 'em' for self-reference and 'anh' for the user, aligning with the user's male gender context. Pronoun usage is consistent and appropriate throughout the conversation.\n"
     ]
    }
   ],
   "source": [
    "pronoun_consistency_metric.measure(tc)\n",
    "print(pronoun_consistency_metric.score, pronoun_consistency_metric.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ConversationalTestCase' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mpronoun_consistency_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/chatbot-tlcn/.venv/lib/python3.12/site-packages/deepeval/evaluate/evaluate.py:257\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(test_cases, metrics, hyperparameters, goldens, observed_callback, identifier, async_config, display_config, cache_config, error_config)\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EvaluationResult(\n\u001b[1;32m    253\u001b[0m         test_results\u001b[38;5;241m=\u001b[39mtest_results, confident_link\u001b[38;5;241m=\u001b[39mconfident_link\n\u001b[1;32m    254\u001b[0m     )\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_cases \u001b[38;5;129;01mand\u001b[39;00m metrics:\n\u001b[0;32m--> 257\u001b[0m     \u001b[43mcheck_valid_test_cases_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     global_test_run_manager\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    260\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
      "File \u001b[0;32m~/chatbot-tlcn/.venv/lib/python3.12/site-packages/deepeval/test_case/utils.py:13\u001b[0m, in \u001b[0;36mcheck_valid_test_cases_type\u001b[0;34m(test_cases)\u001b[0m\n\u001b[1;32m     11\u001b[0m llm_test_case_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     12\u001b[0m conversational_test_case_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_cases\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLLMTestCase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_case\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLLMTestCase\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mllm_test_case_count\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ConversationalTestCase' object is not iterable"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    test_cases=tc,\n",
    "    metrics=[pronoun_consistency_metric],\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define conversation starters\n",
    "CONVERSATION_STARTERS = [\n",
    "    \"Chào shop, mình muốn hỏi về {topic}\",\n",
    "    \"Shop ơi, cho mình hỏi về {topic}\",\n",
    "    \"Mình đang tìm hiểu về {topic}\",\n",
    "    \"Bên shop có {topic} không?\",\n",
    "    \"Mình muốn hỏi về {topic}\"\n",
    "]\n",
    "\n",
    "# Define follow-up questions\n",
    "FOLLOW_UP_QUESTIONS = [\n",
    "    \"Vậy {topic} có {detail} không?\",\n",
    "    \"Có thể cho mình biết thêm về {detail} không?\",\n",
    "    \"Vậy {topic} thì {detail} thế nào?\",\n",
    "    \"Có thể giải thích rõ hơn về {detail} không?\",\n",
    "    \"Vậy {topic} có {detail} không shop?\"\n",
    "]\n",
    "def generate_bot_response(user_message: str, faqs: List[FAQModel], turn_number: int) -> str:\n",
    "    \"\"\"Generate a bot response based on user message and FAQs\"\"\"\n",
    "    if turn_number == 1:\n",
    "        # First turn - greeting and asking for more information\n",
    "        return f\"Dạ chào anh/chị, em có thể giúp gì cho anh/chị ạ?\"\n",
    "    else:\n",
    "        # Follow-up turns - provide information based on FAQs\n",
    "        # Use OpenAI to generate a response based on the user message and FAQs\n",
    "        faq_context = \"\\n\".join([\n",
    "            f\"Q: {faq.question}\\nA: {faq.answer}\"\n",
    "            for faq in faqs\n",
    "        ])\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"\"\"You are a helpful customer service representative at FPT Shop. \n",
    "                Use the following FAQs to answer customer questions:\n",
    "                {faq_context}\n",
    "                \n",
    "                Guidelines:\n",
    "                - Be professional and friendly\n",
    "                - Use appropriate Vietnamese pronouns (em-anh/chị)\n",
    "                - Keep responses concise but informative\n",
    "                - If the question isn't covered in FAQs, ask for more details\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=150\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conversation_test_case(faqs: List[FAQModel], num_turns: int = 2) -> ConversationalTestCase:\n",
    "    \"\"\"Generate a multi-turn conversation test case\"\"\"\n",
    "    # Select random FAQ\n",
    "    faq = random.choice(faqs)\n",
    "    \n",
    "    # Generate conversation turns\n",
    "    turns = []\n",
    "    \n",
    "    # First turn\n",
    "    first_input = random.choice(CONVERSATION_STARTERS).format(topic=faq.title)\n",
    "    first_output = generate_bot_response(first_input, [faq], 1)\n",
    "    turns.append(LLMTestCase(\n",
    "        input=first_input,\n",
    "        actual_output=first_output,\n",
    "        context=[f\"FAQ Category: {faq.category}\"]\n",
    "    ))\n",
    "    \n",
    "    # Follow-up turns\n",
    "    for i in range(1, num_turns):\n",
    "        # Extract key details from FAQ answer for follow-up questions\n",
    "        follow_up = random.choice(FOLLOW_UP_QUESTIONS).format(\n",
    "            topic=faq.title,\n",
    "            detail=random.choice(faq.answer.split(\".\")[0].split())\n",
    "        )\n",
    "        bot_response = generate_bot_response(follow_up, [faq], i + 1)\n",
    "        turns.append(LLMTestCase(\n",
    "            input=follow_up,\n",
    "            actual_output=bot_response,\n",
    "            context=[f\"FAQ Category: {faq.category}\"]\n",
    "        ))\n",
    "    \n",
    "    return ConversationalTestCase(turns=turns)\n",
    "\n",
    "def generate_test_cases(num_cases: int = 10, min_turns: int = 2, max_turns: int = 4) -> List[ConversationalTestCase]:\n",
    "    \"\"\"Generate multiple test cases using FAQs\"\"\"\n",
    "    all_test_cases = []\n",
    "    faqs = get_all_faqs()\n",
    "    \n",
    "    for _ in range(num_cases):\n",
    "        num_turns = random.randint(min_turns, max_turns)\n",
    "        test_case = generate_conversation_test_case(faqs, num_turns)\n",
    "        all_test_cases.append(test_case)\n",
    "    \n",
    "    return all_test_cases\n",
    "\n",
    "def save_test_cases(test_cases: List[ConversationalTestCase], output_file: str):\n",
    "    \"\"\"Save test cases to a JSON file\"\"\"\n",
    "    serialized_cases = []\n",
    "    for case in test_cases:\n",
    "        serialized_turns = []\n",
    "        for turn in case.turns:\n",
    "            serialized_turns.append({\n",
    "                \"input\": turn.input,\n",
    "                \"actual_output\": turn.actual_output,\n",
    "                \"context\": turn.context\n",
    "            })\n",
    "        serialized_cases.append({\"turns\": serialized_turns})\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(serialized_cases, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
